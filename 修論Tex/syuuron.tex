%%%%%%%%%%%%%%%%%%%%����%%%%%%%%%%%%%%%%%%%%
\documentclass[a4paper,12pt]{jarticle}	
%!TEX encoding = UTF-8 Unicode

%%%%%%%%%%%%%%%%%%%%�p�b�P�[�W�̓ǂݍ���%%%%%%%%%%%%%%%%%%%%
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{bm}
\usepackage[dvipdfmx]{graphicx}
\usepackage{ascmac}
\usepackage{amsthm}
\usepackage{bmpsize}
\usepackage{subfig}
\usepackage{nidanfloat}
\usepackage{here}
\usepackage{comment}
%\usepackage{url}
\usepackage[hyphens]{url}
\usepackage{amsmath} 			
\usepackage{amssymb}			
\usepackage{mathrsfs}
\usepackage[titletoc, title]{appendix}
%\usepackage{indentfirst} 			
%%%%%%%%%%%%%%%%%%%%�}�[�W���̐ݒ�%%%%%%%%%%%%%%%%%%%%
\topmargin=10mm 	
\voffset=-1in 		
\headheight=5mm	  	
\headsep=10mm 		
\textheight=252mm 	
\topskip=0mm 		
\footskip=10mm  	

\evensidemargin=30mm 	
\oddsidemargin=30mm 	
\hoffset=-1in 			
\textwidth=170mm 		

\marginparpush=0mm 		
\marginparsep=0mm 		
\marginparwidth=0mm 	

%%%%%%%%%%%%%%%%%%%%�T�v�C�}�C�\�Ȃǂ̖��O���ς���%%%%%%%%%%%%%%%%%%%%
\renewcommand{\thesection}{\arabic{section}.}
\renewcommand{\thesubsection}{\arabic{section}.\arabic{subsection}}
\renewcommand{\figurename}{{Fig}.}
\renewcommand{\tablename}{{Table}}
\renewcommand{\contentsname}{目次}
\renewcommand{\appendixname}{Appendix}
\renewcommand{\refname}{参考文献}
\renewcommand{\labelenumi}{(\Roman{enumi})}


\newcommand{\eref}[1]{Eq.~(\ref{#1})}
\newcommand{\esref}[2]{Eqs.~(\ref{#1}) and (\ref{#2})}
\newcommand{\essref}[2]{Eqs.~(\ref{#1})$\sim$(\ref{#2})}
\newcommand{\figref}[1]{Fig.~\ref{#1}}
\newcommand{\figsref}[2]{Figs.~\ref{#1} and \ref{#2}}
\newcommand{\figssref}[2]{Figs.~\ref{#1}$\sim$\ref{#2}}
\newcommand{\tabref}[1]{Table \ref{#1}}
\newcommand{\secref}[1]{\S \ \ref{#1}}

\makeatletter
\renewcommand{\@cite}[1]{\textsuperscript{(#1)}}
\renewcommand{\@biblabel}[1]{(#1)}
\makeatother

\newcommand{\citeref}[1]{\textsuperscript{\cite{#1}}}
\newcommand{\citesref}[2]{\textsuperscript{\cite{#1},~\cite{#2}}}
\newcommand{\citessref}[2]{\textsuperscript{\cite{#1}$\sim$\cite{#2}}}

\begin{document}
\input{dummy}
\baselineskip=18pt 	

\thispagestyle{empty} 		
%\pagenumbering{roman}	
%\setcounter{page}{0} 		
\pagestyle{plain} 		

\makeatletter
\def\@maketitle{%
\begin{center}%
\let\footnote\thanks
\vspace*{25mm} % 
{\LARGE \@title \par}%
\vskip 1.5em%
{\large
\lineskip .5em%
\begin{tabular}[t]{c}%
\@author
\end{tabular}\par}%
\vskip 1em%
{\large \@date}%
\end{center}%
\par\vskip 1.5em}
\makeatother 

\makeatletter
\long\def\@makecaption#1#2{%
\vskip\abovecaptionskip
\iftdir\sbox\@tempboxa{#1\hskip1zw#2}%
\else\sbox\@tempboxa{#1 #2}%
\fi
\ifdim \wd\@tempboxa >\hsize
\iftdir #1\hskip1zw#2\relax\par
\else #1 #2\relax\par\fi
\else
\global \@minipagefalse
\hbox to\hsize{\hfil\box\@tempboxa\hfil}%
\fi
\vskip\belowcaptionskip}
\makeatother




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Abstract %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Abstract}
In recent years, the aging of infrastructure has been regarded as a problem in Japan, but the local governments that manage them have a shortage of financial resources and inspectors. Therefore, we focused on the inspection method using UAV (Unmanned Aerial Vehicle). Replacing the inspection performed by the special work vehicle with the inspection by the UAV can reduce costs and ensure worker safety. However, because UAVs require technique to operate, automatic flight by GPS is generally used, but radio waves from satellites are blocked on bridges and cannot be used. Therefore, the position of the UAV was estimated using the UWB (Ultra-Wide Band) module which is a ranging device and the optical flow sensor which can measure the speed, and the method for autonomous flight was shown. Next, the experiment showed that the accuracy of the estimated position was sufficiently high. In addition, we performed position holding control with only one point as the target value and autonomous flight control with multiple points as the target values. As a result, it was confirmed that position control was possible without deviating from the target point.

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Abstract %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{概要}
近年の日本ではインフラの老朽化が問題視されているが，それらを管理する地方自治体は財源や点検者が不足しているため，低コストで簡便に行えるインフラ点検の技術が求められる．そこでUAV（Unmanned Aerial Vehicle）による点検手法に着目した．特殊作業車にて行っていた点検をUAVによる点検に置き換えることでコストを下げ，作業者の安全も確保できる．しかしUAVの操縦には技術が必要とされるため，GPSによる自動飛行が一般的であるが，橋梁においては衛星からの電波が遮られ使用不可能である．そこで，測距機器であるUWB（Ultra-Wide Band）モジュールや速度が計測可能なオプティカルフローセンサを用いてUAVの位置を推定し，自律飛行のための手法を示した．次に，実験により推定された位置の精度を確認すると十分に高い結果を得た．また，定点を目標値とする位置保持制御や複数点を目標値とする自律飛行制御を行ったところ，目標点から逸脱することなく位置制御が可能なことを確認した．





\thispagestyle{empty} 
	
\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Contects %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\thispagestyle{empty} 
\tableofcontents 			
\thispagestyle{empty} 	
\pagenumbering{arabic} 	
\setcounter{page}{0} 		
\pagestyle{plain}
 
\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Introduction %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{緒言}
\subsection{研究背景}
近年の日本において，インフラ，特にその中においても橋梁の老朽化が問題視されている．国土交通省が発表するデータによると，長さ15 mを超える橋梁の数は2013年時点で40万橋存在し，その中でも建設後50年が経過したものの割合は18 \%（7万1000橋）である\cite{a}．こうした老朽化した橋は今後も増加すると予想され，10年後には43 \%，20年後には67 \%と，過半数の橋梁が建設後50年を迎えることとなる．適切に管理，検査がなされていない老朽化した橋梁はやはり崩落事故などの危険性をはらんでいる．橋梁の崩落事故はアメリカのミネアポリスのものが有名である．しかし，海外だけでなく，日本国内においても崩落や崩落事故になりかけた事例がいくつか存在する．2007年の6月三重県にある国道23号の木曽川大橋で，コンクリートの床版に覆われたトラスの斜材が腐食して破断する事故が起こった．幸いにもこの事故では崩落や死傷者を出すことは免れたが，ずさんな点検のあり方が浮き彫りになった．事故の1年半ほど前には点検が行われたとされているが，腐食の進んだ鋼材の錆の上から塗装を行うなど，常識を逸脱する補修の形跡が見過ごされていた\cite{b}．こういった不適切な橋梁の管理，運営には橋梁を所有する地方自治体の財源不足なども背景とされている．国土交通省によると，1つの橋梁を近接目視で点検するだけでも50万円の費用がかかるとされている．しかし，市区町村が管理する橋の年間の維持，修繕費は1つの橋梁平均でわずか8万円であり\cite{c}，いかに橋梁の点検に掛ける予算が低いのかがわかる．また，橋梁の点検に用いられる一般的な方法は近接目視及び打音検査であり，傷やひび割れの正確な検出には多くの経験を要する．これらの理由より，低コストかつ簡便に橋梁を点検可能にする新しい技術を開発することが現在の日本において喫緊の課題である．

\begin{figure}[H]
\begin{center}
\includegraphics[height=70mm]{./Fig2/number_of_bridges.png}
\caption{Number of bridges in Japan by construction year\cite{a}.}
\label{Number_of_bridges_in_Japan_by_construction_year}
\end{center}
\end{figure}

そこで，着目したのがドローンなどのロボットを用いた橋梁の点検手法である．ここで，ロボットを用いた点検手法は大別して2種類に分けることができる．1つ目は機体に車輪を有し，橋梁の壁面や床面を伝って移動することで点検箇所へアプローチ可能な地上型ロボットである．もう1つはUAVなどの飛行型ロボットであり，これらは前者と異なり，空中から点検箇所にアプローチ可能である．地上型ロボットとしては高田らが開発したBIREM\cite{d}（Fig. \ref{BIREM}）が挙げられる．このロボットは車輪の先端に磁石を装備しており，吸着対象が磁性体ならば，床や壁を伝いながら点検箇所へ接近し，カメラを用いた目視検査などがすることが可能である．しかし，このロボットは点検箇所まで構造物が地続きである必要があり，橋梁の途中で大きなギャップがあった場合にその先に進めないことや，大きな段差があった場合にそれらを乗り越えられない問題もある．しかし，飛行型のロボットの場合，大きなギャップや障害物があってもそれらを乗り越えて点検箇所まで近づける．これらの理由より，本研究では飛行型ロボットを開発するに至った．

\begin{figure}[H]
\begin{center}
\includegraphics[height=70mm]{./Fig2/takadabylim.jpg}
\caption{BIREM\cite{d}.}
\label{BIREM}
\end{center}
\end{figure}


\subsection{インフラ点検用UAV及び点検機器の開発}
先行研究において，赤堀らはFig. \ref{UAV_akahori}に示すインフラ点検用UAVを開発した\cite{e}．このUAVは機体の上部にEPM（Electro-Parmanent Magnet）と呼ばれる磁石を搭載し，磁力を用いて構造物の鋼材に吸着することで，安定した点検を可能にした．このEPMと呼ばれる磁石の特徴は，磁力の吸着状態と開放状態を自在に制御することが可能なことである．また，この磁石は電磁石と異なり，吸着と離脱時のみ電力を消費し，吸着中は電力を消費しない．このUAVはEPMに加え，先端にカメラを有するアームも装備するため，EPMを用いて吸着した状態で安定した目視点検をすることが可能である．



\begin{figure}[H]
\begin{center}
\includegraphics[height=90mm]{./Fig2/Overall_picture_of_our_robot.png}
\caption{Overall view of the developed inspection robot in the previous study\cite{e}.}
\label{UAV_akahori}
\end{center}
\end{figure}

\noindent
また，著者の先行研究ではこのEPMを吸着機構に採用した振動計測モジュールを開発した（Fig. \ref{vibration measurement unit}）．このモジュールは加速度センサ及びデータロガーを搭載しており，対象物に吸着した後，加速度を計測，ロギングすることが可能である．そして，その振動を解析することで対象物の健全性を評価することが可能である．このモジュールを用いた点検方法としては，まず点検箇所までUAVを用いてこれを運搬し，EPMの磁力で貼り付かせる．必要なデータを計測した後，最終的にUAVで回収する流れである．また，重量が約230 gであるため，赤堀らが開発したUAVであれば，複数個積載し，運搬することが可能である．



\begin{figure}[H]
\begin{center}
\includegraphics[height=70mm]{./Fig2/front.png}
\caption{vibration measurement unit.}
\label{vibration measurement unit}
\end{center}
\end{figure}



\noindent
これらのUAVを用いた点検では構造物の地形に対して柔軟な対応性を有するが，機体の操作は全て自身の操縦で行う必要性がある．経験の豊富なパイロットであれば狙い通りの箇所に接近し，点検することやセンサを取り付けることが可能である．しかし，経験の浅いパイロットが操縦する場合，非常に困難である．


\subsection{一般的な自律飛行型UAV}
飛行型ロボットを点検に用いることの有用性は高いが，操作面においては課題が多いのが現状である．手動操縦は操作技術を要するため，現在市販される多くのドローンはGPSやレーザーレンジファインダなどの位置推定システムを用いて全自動，もしくは半自動飛行が可能である\cite{f}\cite{g}\cite{h}．本研究でも用いたフライトコントローラもGPSアンテナが搭載されており，屋外のGPS環境であれば目的地を入力することによりその地点まで全自動飛行することが可能である．しかし，研究対象とする橋梁などの構造物の周辺環境においては，構造物自体が遮蔽物となりGPSの電波が遮断されるため，GPSを用いた位置推定は不可能である．そのような非GPS環境においても自動飛行可能なUAVも多くの企業や研究者によって開発が行われている．株式会社自律制御システム研究所はFig. \ref{photo5}に示すSLAM（Simultaneous Localization and Mapping）の機能を有したUAV\cite{i}を開発した．このUAVは非GPS環境においても自己位置推定と環境地図の作製を同時に行いながら自律飛行をすることが可能である．
	

\begin{figure}[H]
\begin{center}
\includegraphics[height=70mm]{./Fig2/photo5.png}
\caption{ACSL-PF1\cite{i}.}
\label{photo5}
\end{center}
\end{figure}

\noindent
手法としては搭載された下向きのモノラルカメラや前方に向けて取り付けられたステレオカメラを用いて撮影した画像に処理を行うことで自己位置や方角を推定し自律飛行を行う．しかし，それらのためには高価で精度の高いカメラや画像処理用のGPUを搭載する必要があるため，機体自体の値段が高価になる．また，画像から得た情報を基に様々な値を計算するには計算負荷の高い演算をしなくてはならない．点検に掛けることが可能な財源が限られている地方自治体にとって，人件費がかからなかったとしても，機体が高価であった場合，大きなコスト削減は見込めない．また，多くのセンサや高負荷な計算が可能である高性能なCPUやGPUを搭載する必要があるため，機体が大型化し，狭い点検空間に入っていくのが困難になる問題がある．


\subsection{研究目的}
前節で述べたこれらの課題を克服するため，本研究ではローカル座標を推定する手法にUWBモジュールを用いる手法に着目した．UWB（超高帯域無線通信，Ultra-Wide Band）とは無線通信方式の一種であり，Wi-FiやBlutoothなど他の無線通信方式に比べ，広い帯域幅を持った通信方式である\cite{j}．このモジュールは片方のデバイスからもう片方のデバイスに電波を送信することで通信を行う．その際の通信に掛かった時間に電波の速度を掛けることにより，デバイス間の距離を算出することが可能である．このモジュールを用いて距離を求め，後に示す手法により演算することでUAVの位置を3次元空間内で得ることが可能である．自己位置を推定する際のUWB移動局と固定局との関係をFig. \ref{UWB_positioning}に示す．


\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/UWB_positioning.png}
\caption{Schematic diagram of the position estimation method.}
\label{UWB_positioning}
\end{center}
\end{figure}

\noindent
詳細は以降の章にて後述するが，座標が既知の各固定局と移動局との距離を計測し，マルチラテレーションの手法を用いることで，移動局の座標を推定することが可能である．この手法はGPSアンテナとGPS衛星との距離を用いて移動局の座標を得るのと同手法である．またUWBモジュールは1個あたり数千円と非常に安価であり，位置制御システムのコスト削減に有効である．それに加えてマルチラテレーションの計算は画像解析を用いる計算などに比べて非常に負荷が軽く，高性能なコンピュータを搭載する必要がないため，機体が大型化することもない．しかし，UWBモジュールの更新周期は4つの固定局を用いた場合に10 Hzと低く，クアッドロータが高速で移動した際には，位置推定周期としては不十分である．そこで，本研究での目的はUWBモジュールの更新周期の遅さを補うためにUWBモジュールを用いたローカルポジショニングシステムにIMU，距離センサ，及びオプティカルフローセンサの値も参照することでクアッドロータの位置を推定し，その位置を制御する手法を提案することである．IMU(Inertial Measurement Unit）は加速度，角速度，地磁気を数1000 Hz程度の高い更新周波数で計測可能であり，加速度や角速度を積分することにより，速度や変位を得ることが可能であるが，値を積分した際にノイズ成分も積分するため，推定値が時間と共にドリフトする．距離センサは積分することなく，地面との距離を計測することが可能である．オプティカルフローセンサは地面の特徴点の移動量より機体の速度を算出することが可能である．先行研究において赤堀ら\cite{e}はUWBモジュール，IMU，距離センサを用いたクアッドロータの位置推定システム，及び位置制御システムを開発した．しかし，姿勢角制御の周期が遅いことが原因で，クアッドロータの位置が発散し，位置を目標地点において制御するには至らなかった．そこで，本研究では姿勢角制御の遅さを補うためにフライトコントローラを追加で新たに導入し，応答性の改善を図った．また，既存の位置推定システムに対し，新たにオプティカルフローセンサも搭載し，従来までのシステムでは取り除けなかった，目標点におけるクアッドロータの細かい振動を取り除くための改善も行った．次章からはUWBモジュール及び各種センサ値にカルマンフィルタを適用したクアッドロータの位置推定手法および位置制御手法を示していく．


\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%クアッドロータの位置推定アルゴリズム%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{クアッドロータの位置推定アルゴリズム}
本研究で提案するクアッドロータの位置及び姿勢推定にはカルマンフィルタ，その中でも特に非線形なシステムに適応可能な拡張カルマンフィルタ（EKF : Extended Kalman Filter)を使用した．ここで，カルマンフィルタとは，誤差を含むある観測値（2種類以上も可）を使用し，時々刻々と変化する状態量を推定するのに用いられる，逐次処理が可能なフィルタリング手法である．代表例としてはカーナビゲーションシステムが挙げられる．カーナビゲーションシステムはGPSから得られる誤差の乗った位置情報と内部の加速度センサから得られる誤差の乗った加速度情報を統合することにより，自車の位置座標や速度などを推定している．本研究ではIMU，UWBモジュール，距離センサ，オプティカルフローセンサから得られるセンサ値を統合し，機体の姿勢角，速度，座標を推定するのに用いられる．本章では初めに拡張カルマンフィルタの原理を示した後，UWBモジュールやオプティカルフローセンサの原理やキャリブレーション方法について述べる．そして最後にそれらセンサを統合したシステムを示し，位置の推定方法を説明する．



\subsection{拡張カルマンフィルタの原理\cite{k}}
拡張カルマンフィルタは非線形システムを各時刻において線形化し，それぞれの時刻において時変カルマンフィルタを適用する考えに基づいている．まず離散時間非線形状態空間表現が次の2式で表される場合を考える．

\begin{align}
\textbf{x}(t+1) = \textbf{f}(\textbf{x}(t)) + \textbf{B}\textbf{v}(t)
\label{2-1}
\end{align}

\begin{align}
\textbf{y}(t) = \textbf{h}(\textbf{x}(t)) + \textbf{w}(t)
\label{2-2}
\end{align}

\noindent
ここで$\textbf{f}(\cdot)$，および$\textbf{h}(\cdot)$はベクトル値をとる$\textbf{x}(t)$の非線形関数である．また$\textbf{v}(t)$は平均値ベクトル0，共分散行列$\textbf{Q}$のr次元システム雑音ベクトル，$\textbf{w}(t)$は平均値ベクトル0，共分散行列$\textbf{R}$のp次元観測雑音ベクトルであり，互いに独立な正規性白色雑音と仮定する．時刻$t$，$t+1$において，それぞれ事前状態推定値$\hat{\textbf{x}}^{-}$と事後推定値$\hat{\textbf{x}}$が利用可能であるという仮定のもとで，式\eqref{2-1}と式\eqref{2-2}の非線形関数をテイラー級数展開を用いて線形近似すると，

\begin{align}
\textbf{f}(\textbf{x}(t))=\textbf{f}(\hat{\textbf{x}}(t))+\textbf{A}(t)(\textbf{x}(t)-\hat{\textbf{x}}(t)),\left.\textbf{A}(t)=\frac{\partial \textbf{f}(\textbf{x})}{\partial \textbf{x}}\right|_{\textbf{x}=\hat{\textbf{x}}(t)}
\label{2-3}
\end{align}

\begin{align}
\textbf{h}(\textbf{x}(t))=\textbf{h}(\hat{\textbf{x}}^{-}(t))+\textbf{c}^{T}(t)(\textbf{x}(t)-\hat{\textbf{x}}^{-}(t)),\left.\textbf{C}^{T}(t)=\frac{\partial \textbf{h}(\textbf{x})}{\partial \textbf{x}}\right|_{\textbf{x}=\hat{\textbf{x}}^{-}(t)}
\label{2-4}
\end{align}\

\noindent
が得られる．式\eqref{2-3}を式\eqref{2-1}に，式\eqref{2-4}を式\eqref{2-2}に代入すると，それぞれ，

\begin{align}
\textbf{x}(t+1)=\textbf{A}(t)\textbf{x}(t)+\textbf{b}\textbf{v}(t)+\textbf{f}(\hat{\textbf{x}}(t))-\textbf{A}(t)\hat{\textbf{x}}(t)
\label{2-5}
\end{align}

\begin{align}
\textbf{y}(t)=\textbf{C}^{T}(t)\textbf{x}(t)+\textbf{w}(t)+\textbf{h}(\hat{\textbf{x}}^{-}(t))-\textbf{C}^{T}(t)\hat{\textbf{x}}^{-}(t)
\label{2-6}
\end{align}\

\noindent
が得られる．さらに

\begin{align}
\textbf{u}(t)=\textbf{f}(\hat{\textbf{x}}(t))-\textbf{A}(t)\hat{\textbf{x}}(t)
\label{2-7}
\end{align}

\begin{align}
\textbf{z}(t)=\textbf{y}(t)-\textbf{h}(\hat{\textbf{x}}^{-}(t))+\textbf{C}^{T}(t)\hat{\textbf{x}}^{-}(t)
\label{2-8}
\end{align}\

\noindent
とおくと，式\eqref{2-5}と式\eqref{2-6}はそれぞれ次のようになる．

\begin{align}
\textbf{x}(t+1)=\textbf{A}\textbf{x}(t)+\textbf{B}\textbf{v}(t)+\textbf{u}(t)
\label{2-9}
\end{align}

\begin{align}
\textbf{z}(t)=\textbf{C}\textbf{x}(t)+\textbf{w}(t)
\label{2-10}
\end{align}\

\noindent
このように非線形システムをテイラー級数展開を用いて線形近似すると制御入力がある場合のカルマンフィルタになる．以上より予測ステップにおける更新式は

\begin{align}
\hat{\textbf{x}}^{-}(t)=\textbf{f}(\hat{\textbf{x}}(t-1))
\label{2-11}
\end{align}

\begin{align}
\textbf{P}^{-}(t)=\textbf{A}(k-1)\textbf{P}(t-1)\textbf{A}^{T}(k-1)+\textbf{B}\textbf{Q}\textbf{B}^{T}
\label{2-12}
\end{align}\

\noindent
となる．ここで$\textbf{A}(t-1)$は

\begin{align}
\left.\textbf{A}(t-1)=\frac{\partial \textbf{f}(\textbf{x})}{\partial \textbf{x}}\right|_{\textbf{x}=\hat{\textbf{x}}(t)}
\label{2-13}
\end{align}\

\noindent
となる．またフィルタリングステップの更新式は

\begin{align}
\hat{\textbf{x}}(t)=\hat{\textbf{x}}^{-}(t)+\textbf{g}(t)(\textbf{y}(t)-\textbf{h}(\hat{\textbf{x}}^{-}(t)))
\end{align}

\begin{align}
\textbf{P}(t)=(\textbf{I}-\textbf{G}(k)\textbf{C}^{T}(t))\textbf{P}^{-}(k)
\end{align}\

\noindent
となる．ここでカルマンゲイン$G(t)$及び$\textbf{C}^{T}(t)$は次式で計算することができる．

\begin{align}
\textbf{G}(t)=\textbf{P}^{-}(k)\textbf{C}^{T}(\textbf{C}\textbf{P}^{-}(k)\textbf{C}^{T}+\textbf{R})^{-1}
\end{align}\

\begin{align}
\left.\textbf{C}^{T}(t)=\frac{\partial \textbf{h}(\textbf{x})}{\partial \textbf{x}}\right|_{\textbf{x}=\hat{\textbf{x}}^{-}(t)}
\end{align}\

\noindent
拡張カルマンフィルタにおいては各時刻ごとに$\textbf{f}$と$\textbf{h}$のヤコビアンを求めるため偏微分の計算を行わなければならない．そのため，微分可能な滑らかな非線形性の場合には拡張カルマンフィルタを適用できるが，不連続な非線形性をもつ場合には適用できない．






\subsection{UWB通信}
\subsubsection{UWBモジュールの測距原理}
UWBの技術が発展するまでは，無線通信を利用した距離測定においてBlutoothやWi-Fiが多く用いられてきた．片方のデバイスが電波を発信し，それをもう片方が受け取ることでデバイス同士が通信を行う．受信側の受け取った電波の強弱により発信側が近くにあるのか遠くにあるのかを判別し，デバイス間の距離を算出する．しかし，弱い電波を受け取った際，距離が離れているため電波が弱いのか，それともデバイス間に障害物があるため電波が弱いのか，ということを判別できない．したがって，Wi-FiやBlutoothを用いた測距は誤差が5 mほど乗るとされている\cite{l}．一部の企業はWi-Fi電波の飛行時間（Time of flight，ToF）や到着時間（Time of Arrival，ToA）を使用し，距離をより正確に測るための代替アルゴリズムを開発したが，既存のWi-Fiを用いてこれを行うことはハードウェアの問題により難しいとされている．

UWB通信（超広帯域無線通信，Ultra-Wide Band）とは無線通信方式の1種であり，非常に広い帯域幅にわたって電波を拡散させることで高速通信を可能とする．Fig. \ref{UWB_power}にUWB通信と既存の無線通信方式とのスペクトラムの比較を示す．周波数の帯域は3.1 GHｚから10.6 GHzであり，その帯域幅は7.5 GHzと従来の無線の数百 kHzやWi-Fiの20 MHzに比べてかなり広い帯域を利用している\cite{m}．

\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/UWB_power.png}
\caption{Comparison of power spectrum between UWB and other wireless communication systems.}
\label{UWB_power}
\end{center}
\end{figure}

\noindent
送信出力は-41.3 dBm/MHz以下に制限されており，これは家庭用テレビやパソコン等の一般の電子機器等が発生する雑音レベルの約500分の1以下の非常に小さな出力であり，人体に悪影響を及ぼさない．また，UWB通信はFig. \ref{narrow_wide}に示すようにナノ秒オーダーのパルスを通信に使用し，狭帯域信号のような立ち上がりが遅い信号に比べて，デバイス間の距離を高精度で測定可能である\cite{l}．

\begin{figure}[H]
\begin{center}
\includegraphics[height=60mm]{./Fig2/narrow_wide.png}
\caption{Comparison of pulses between narrow band and ultra wide band signals\cite{l}.}
\label{narrow_wide}
\end{center}
\end{figure}

\noindent
また，Fig. \ref{narrow}，Fig. \ref{wide}に示すように狭帯域信号に比べ，UWB信号はSN比が良いため，ノイズの影響を受けにくいことなどが特長として挙げられる\cite{l}．

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}

      \begin{minipage}[t]{0.5\hsize}
        \begin{center}
         \includegraphics[height=50mm]{./Fig2/narrow.png}
	  \caption{Narrow band signal with noise\cite{l}.}
	　\label{narrow}
        \end{center}
      \end{minipage}

      \begin{minipage}[t]{0.5\hsize}
        \begin{center}
          \includegraphics[height=50mm]{./Fig2/wide.png}
          \caption{Ultra wide band signal with noise\cite{l}.}
	   \label{wide}
        \end{center}
      \end{minipage}

    \end{tabular}
  \end{center}
\end{figure}

\noindent
無線通信を測距に利用する際に大きな問題とされるのがマルチパスの発生である．マルチパスとは電波を受信した際に，直接波の他に壁などの障害物に反射した反射波を受信する場合があり，この際，正確な信号受け取れないことや，直接波の位相を反射波が遅らせることが発生する現象である．テレビやラジオにてゴースト障害が起きるのもこのマルチパスが原因とされている．無線通信を利用した測距の場合には正確な到達時間を計測できず，測距誤差が発生する．次のFig. \ref{narrow_with_reflections}，Fig. \ref{wide_with_reflections}に狭帯域信号とUWB信号のマルチパスの影響の比較を示す．



\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}

      \begin{minipage}[t]{0.5\hsize}
        \begin{center}
         \includegraphics[height=50mm]{./Fig2/narrow_with_reflections.png}
	  \caption{Narrow band signal with reflections\cite{l}.}
	　\label{narrow_with_reflections}
        \end{center}
      \end{minipage}

      \begin{minipage}[t]{0.5\hsize}
        \begin{center}
          \includegraphics[height=50mm]{./Fig2/wide_with_reflections.png}
          \caption{Ultra wide band signal with reflections\cite{l}.}
	   \label{wide_with_reflections}
        \end{center}
      \end{minipage}

    \end{tabular}
  \end{center}
\end{figure}

\noindent
狭帯域信号では立ち上がりと立ち下がりが鈍く，障害物で位相が反転した反射波の影響により直接波の位相や振幅が変化させられているのが分かる．しかし，UWB信号は立ち上がり時間と立ち下がり時間が短いため，直接波の後に反射波が来ていても直接波に悪影響を与えない．このようなマルチパス耐性が高いこともUWBの特長である\cite{l}．


次にUWB通信を用いた測距方法について見ていく．UWB通信による測距は主に電波の飛行時間（ToF）を用いている．送信側と受信側が互いに通信し，電波の到達するのに掛かった時間（Tof）に電波の速度（$c$）を掛けることにより，距離（$d$）を測定することが可能である．次に計算式を示す．

\begin{align}
d = \textrm{ToF} \times c
\label{2-2-1}
\end{align}

\noindent
またFig. \ref{UWB_ranging_2}に通信プロトコルを示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/UWB_ranging_2.png}
\caption{Ranging protocol of UWB module.}
\label{UWB_ranging_2}
\end{center}
\end{figure}

\noindent
これ以降，クアッドロータに搭載された移動局をタグ，床に固定された固定局をアンカと記載する．クアッドロータの座標を3次元で推定するためには1つのタグと3つ以上のアンカが必要である．それに伴い，複数のデバイスを識別するためにまずアンカ側から16進数からなるIDを送信する．その後タグ側から応答があり，最後にアンカ側のタイムスタンプ（$T_{SP}, T_{RR}, T_{SF}$）を送信する．この送られてきたタイムスタンプ及びタグ側のタイムスタンプ（$T_{RP}, T_{SR}, T_{RF}$）を用い，次式のように電波の飛行時間（ToF）を計算可能である．

\begin{align}
\textrm{ToF} = \frac{1}{4}((T_{SP} - T_{RR}) - (T_{SR} - T_{RP}) + (T_{RF} - T_{SR}) - (T_{SF} - T_{RR})) 
\label{2-2-2}
\end{align}

\noindent
次のFig. \ref{Anchor}に製作したUWBモジュールのアンカを示す．搭載されたUWBチップはDecaWave社製のDWM1000\cite{n}である．マイコンはTeensy3.6を用いて制御を行っている．電源はFig. \ref{Li_ion}に示すUltraLife社製, 1 cell, 1800 mAhのリチウムイオンバッテリを用いている．図の基板構成で満充電から約3時間容量が保つ．Fig. \ref{Anchor}からわかるように，小型であるためアンカの設置や回収は容易に行うことが可能である．


\begin{figure}[H]
\begin{center}
\includegraphics[height=60mm]{./Fig2/Anchor.png}
\caption{UWB anchor.}
\label{Anchor}
\end{center}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[height=50mm]{./Fig2/Li_ion.jpg}
\caption{Battery for UWB Anchor\cite{o}.}
\label{Li_ion}
\end{center}
\end{figure}


\noindent
前述したようにUWB通信はマルチパスに耐性があり，本研究と同様にUWBモジュールを用いたクアッドロータの位置制御を行っている研究\cite{p}でも言及されているように，壁のように強い反射体の近くにおいても測距性能は正確であるが，森林のようなデバイス間に障害物が存在する環境：NLOS(Non Line Of Sight，非見通し環境)においてはマルチパスが発生し，真値より大きく外れた値や負の値を取ることがある．本研究においても，このマルチパスの影響にる値の発散を確認した．Fig. \ref{UWB_out}に測距した際にマルチパスが発生し，値が発散した結果を示す．またそれの拡大図もFig. \ref{UWB_out_zoom}に合わせて示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=60mm]{./Fig2/UWB_out.png}
\caption{Ranging result when outliers occur.}
\label{UWB_out}
\end{center}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[height=60mm]{./Fig2/UWB_out_zoom.png}
\caption{Ranging result when outliers occur (enlarged image above).}
\label{UWB_out_zoom}
\end{center}
\end{figure}

\noindent
測距手順を以下に説明する．実験室の床に基準となる線を1 mから5 mまで1 m間隔でマーキングした．始線にタグを固定し，4つのアンカを基準線に添わせて並べる．数秒間測距を行った後，1 m先の次の基準線へ4つのアンカをを移動させる．この手順を他の線においても繰り返した．実験時の模式図を次のFig. \ref{}に示す．


\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/ranging_experiment.png}
\caption{Schematic diagram of ranging experiment.}
\label{ranging_experiment}
\end{center}
\end{figure}



2つの図からわかるように，測距した最長の距離は5 mであるのにも関わらず，値が発散し最長300 mほどの値や負の値を計測している．UWBモジュール間に障害物が無かったのにも関わらず，こういったマルチパスが発生した原因は壁や天井により電波が反射したためであると考えられる．タグと各アンカとの正確な距離が得られていない場合，3次元空間内におけるクアッドロータの位置推定値も不正確になるため，こういった発散した値は取り除く必要がある．そこで，電波の指向性を考慮し，モジュールケースの製作を行った．UWBモジュールには指向性があり，電波強度の強い向きと弱い向きが$x,,y, z$軸周りに存在する．ここで，本研究にて採用したUWBチップ（DWM1000）の軸を次のFig. \ref{UWB_axis}のように定義する．


\begin{figure}[H]
\begin{center}
\includegraphics[height=60mm]{./Fig2/UWB_axis.png}
\caption{UWB chip axis.}
\label{UWB_axis}
\end{center}
\end{figure}

\noindent
チップから発せられる電波の指向性をDWM1000を製造するDecaWave社がデータシート\cite{n}において公開している．$x, y, z$軸周りにおける電波の指向性をFig. \ref{UWB_angle_x}からFig. \ref{UWB_angle_z}に示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=50mm]{./Fig2/UWB_angle_x.png}
\caption{Directivity of radio wave around $x$ axis\cite{n}.}
\label{UWB_angle_x}
\end{center}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[height=50mm]{./Fig2/UWB_angle_y.png}
\caption{Directivity of radio wave around $y$ axis\cite{n}.}
\label{UWB_angle_y}
\end{center}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[height=50mm]{./Fig2/UWB_angle_z.png}
\caption{Directivity of radio wave around $z$ axis\cite{n}.}
\label{UWB_angle_z}
\end{center}
\end{figure}

\noindent
3つの図を考慮すると，UWBチップの平面方向から垂直な方向，つまりFig. \ref{UWB_axis}の$x$軸の方向が通信対象を向けば電波強度を確保できることがわかる．そこで，Fig. \ref{UWB_case_angle}に示すアンカ用のホルダを3Dプリンタにより製作した．


\begin{figure}[H]
\begin{center}
\includegraphics[height=70mm]{./Fig2/UWB_case_angle.png}
\caption{UWB module holder considering radio wave directivity.}
\label{UWB_case_angle}
\end{center}
\end{figure}

\noindent
これを用いる前は，実験室の壁面に対して垂直にアンカを貼り付けていたが，このホルダを用いることでチップ垂直方向をクアッドロータの方向に向けることが可能である．これを垂直な壁面に貼り付けることで$30^\circ$のオフセット角を与えることができる．そしてこのホルダをアンカの4つ分使用し，実験室の4隅に取り付け，アンカで取り囲まれる空間内でタグを動かし，測距を行った．アンカの電波の強い方向がタグの方を向くため，マルチパスは発生しなくなると考えられたが，結果はFig. \ref{UWB_out}と同様に発散した値を計測した．したがってアンカの取り付け角度によってマルチパスの発生を抑えることは困難であるという結論を得た．

次に行ったのがプログラムによる発散値の処理を行い，発散値をロギングしない方法である．処理の内容は，アンカとタグとで通信を行い，計測した距離データを1度メモリ内にバッファする．そして，次の距離データが送られてきた際にバッファした距離と比較し，閾値を上回る変化があった場合にはその直近のデータを破棄し，1つ前のデータを採用するというものである．距離データの発散は，条件にもよるが数秒に1サンプル程度の頻度で発生し，連続したサンプル同士が両方発散することはない．したがって，この処理の方法により真値からかけ離れた値のみを適切に破棄することが可能である．閾値としては，クアッドロータが1 m/sの速度で水平面内を飛行可能であると仮定し，測距の1ループ内で移動不可能な距離を閾値として設定した．このプログラムによる処理を行い，発散値を回避した測距結果をFig. \ref{UWB_cali}に示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=60mm]{./Fig2/UWB_cali.png}
\caption{Ranging result avoiding outlier.}
\label{UWB_cali}
\end{center}
\end{figure}

\noindent
実験方法はFig. \ref{UWB_out}の実験を行った際と同様である．アンカを動かした際の振動による値のずれは生じているが，処理する前の結果と比べて適切に発散値を回避することができた．


%\subsubsection{更新周波数の改善のアプローチ（マイコンスペックの比較，周波数グラフの比較）}

\subsection{オプティカルフローセンサ}
\subsubsection{オプティカルフローセンサの原理}
先行研究では，クアッドロータの位置や速度などの状態量をUWBモジュール及びIMUを用いて推定していた．しかし，UWBモジュールのアンカを4つ用いた際に得られる距離データの更新周期は10 Hzと遅く，クアッドロータが高速度で動いた際や$x, y$平面内において振動が生じた際に更新周期が不十分であった．そこで，更新周期の遅さを補うために本研究では新たにオプティカルフローセンサを搭載した位置推定および位置制御システムを構築した．オプティカルフローセンサとは，カメラで撮影した画像の特徴点の移動量から，移動する物体の速度や移動量を算出可能なセンサである．オプティカルフローはPython環境にてOpenCVなどのモジュールを用い，パーソナルコンピュータを使用し計算することも多い．例としては，あらかじめ撮影した車の写真から車速を割り出すことなどに使用される．そして，オプティカルフローセンサは画像の撮影から移動量の算出までを，センサボードに搭載したチップで行うことが可能である．そして，それらのセンサ値をマイコンにより適切に処理することにより，搭載したロボットなどの速度や移動量を得ることができる．また，オプティカルフローセンサの例としては光学式マウスなどが挙げられる．光学式マウスはオプティカルフローセンサにより，マウスの移動量を算出している．オプティカルフローセンサを用いたクアッドロータの位置制御に関する研究\cite{q}\cite{r}においてもクアッドロータにこのセンサを搭載し，クアッドロータの位置保持制御や目標点まで移動させる位置制御を行っている．本研究で採用したオプティカルフローセンサモジュールの外観をFig. \ref{optical_flow}に示す．


\begin{figure}[H]
\begin{center}
\includegraphics[height=50mm]{./Fig2/optical_flow_with_axis.png}
\caption{Optical Flow Sensor Module\cite{s}.}
\label{optical_flow}
\end{center}
\end{figure}

\noindent
このモジュールはオプティカルフローセンサとしてPMW3901のチップを搭載しており，それに加え距離センサとしてVL53L0x ToFセンサを搭載している．2つのセンサが同一の基板上に搭載されているため汎用性が高いモジュールであり，オプティカルフローセンサはSPI通信，距離センサは$\textrm{I}^{2}\textrm{C}$通信をそれぞれ用いるため，配線が少なくてすむ．また，図より大きさもとても小型であることがわかり，積載量の限られたクアッドロータなどにおいても容易に搭載可能である．後述するが，同一基板上に搭載された距離センサはオプティカルフローセンサから得た値を補正するのに用いられる．


\subsubsection{センサのキャリブレーション}
オプティカルフローセンサから得られる速度のキャリブレーション方法について述べる．まず，オプティカルフローセンサから得られる値は撮影した画像の変化から得られる特徴点の移動量，つまり単位は距離ではなくピクセルである．例えば，ある物体の上でクアッドロータが100 mm移動したとする．その際，移動距離が同じであっても，クアッドロータの高さが低ければピクセル数の変化量は大きいが，高さが2倍になった場合，ピクセル数の変化量は半分になる．それを表した図がFig. \ref{opt_distance}である．

\begin{figure}[H]
\begin{center}
\includegraphics[height=70mm]{./Fig2/opt_distance.png}
\caption{Difference in Sensor Value Due to Difference in Quad-Rotor Height.}
\label{opt_distance}
\end{center}
\end{figure}

\noindent
そこで，オプティカルフローセンサから得られるピクセル数の変化量と距離センサから得られる距離を乗算し，適切な定数を掛けることで真の移動距離を算出することが可能である．なお，飛行体の高度とオプティカルフローセンサから得られる値の関係はオプティカルフローセンサを利用した位置推定に関する研究\cite{s}に詳しい記述がある．またその論文を参考にすると，センサが値を取得し，次の値を取得するまでをセンサの1ループと考えると，その1ループ中に移動した距離は次式で表せる．

\begin{align}
\textrm{Moving distance} = \left( \frac{\textrm{Sensor value} \times \textrm{Altitude}}{\textrm{Sensor's resolution in pixels} \times \textrm{Scalar}}\right) \times 2.0 \times \tan \left(\frac{\textrm{Field of view}}{2.0} \right)
\label{2-3-1}
\end{align}

\noindent
Sensor valueはオプティカルフローセンサから得た値であり，Altitudeは距離センサから得た地面までの距離である．Field of viewはオプティカルフローセンサが撮影可能な画角であり，Sensor's resolution in pixelsは撮影画像の画素数つまり解像度である．この2つの値はセンサ固有のものであり，それらを次のTable. \ref{sensor_value}に示す．


\begin{table}[H]
 \caption{Sensor characteristic value.}
  \label{sensor_value}
 \begin{center}
  \begin{tabular}{|c||c|}
   \hline
    FOV [$^{\circ}$]&  42 \\
   \hline
  Resolution [pixel]& 30 $\times$ 30       \\
   \hline 
  \end{tabular}
 \end{center}
\end{table}

\noindent
Scalarは定数であり，このScalarの値を次のキャリブレーションにより求めた．式(\ref{2-3-1})から得られるのは，あくまでも1ループ中に動いた距離，つまり速度である．物体が移動した真の速度を用いてこのScalarの値を求めることは可能であるが，速度を外部のセンサなどを用いて求めるのはシステムが複雑になる．そこで，速度ではなく真の移動距離を用いてこのScalarの値を求めることにした．過去のある時点から現在までに移動した距離を算出するにはセンサから得られた速度に対してマイコンが1ループにかかる処理時間を掛け，それを足し合わせることで可能である．つまり，センサ値を積分することである．そこで次のような実験を行った．次のFig. \ref{opt_experiment1}，Fig. \ref{opt_experiment2}のようにある高さに対し，センサが下を向くように固定し，1方向のみレールにより自由度を与える．レールに既知の距離を複数点マークし，その距離分だけセンサを動かした．



\begin{figure}[H]
  \begin{center}
    \begin{tabular}{cc}

      \begin{minipage}[t]{0.5\hsize}
        \begin{center}
         \includegraphics[height=55mm]{./Fig2/opt_experiment1.png}
	  \caption{Narrow band signal with reflections.}
	　\label{opt_experiment1}
        \end{center}
      \end{minipage}

      \begin{minipage}[t]{0.5\hsize}
        \begin{center}
          \includegraphics[height=55mm]{./Fig2/opt_experiment2.png}
          \caption{Ultra wide band signal with reflections.}
	   \label{opt_experiment2}
        \end{center}
      \end{minipage}

    \end{tabular}
  \end{center}
\end{figure}


\noindent
センサ値を積分して得られた距離データと真の距離を最小二乗法により近似することでScalarを求めた．センサを動かした距離はTable \ref{Sensor_Value_and_Moved_Distance}に示すように0 mmから800 mmまでの200 mm間隔である．また，固定したセンサの床からの高さは775 mmである．センサ値の値は3回試行した結果の平均値である．移動距離と計測値の関係を次のTable \ref{Sensor_Value_and_Moved_Distance}に，これらの関係をグラフにしたものをFig. \ref{opt_cali}に示す．




\begin{table}[H]
 \caption{Sensor values and moving distance.}
 \label{Sensor_Value_and_Moved_Distance}
 \begin{center}
  \begin{tabular}{|c|c|}
   \hline
    Moving distance [mm] & Average of sensor value [-]\\
   \hline\hline
   0 & 0 \\
   \hline 
   200 & 3061 \\
   \hline
   400 & 6165\\
   \hline
   600 & 9198 \\
   \hline
   800 & 12296 \\
   \hline
  \end{tabular}
 \end{center}
\end{table}



\begin{figure}[H]
\begin{center}
\includegraphics[height=60mm]{./Fig2/opt_cali.png}
\caption{Relationship between sensor value and moving distance.}
\label{opt_cali}
\end{center}
\end{figure}

\noindent
近似直線からわかるように，センサ値と移動距離の関係は線形的に近似可能である．センサの床からの距離，つまり式(\ref{2-3-1})中のAltitudeは距離センサ得られる値を用いたが，Altitudeの値を真値(775 mm)に固定して計算しても結果は同様のものであった．また，この結果はFig. \ref{optical_flow}に示す$y$軸方向の移動の実験におけるものであったが，同様に$x$軸方向における実験も行ったが結果は同様のものであった．したがって各軸におけるScalarの値は同一の値を採用した．以上の検証よりScalarが求まったため，オプティカルフローセンサよりセンサ座標系における速度が得られるようになった．

次にセンサ座標系のワールド座標系への変換方法について述べる．前述した方法で得られる値はセンサ座標系における速度であり，クアッドロータの位置や速度をワールド座標系内で推定し，位置を制御するにはセンサ座標系をワールド座標系へ変換する必要がある．まず，Fig. \ref{quad_fig}にワールド座標系と機体座標系の関係を示す．


\begin{figure}[H]
\begin{center}
\includegraphics[height=60mm]{./Fig2/quad_fig.png}
\caption{Relationship between the world coordinate system and the quad-rotor coordinate system.}
\label{quad_fig}
\end{center}
\end{figure}


\noindent
ワールド座標系は地上の任意の点を原点とする地上に固定されている座標系であり，r-frameと表す．そして，機体座標系は機体重心を原点とし，機体前方を$y_b$，右方向を$x_b$，上方向を$z_b$とした座標系であり，b-frameと表す．また，3次元の姿勢表現としてオイラー角を用いた表現を行う．r-frameとb-frameの回転角の関係は$\phi, \theta, \psi$の3つのオイラー角を用いて表現できる．$\phi, \theta, \psi$はそれぞれ$x, y, z$軸周りにおける回転であり，ピッチ角，ロール角，ヨー角と呼ばれる．もし，機体がワールド座標系内にて$z$軸周りに$\psi$だけ回転した場合，オプティカルフローセンサから得られる速度を$\psi$を用いてワールド座標系での速度へ変換する必要がある．オプティカルフローセンサから得られる$x, y$軸それぞれの速度を$\textbf{v}_o = [v_{ox}, v_{oy}]^T$とし，変換した後のワールド座標系内での速度を$\textbf{v}_r = [v_{rx}, v_{ry}]^T$とすると，それらの関係は$z$軸周りにおける回転行列を用いて次式により表せる．

\begin{align}
\label{2-3-2}
\begin{split}
\left[
    \begin{array}{c}
      v_{rx}  \\
      v_{ry}
    \end{array}
\right]
&= 
\left[
    \begin{array}{cc}
      \cos\psi & -\sin\psi \\
      \sin \psi & \cos\psi
    \end{array}
\right]
\left[
	\begin{array}{cc}
		v_{ox}  \\
		v_{oy}
	\end{array}
\right] \\
&=
\left[
    \begin{array}{c}
      v_{ox}\cos\psi  -v_{oy}\sin\psi \\
      v_{ox}\sin\psi + v_{oy}\cos\psi
    \end{array}
\right]
\end{split}
\end{align}\

\noindent
$z$軸周りの回転角度は地磁気センサ及び角速度センサを使用して推定したものを用いる．推定方法は次章にて説明する．式(\ref{2-3-1})を用いることでクアッドロータのワールド座標系内での速度をオプティカルフローセンサにより得られるようになった．


\subsection{UWBモジュール，IMU，距離センサのみを用いた従来の位置推定システム}
まず，先行研究において開発され，本研究において改良したクアッドロータの外観をFig. \ref{quad-rotor}に示す．また詳細な仕様をTable \ref{Quad-rotor specifications}に示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=90mm]{./Fig2/quad-rotor.png}
\caption{Quad-rotor equipped with UWB module, IMU and distance sensor.}
\label{quad-rotor}
\end{center}
\end{figure}


\begin{table}[H]
 \caption{Quad-rotor specifications.}
 \label{Quad-rotor specifications}
 \begin{center}
  \begin{tabular}{|c||c|}
   \hline
   Total weight [kg] & 0.65 \\ 
   \hline
   Height [mm]& 110 \\
   \hline
   Width [mm]& 250 \\
   \hline
   Depth [mm]& 250 \\
   \hline
   Propeller size [inch] & 5$\times$3\\
   \hline
   Maximum flight time [min]& 10 \\
   \hline
    KV value [rpm/V]& 2633 \\
   \hline
   Buttery capacity[mAh]& 1800 \\
   \hline
  \end{tabular}
 \end{center}
\end{table}

\noindent
先行研究からの改良点は新たにフライトコントローラを追加した点である．次のFig. \ref{system}に先行研究にて開発された位置推定アルゴリズムを用いた位置制御用のシステムを示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/system.png}
\caption{System configuration of sensors.}
\label{system}
\end{center}
\end{figure}

\noindent
本クアッドロータでは姿勢角や位置などの推定値の計算や位置制御のための姿勢角の計算などは全てLinux OS搭載のコンピュータ，Raspberry Piを用いて行う．センサボードはNAVIO2を搭載しており，加速度センサ及び角速度センサの機能を有している．UWBモジュールはSPI通信でArduino Pro Miniと通信しており，4つのアンカから集めた距離データを集約しUART通信でRaspberry Piに送っている．距離センサの値は$\textrm{I}^2\textrm{C}$通信を用いてRaspberry Piに送っている．先行研究においては，推定した自己位置や姿勢を基に姿勢角を制御する際，フライトコントローラとしてRaspberry Piを用い，Integral Backstepping制御を適用することでクアッドロータの位置制御を行っていた．しかし，その制御システムでは姿勢角制御のループ周波数が遅く，位置制御が振動的になり目標の位置にクアッドロータを収束させることが不可能であった．そこで，本研究ではその姿勢角制御の遅さを補うため，推定値の演算を行うコンピュータとクアッドロータの姿勢角制御を行うコンピュータを分離させた．推定値の演算や位置の偏差から目標姿勢角を計算することなどは従来通りRaspberry Piを用いて行うが，姿勢角制御はmRobotics社が製作しているPixracer\cite{t}と呼ばれるフライトコントローラを用いて行うように仕様を変更した．Fig. \ref{pixracer}にPixracerの外観を示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/pixracer.png}
\caption{Appearance of Pixracer\cite{t}.}
\label{pixracer}
\end{center}
\end{figure}

\noindent
このボードは6個のPWM出力ピンを備えており，重量も約11 gと軽量のため，小型の航空機や地上機などのコントローラとして採用されることが多い．加速度センサ，角速度センサ，地磁気センサ，気圧センサなどの各種センサやWi-Fiモジュールも搭載されるため，汎用性が高いコントローラである．また，GPSも搭載されており，GPS環境下であればオートフライトも可能である．本研究にてこのコントローラを採用した理由は非常に小型・軽量であるため，従来のクアッドロータに追加で搭載した場合にも，大きな改良を施さなくて良い点やファームウェアやプログラムがオープンソースなため，自身で内部の仕様を変更可能であることなどが理由である．また，何よりも大きな利点は高速なCPUを搭載し，完成度の高い姿勢角制御のアルゴリズムが使用可能なため，自身で構築した姿勢角制御アルゴリズムよりも精度良くクアッドロータの姿勢角を制御可能なことである．Fig. \ref{system}に示すようにフライトコントローラはUSBを介してRaspberry Piと接続されており，Raspberry Piが計算した目標姿勢角をフライトコントローラに送ることで，クアッドロータを目標姿勢に追従させることが可能である．Fig. \ref{system_core_design}に位置制御のブロック線図を示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=100mm]{./Fig2/system_core_design.png}
\caption{Block diagran of positon control system.}
\label{system_core_design}
\end{center}
\end{figure}

\noindent
手順としてはまず，UWBモジュールのタグと各アンカとの距離($d_1$から$d_4$)，距離センサから得た地面との距離($d_h$)，センサボードから得た加速度($a_x, a_y, a_z$)，角速度値($\omega_x, \omega_y, \omega_z$)をミキシングし，拡張カルマンフィルタを適用することで位置($x, y, z$)，速度($v_x, v_y, v_z$)，姿勢角($\phi, \theta, \psi$)を推定する．そして，目標座標と現在座標の偏差をPID制御器に通すことで目標姿勢角（$\phi_d, \theta_d, \psi_d$）を求める．そしてそれをフライトコントローラへ送信可能なサーボ信号(Ch1からCh4)へと変換し，フライトコントローラへ送ることでクアッドロータの姿勢角及びスラストが制御され，目標位置へと機体が移動する流れである．

次に拡張カルマンフィルタを用いてクアッドロータの位置を推定する方法について述べる．まず，姿勢角や位置を推定するのに拡張カルマンフィルタを用いる理由について述べる．初めに姿勢角についてであるが，姿勢角はカルマンフィルタの状態方程式側において角速度センサの値を積分して角度に変換することで算出する．しかし，積分した際に角速度センサに乗ったノイズまで積分するため，推定した角度が時間とともにドリフトする．また，観測方程式側では加速度センサから得られる値よりヨー角以外の姿勢角を直接計算できる．その際，積分を行わないため算出値がドリフトをすることはないが，クアッドロータが並進移動した際に余計な加速度がかかるため，正確な角度を計算できなくなる．それら2種類のセンサの不利な点を補うのに今回のようなカルマンフィルタを用いた姿勢角の推定は有効である．次に位置推定についてであるが，位置推定の計算は状態方程式側において加速度センサの値を2回積分して求めた移動距離と観測方程式側においてUWBモジュールを用いて求めた距離を用い，マルチラテレーションの手法にて計算した座標をミキシングすることで位置を推定している．加速度センサからは数1000 Hzにて加速度を得られるため，位置推定値も変化に対する応答性が高いが，姿勢角を求めた際と同様に積分するため値がドリフトする．また，UWBを用いた推定ではドリフトしない絶対座標が得られるが，UWBアンカを4つ使用した際の更新周波数が10 Hzと遅いため，クアッドロータが高速で運動した際には応答性の悪い推定値になる．このように位置推定においても，お互いのセンサ不利な点を補えるためカルマンフィルタは有効である．UWBモジュールを用いてクアッドロータの位置を推定する方法にマルチラテレーションの手法を用いていると述べたが，これについて説明する．マルチラテレーションとは座標が既知の3つ以上の固定局と移動局間の距離を求め，アルゴリズムに基づいて計算することで，移動局の座標を求める手法のことである．身近な例では，複数個のGPS衛星とGPS移動局との距離よりモジュールの位置を割り出すのに使用されている．位置を計算する手法は数多く存在し，マルチラテレーションに関する研究\cite{u}\cite{v}に詳しい解法が載っている．Fig. \ref{UWB_positioning2}にマルチラテレーションにおける模式図を再び示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/UWB_positioning2.png}
\caption{Position relationship between Anchors and Tag.}
\label{UWB_positioning2}
\end{center}
\end{figure}

\noindent
アンカが固定局のことであり，その絶対座標は既知である．そして，タグは座標未知の移動局であり，クアッドロータに搭載されている．このタグの位置を求める．タグ及びアンカの座標とモジュール間の距離の関係は次式により表せる．

\begin{align} 
\label{2-4-1}
\left[
    \begin{array}{c}
      d_{1} \\
      d_{2} \\
      d_{3} \\
      d_{4}
    \end{array}
\right]
=
\left[
    \begin{array}{c}
      \sqrt{(\hat{x}-x_{1})^{2}+(\hat{y}-y_{1})^{2}+(\hat{z}-z_{1})^{2}} \\
      \sqrt{(\hat{x}-x_{2})^{2}+(\hat{y}-y_{2})^{2}+(\hat{z}-z_{2})^{2}} \\
      \sqrt{(\hat{x}-x_{3})^{2}+(\hat{y}-y_{3})^{2}+(\hat{z}-z_{3})^{2}} \\
      \sqrt{(\hat{x}-x_{4})^{2}+(\hat{y}-y_{4})^{2}+(\hat{z}-z_{4})^{2}} 
    \end{array}
\right]
\end{align}\



\noindent
方程式(\ref{2-4-1})を$\hat{x}, \hat{y}, \hat{z}$について解くことによりタグの三次元位置座標を求めることが可能である．なお，この式は後に出てくる拡張カルマンフィルタの観測方程式の一部である．次に拡張カルマンフィルタにおける状態方程式を見ていく．機体の速度ベクトル$\textbf{v}_\textbf{r} = [v_x, v_y, v_z]^T$と機体の位置ベクトル$\textbf{p}_\textbf{r} = [x_r, y_r, z_r]^T$ の関係は次式で表せる．

\begin{align}
\label{2-4-2}
\frac{d}{dt}\textbf{p}_\textbf{r}=\textbf{v}_\textbf{r}
\end{align}

\noindent
速度ベクトルの時間微分$\frac{d}{dt} \bf{v_r}$は加速度センサより得られるセンサ値$\textbf{a}_\textbf{b} = [a_x, a_y, a_z]^T$と回転行列$\textbf{R}$を用いて次式で表せる．


\begin{align}
\label{2-4-3}
\frac{d}{dt}\textbf{v}_\textbf{r} = \textbf{R}\textbf{a}_\textbf{b} - \textbf{g}_\textbf{r}
\end{align}

\noindent
ここで，ワールド座標系において重力は$z$軸負方向に重力加速度: $g$分だけ作用するため，$\textbf{g}_\textbf{r}$は$\textbf{g}_\textbf{r} = [0, 0, -g]^T$と定義できる．また，Fig. \ref{quad_fig}におけるr-frameとb-frame間の回転行列$\textbf{R}_\textbf{r}^\textbf{b}$は次式で定義される．

\begin{align}
\label{2-4-4}
\begin{split}
\textbf{R}_\textbf{r}^\textbf{b}(\phi,\theta,\psi)
&=
\left[
    \begin{array}{ccc}
      1 & 0 & 0\\
      0 & \cos\phi & \sin\phi \\
      0 & -\sin\phi & \cos\phi
    \end{array}
\right]
\left[
    \begin{array}{ccc}
      \cos\theta & 0 & -\sin\theta\\
      0 & 1 & 0 \\
      \sin\theta & 0 & \cos\theta
    \end{array}
\right]
\left[
    \begin{array}{ccc}
      \cos\psi & \sin\psi & 0\\
      -\sin\psi & \cos\psi & 0 \\
      0 & 0 & 1
    \end{array}
\right]
\\
&=
\left[
    \begin{array}{ccc}
      \cos\theta\cos\psi & \cos\theta\sin\psi & -\sin\theta\\
      \sin\phi\sin\theta\cos\psi & \sin\phi\sin\theta\sin\psi+\cos\phi\cos\psi & \sin\phi\cos\theta \\
      \cos\phi\sin\theta\cos\psi & \cos\phi\sin\theta\sin\psi-\sin\phi\cos\psi & \cos\phi\cos\theta
    \end{array}
\right]
\end{split}
\end{align}

\noindent
そしてオイラー角$\Theta = [\phi, \theta, \psi]^T$の時間微分と角速度センサより得られる機体角速度$\boldmath{\omega} = [p, q, r]^T$の関係は次式で表せる．


\begin{align}
\label{2-4-5}
\frac{d}{dt}\Theta = \textbf{W} \omega
\end{align}\

\noindent
なお，$\textbf{W}$は先行研究\cite{e}より

\begin{align}
\label{2-4-6}
\textbf{W}=
\left[
    \begin{array}{ccc}
      1 & \sin\phi\tan\theta & \cos\phi\tan\theta\\
      0 & \cos\phi & -\sin\phi \\
      0 & \sin\phi /\cos\theta & \cos\phi / \cos\theta
    \end{array}
\right]
\end{align}\

\noindent
である．状態ベクトルを$\textbf{x} = [\Theta, \textbf{p}_\textbf{r}, \textbf{v}_\textbf{r}]^T$と定義し，式(\ref{2-4-2})(\ref{2-4-3})(\ref{2-4-5})をまとめると次のようになる．

\begin{align}
\label{2-4-7}
\dot{\textbf{x}}(t)=\textbf{f}(\textbf{x}(t))
\end{align}\

\noindent
ただし$\textbf{f}(\cdot)$は


\begin{align} 
\label{2-4-8}
\textbf{f}(\textbf{x}(t))
=
\left[
    \begin{array}{c}
      \textbf{W}\omega \\
      \textbf{v}_\textbf{r} \\
      \textbf{R}\textbf{a}_\textbf{b} - \textbf{g}_\textbf{r} 
    \end{array}
\right]
\end{align}

\noindent
角速度センサ及び加速度センサから得られる出力値に含まれる観測ノイズ$\delta\omega=[\delta p,\delta q, \delta r]^{T}$及び$\delta \textbf{a}_\textbf{b}=[\delta a_{x},\delta a_{y}, \delta a_{z}]^{T}$を考慮すると式(\ref{2-4-7})は次式のようになる．

\begin{align}
\label{2-4-9}
\dot{\textbf{x}}(t)=\textbf{f}(\textbf{x}(t))+\textbf{B}\textbf{v}
\end{align}

\noindent
ただし，$\textbf{B},\textbf{v}$はそれぞれ


\begin{align} 
\label{2-4-10}
\textbf{B}
=
\left[
    \begin{array}{ccc}
      \textbf{0}_{3\times 3}&\textbf{0}_{3\times 3}&\textbf{I}_{3\times 3} \\
      \textbf{I}_{3\times 3}&\textbf{0}_{3\times 3}&\textbf{I}_{3\times 3}
    \end{array}
\right]^{T},\quad
\textbf{v}=[\delta p,\delta q, \delta r,\delta a_{x},\delta a_{y}, \delta a_{z}]^{T}
\end{align}\

\noindent
である．さらにオイラー法を用いて式(\ref{2-4-9})を離散化すると

\begin{align}
\label{2-4-11}
\textbf{x}(t+1)=\textbf{f}_{t}(\textbf{x}(t))+\textbf{B}_{t}\textbf{v}
\end{align}\

\noindent
ただし

\begin{align}
\label{2-4-12}
\textbf{f}_{t}(\textbf{x}(t))=\textbf{x}(t)+\textbf{f}(\textbf{x}(t))\Delta t, \quad \textbf{B}_{t}=\textbf{B}\Delta t
\end{align}\

\noindent
である．ここで$\Delta t$はサンプリング周期である．

次に観測方程式について見ていく．観測値はUWBモジュールから得られる距離データ，加速度センサデータ，角速度センサデータ，距離センサデータ及びフライトコントローラであるPixracerが推定したヨー角($\psi$)をそれぞれ採用した．
まず，加速度センサ値を用いた角度の算出である．加速度おセンサから得られるセンサ値$\textbf{a}_\textbf{b}$と重力ベクトル$\textbf{g}_\textbf{r}$の関係は回転行列$\textbf{R}$を用いて次のようになる．

\begin{align}
\label{2-4-13}
\begin{split}
\left[
    \begin{array}{c}
      a_{x} \\
      a_{y} \\
      a_{z}
    \end{array}
\right]
&=
\left[
    \begin{array}{ccc}
      \cos\theta\cos\psi & \cos\theta\sin\psi & -\sin\theta\\
      \sin\phi\sin\theta\cos\psi & \sin\phi\sin\theta\sin\psi+\cos\phi\cos\psi & \sin\phi\cos\theta \\
      \cos\phi\sin\theta\cos\psi & \cos\phi\sin\theta\sin\psi-\sin\phi\cos\psi & \cos\phi\cos\theta
    \end{array}
\right]
\left[
    \begin{array}{c}
      0\\
      0 \\
      -g
    \end{array}
\right]\\
&=
\left[
    \begin{array}{c}
      g\sin\theta\\
      -g\cos\theta\sin\phi\\
      -g\cos\theta\cos\phi
    \end{array}
\right]
\end{split}
\end{align}\

\noindent
式(\ref{2-4-13})の最終項を見ると，$\psi$つまりヨー角成分が現れていないことがわかる．つまり加速度センサのみではヨー角を推定することはできず，そのため今回はヨー角の推定に角速度センサの値とPixracerから得られるヨー角をミキシングしている．ここで観測行列を$\textbf{y}(t) = [a_x, a_y, a_z, d_1, d_2, d_3, d_4, d_h, \psi_{pix}]^T$とおき，式(\ref{2-4-1})，(\ref{2-4-13})と合わせると


\begin{align}
\label{2-4-14}
\textbf{y}(t)=\textbf{h}_{t}(\textbf{x}(t))
\end{align}

\noindent
ただし$\textbf{h}(\cdot)$は

\begin{align} 
\label{2-4-15}
\textbf{h}_{t}(\textbf{x}(t))
=
\left[
    \begin{array}{c}
       g\sin\theta\\
      -g\cos\theta\sin\phi\\
      -g\cos\theta\cos\phi\\
      \sqrt{(x-x_{1})^{2}+(y-y_{1})^{2}+(z-z_{1})^{2}} \\
      \sqrt{(x-x_{2})^{2}+(y-y_{2})^{2}+(z-z_{2})^{2}} \\
      \sqrt{(x-x_{3})^{2}+(y-y_{3})^{2}+(z-z_{3})^{2}} \\
      \sqrt{(x-x_{4})^{2}+(y-y_{4})^{2}+(z-z_{4})^{2}} \\
	z \\
	\psi
    \end{array}
\right]
\end{align}\

\noindent
である．なお$d_h$は距離センサから得られた地面までの距離，$\psi_{pix}$はPixracerが推定したヨー角の値である．式(\ref{2-4-15})に加速度センサ，UWBモジュール，距離センサ，Pixracerからの出力に含まれるノイズ$[\delta a_{x}, \delta a_{y}, \delta a_{z}]^{T},\ [\delta d_1, \delta d_2, \delta d_3, \delta d_4]^{T},\ \delta d_{h},\ \delta \psi_{pix}$を考慮すると観測方程式は


\begin{align}
\label{2-4-16}
\textbf{y}(t)=\textbf{h}_{t}(\textbf{x}(t))+\textbf{w}
\end{align}\

\noindent
となる．ただし$\textbf{w}$は

\begin{align}
\label{2-4-17}
\textbf{w}=[\delta a_{x}, \delta a_{y}, \delta a_{z}, \delta d_1, \delta d_2, \delta d_3, \delta d_4, \delta d_{h}, \delta \psi_{pix}]^{T}
\end{align}

\noindent
以上より状態方程式(\ref{2-4-11})及び観測方程式(\ref{2-4-16})が導出できた．この離散プロセスモデルに対して2.1節にて示した拡張カルマンフィルタを適用することで位置推定アルゴリズムを得ることができる．





\subsection{従来の構成にオプティカルフローセンサも加えた位置推定システム}
ここではオプティカルフローセンサの値も推定アルゴリズムに組み込んだ手法について説明する．前のセンサ構成(Fig. \ref{system})にオプティカルフローセンサボードも加えた構成をFig. \ref{system_2}に，オプティカルフローセンサも組み込んだブロック線図をFig. \ref{system_core_design2}に示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=100mm]{./Fig2/system_2.png}
\caption{Configuration of sensors with optical flow sensor board.}
\label{system_2}
\end{center}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[height=100mm]{./Fig2/system_core_design2.png}
\caption{Block diagran of positon control system.}
\label{system_core_design2}
\end{center}
\end{figure}

\noindent
図からわかるようにオプティカルフローセンサボードとマイコン（Teensy LC）が新たに加わった．ここで，なぜマイコンを2つ（Arduino Pro Mini，Teensy LC）用いているかの理由を説明する．UWBモジュール（DWM1000）及びオプティカルフローセンサ（PMW3901）はSPI通信を用いてマイコンと通信する．SPI通信はマスタ側とスレイブ側が4線で通信する通信規格であり，スレイブの数が複数あっても1つのマイコンでそれらを処理することが可能である．したがって，Fig. \ref{system_2}に示すArduino Pro Mini1つで3つのセンサ（PMW3901, VL53L0X, DWM1000）の値を処理することを考えた．しかし，実際はPMW3901とDWM1000の2つのセンサ間の相性が悪く，同時に2つのセンサの値を取得することが不可能であった．したがって，オプティカルフローセンサボードの値を処理するマイコン（Teensy LC）とUWBモジュールの値を処理するマイコン（Arduino Pro Mini）を分離し，別々に値を取得してから1つのマイコン（Teensy LC）に値をまとめ，UART通信でRaspberry Piに送る本構成を組んだ．また，Teensy LCであるが，このマイコンはArduino Pro Miniと異なり，1つのマイコンで複数のUART通信を行うことが可能\cite{w}であり，図のようにArduino Pro Mini及びNAVIO2の2種類のボードと通信を行う必要があったためこのマイコンを採用するに至った．

次にオプティカルフローセンサの値も拡張カルマンフィルタを組み込んだ式を示していく．このアルゴリズムにおいても状態方程式は式(\ref{2-4-11})と同じものを用いる．つまり，状態方程式側にて，加速度センサの積分値を用いてクアッドロータの変位を推定し，角速度センサの値を用いて姿勢角を推定する．観測方程式であるが加速度センサ値，UWBモジュールから得た値，距離センサ値，Pixracerから得た値を用いることは変わらず，そこにオプティカルフローセンサから得た速度値が加わった．つまり観測行列は$\textbf{y}(t) = [a_x, a_y, a_z, d_1, d_2, d_3, d_4, d_h, \psi_{pix}, v_{rx}, v_{ry}]^T$と表される．ここで$v_{rx}$と$v_{ry}$は式(\ref{2-3-1})で表されるヨー角回転を補正した値である．そして，観測方程式は


\begin{align}
\label{2-4-18}
\textbf{y}(t)=\textbf{h}_{t}(\textbf{x}(t))
\end{align}\

\noindent
となり，$\textbf{h}(\cdot)$は

\begin{align} 
\label{2-4-19}
\textbf{h}_{t}(\textbf{x}(t))
=
\left[
    \begin{array}{c}
       g\sin\theta\\
      -g\cos\theta\sin\phi\\
      -g\cos\theta\cos\phi\\
      \sqrt{(x-x_{1})^{2}+(y-y_{1})^{2}+(z-z_{1})^{2}} \\
      \sqrt{(x-x_{2})^{2}+(y-y_{2})^{2}+(z-z_{2})^{2}} \\
      \sqrt{(x-x_{3})^{2}+(y-y_{3})^{2}+(z-z_{3})^{2}} \\
      \sqrt{(x-x_{4})^{2}+(y-y_{4})^{2}+(z-z_{4})^{2}} \\
	z \\
	\psi \\
	v_x \\
	v_y
    \end{array}
\right]
\end{align}\

\noindent
である．前と同様に各種センサから得られるノイズを考慮すると観測方程式は

\begin{align}
\label{2-4-20}
\textbf{y}(t)=\textbf{h}_{t}(\textbf{x}(t))+\textbf{w}
\end{align}\

\noindent
となり，$\textbf{w}$は

\begin{align}
\label{2-4-21}
\textbf{w}=[\delta a_{x}, \delta a_{y}, \delta a_{z}, \delta d_1, \delta d_2, \delta d_3, \delta d_4, \delta d_{h}, \delta \psi_{pix}, \delta v_{rx}, \delta v_{ry}]^{T}
\end{align}

\noindent
である．以上より新たな構成においても観測方程式が導出できた．これら状態方程式，観測方程式を前節と同様に拡張カルマンフィルタに適用することでオプティカルフローセンサも組み込んだ位置推定アルゴリズムを得ることができる．



\newpage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% 位置制御用クアッドロータの開発 %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{位置制御用クアッドロータの開発}
2.4節で示したクアッドロータは先行研究から利用されてきたものであり，本研究から新たにフライトコントローラ（Pixracer）やオプティカルフローセンサを搭載するに当たって積載物の重量が増加し，推力不足が懸念された．そして，クアッドロータの推力に余裕が生まれると，機体の応答性が向上し，位置制御の精度が高くなると考えた．そこで，推力の高い新たなクアッドロータのシステムを構築した．その新たに構築したクアッドロータをFig. \ref{quad-rotor2_front}，Fig. \ref{quad-rotor2_back}に示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=85mm]{./Fig2/quad-rotor2_front.png}
\caption{Front side of quad-rotor.}
\label{quad-rotor2_front}
\end{center}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[height=70mm]{./Fig2/quad-rotor2_back.png}
\caption{Back side of quad-rotor.}
\label{quad-rotor2_back}
\end{center}
\end{figure}

\noindent
図からわかるようにクアッドロータ上面にマイコンやメインコンピュータであるRaspberry Piを配置し，下面にフライトコントローラやオプティカルフローセンサボードを配置した．先行研究から使用してきたクアッドロータの場合にはフライトコントローラを上面に配置していたために重心が上がってしまい，不安定であった．したがって新たに構築したこのクアッドロータは下側にコントローラを配置し，重心が上がらないように配慮した．そして，次のTable \ref{New quad-rotor specifications}に詳細な仕様を示す．


\begin{table}[H]
 \caption{New quad-rotor specifications.}
 \label{New quad-rotor specifications}
 \begin{center}
  \begin{tabular}{|c||c|}
   \hline
   Total weight [kg] & 1.05 \\ 
   \hline
   Height [mm]& 200 \\
   \hline
   Width [mm]& 443 \\
   \hline
   Depth [mm]& 443 \\
   \hline
   Propeller size [inch] & 8$\times$4.5\\
   \hline
   Maximum flight time [min]& 10 \\
   \hline
    KV value [rpm/V]&  920\\
   \hline
   Buttery capacity[mAh]& 2650 \\
   \hline
  \end{tabular}
 \end{center}
\end{table}

\noindent
モータやバッテリなど飛行に必要な部品以外に追加で数百gほど搭載可能なスラストが出せるように部品選定を行った．モータの電圧やプロペラの種類にもよるが，最高で約200 gの追加スラストを生み出すことが可能な構成である．また，総飛行時間は約10分であるが，高いパフォーマンス状態で飛行可能な時間は約5分である．






\newpage
\section{位置推定アルゴリズムの精度評価}
\subsection{従来推定アルゴリズムを用いた位置推定の精度評価}
この章では前章にて説明した位置推定アルゴリズムを用い，クアッドロータの位置を推定し，その推定精度の評価を行う．まず位置推定実験に使用した実験環境を次の図に示す．なお，本実験ではクアッドロータは飛行させず，床に置いた静止状態で目標点における位置を推定した．


\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/experiment_field.png}
\caption{Laboratory used for position estimation and position control experiments.}
\label{experiment_field}
\end{center}
\end{figure}

\noindent
まず，クアッドロータの位置を推定する領域を取り囲む形で4つのUWBアンカをFig. \ref{experiment_field}に示すように設置した．アンカはFig. \ref{anchor_zoom}に示すようにカメラ用の三脚の頂点に固定した．また，アンカを設置した位置の絶対座標をTable \ref{Absolute position of target UWB anchors}に示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=60mm]{./Fig2/anchor_zoom.png}
\caption{Laboratory used for position estimation and position control experiments.}
\label{anchor_zoom}
\end{center}
\end{figure}



\begin{table}[H]
 \caption{Absolute position of target UWB anchors.}
 \label{Absolute position of target UWB anchors}
 \begin{center}
  \begin{tabular}{|c|c|c|c|}
   \hline
    & $x$ position [m] & $y$ position [m] & $z$ position [m] \\
   \hline\hline
   Anchor1 &  -5.460 & 2.698 & 1.763\\
   \hline 
   Anchor2 &  5.460 & 2.698 & 1.763\\
   \hline
   Anchor3 &  5.460 & -2.698 & 1.763\\
   \hline
   Anchor4 &  -5.460 & -2.698 & 1.763\\
   \hline
  \end{tabular}
 \end{center}
\end{table}

\noindent
そして，本実験での実験手順を以下に示す．まず，実験室の床に対し，目標点として与える点の真値を可能な限り精度良くマークした．次のTable \ref{Relative coordinates of target points}にその4点の目標値の相対座標を示す．なお，Fig. \ref{experiment_field}において，実験領域に衝撃吸収用のウレタンマットが敷かれているが，この位置推定実験の際には敷かれていないため，マットは真値に対し影響を与えない．

\begin{table}[H]
 \caption{Relative coordinates of target points.}
 \label{Relative coordinates of target points}
 \begin{center}
  \begin{tabular}{|c|c|c|}
   \hline
    & $x$ position [m] & $y$ position [m] \\
   \hline\hline
   Point0 (Origin) &  0.00 & 0.00 \\
   \hline 
   Point1           &  4.00 & 0.00 \\
   \hline
   Point2           &  4.00 & -3.00 \\
   \hline
   Point3           &  0.00 & -3.00 \\
   \hline
  \end{tabular}
 \end{center}
\end{table}

\noindent
次にクアッドロータの左手前の足が床にマークしたPoint0と重なるようにクアッドロータを床に置く．そして，プログラム内にて座標の並行移動を行い，その一番初めにクアッドロータを接地した点を相対座標系における原点（Point0）としてキャリブレーションを行う．その点において，数十秒間クアッドロータを放置し，次の目標点（Point1）へと手で持って移動させる．Point1においても同様に数十秒間放置した．この動作を他の残り2点でも同様に行い，各点の静止状態における相対座標を，前に示したオプティカルフローセンサを用いない従来の推定手法により推定した．その推定結果を次のFig. \ref{position_verification_2_copy}に示す．




\begin{figure}[H]
\begin{center}
\includegraphics[height=100mm]{./Fig2/position_verification_2_copy.png}
\caption{Position estimation results when the quad rotor is stationary using the conventional estimation method.}
\label{position_verification_2_copy}
\end{center}
\end{figure}

\noindent
図中における赤い点がそれぞれの目標点であり，青い線が推定結果を表している．初めにキャリブレーションを行ったPoint0以外の3点において数cmから数10 cmほどの定常偏差が生じているが，いずれの点においても誤差1 m以内の精度で位置を推定できていることがわかる．また，点間の移動の過程において，推定された座標の線が直線的でないのは，移動の際に目標となる基準線を与えず，目標点のみ移動の際の指標として与えたためである．目標点同士を線で結び，その上をトレースできれば，結果はより直線に近づくと考えられる．





\subsection{センサの種類及びカルマンフィルタの分散値が位置推定精度に与える影響の考察}
この章では先行研究において提案された手法を用いて位置推定を行った結果と，本研究において提案するオプティカルフローセンサも用いた手法を用いて位置推定を行った結果を数値シミュレーションを用いて比較する．また，後者におけるシミュレーションでは，カルマンフィルタにおけるセンサの分散値を変化させ，それが推定結果にどのような影響を与えるかも考察する．まず，シミュレーションに用いるためのセンサ値を実際の実験を通してロギングした．実験方法は床に描いた二等辺三角形の頂点及び線上を，台に固定したクアッドロータがトレースする形で動かし，その際のそれぞれのセンサ値をロギングした．ロギングしたセンサ値はIMU，UWBモジュール，距離センサ，オプティカルフローセンサの値である．また，床面上の線をトレースするのは，クアッドロータにFig. \ref{laser}のように取り付けたレーザポインタから光を下向きに照射し，それが線をなぞるように台を動かすことで実現した．


\begin{figure}[H]
\begin{center}
\includegraphics[height=70mm]{./Fig2/laser.png}
\caption{Laser pointer attached for the purpose of tracing a line drawn on the floor.}
\label{laser}
\end{center}
\end{figure}

\noindent
また，設置したUWBアンカの絶対座標をTable \ref{Absolute position of UWB anchors_2}に，床面に描いた二等辺三角形の頂点の相対座標をTable \ref{Relative coordinates of target points_2}に示す．

\begin{table}[H]
 \caption{Absolute position of UWB anchors.}
 \label{Absolute position of UWB anchors_2}
 \begin{center}
  \begin{tabular}{|c|c|c|c|}
   \hline
    & $x$ position [m] & $y$ position [m] & $z$ position [m] \\
   \hline\hline
   Anchor1 &  -1.00 & 1.50 & 0.73\\
   \hline 
   Anchor2 &    1.00 & 1.50 & 0.73\\
   \hline
   Anchor3 &    1.00 & -1.50 & 0.73\\
   \hline
   Anchor4 &  -1.00 & -1.50 & 0.73\\
   \hline
  \end{tabular}
 \end{center}
\end{table}



\begin{table}[H]
 \caption{Relative coordinates of target points.}
 \label{Relative coordinates of target points_2}
 \begin{center}
  \begin{tabular}{|c|c|c|}
   \hline
    & $x$ position [m] & $y$ position [m] \\
   \hline\hline
   Point0 (Origin) &  0.00 & 0.00 \\
   \hline 
   Point1           &  1..00 & 0.00 \\
   \hline
   Point2           &  0.00 & 1.00 \\
   \hline
   Point3           &  -1.00 & 0.00 \\
   \hline
  \end{tabular}
 \end{center}
\end{table}


\noindent
二等辺三角形の底辺の中点を相対座標系の原点とし，クアッドロータを最初に設置した地点としてキャリブレーションを行う．クアッドロータをPoint0からPoint3まで順に動かし，最後にPoint0に戻した．また，各点においてクアッドロータを10秒間ずつ静止させた．以上の実験を通して集めたデータを数値計算ソフトであるMatlabを用いて作製した位置推定プログラムに対して適用し，位置推定の計算をオフラインの環境で行った．ここで，拡張カルマンフィルタを含むカルマンフィルタにおいて調整可能なパラメータは主に共分散行列の初期値及び観測方程式における各センサの分散値である．数値シミュレーションにおいて初期値は変えず，シミュレーションに使用するセンサの種類及び，それぞれのセンサの分散値を変化させ，それの結果を見ていく．次の表に各シミュレーションにおいて使用したセンサの種類及び，分散値を示す．



\begin{table}[H]
 \caption{Type of used sensors and variance values.}
 \label{Type of used sensors and variance values}
 \begin{center}
  \begin{tabular}{|c|c|c|c|}
   \hline
                  & Accelerometer  &  UWB module & Optical flow sensor   \\
   \hline\hline
   Simulation1 &  0.4    & 0.02   & -        \\
   \cline{2-4}
                   &   0.004 & 0.01 & 0.0006  \\
   \hline 
   Simulation2 &    0.4 & 0.02 & -       \\
   \cline{2-4}
                   &    0.004     &    0.000001    &     0.06     \\
   \hline
   Simulation3 &    0.4    & 0.02 & - \\
   \cline{2-4}
                   &    0.004 & 0.1 &  0.0006 \\
   \hline
  \end{tabular}
 \end{center}
\end{table}

\noindent
シミュレーション1から3において，加速度センサ及びUWBモジュールのみの場合はそれらの分散値を変更せず，3種類のセンサを用いる場合のみ分散値を変更した．各シミュレーションにおける結果を次に示す．それぞれのシミュレーションにおいて，青色の線がUWBモジュールと加速度センサの観測値のみフュージョンしたもの，橙色はUWBモジュール，加速度センサ，オプティカルフローセンサの3種類をフュージョンしたもの，黄色はオプティカルフローセンサから得られた速度値を単純に積分して足し合わせたものである．なお，シミュレーション1においてはPoint2付近における拡大図も合わせて示す．






\begin{figure}[H]
\begin{center}
\includegraphics[height=100mm]{./Fig2/result1.png}
\caption{Result of simulation1.}
\label{result1}
\end{center}
\end{figure}


\begin{figure}[H]
\begin{center}
\includegraphics[height=100mm]{./Fig2/result1_up.png}
\caption{Enlarged view of Fig. \ref{result1}.}
\label{result1_up}
\end{center}
\end{figure}


\begin{figure}[H]
\begin{center}
\includegraphics[height=100mm]{./Fig2/result3.png}
\caption{Result of simulation2.}
\label{result3}
\end{center}
\end{figure}




\begin{figure}[H]
\begin{center}
\includegraphics[height=100mm]{./Fig2/result4.png}
\caption{Result of simulation3.}
\label{result4}
\end{center}
\end{figure}



\noindent
シミュレーション1は3種類のセンサの分散値をトライアンドエラーで調整し，オプティカルフローセンサの値を積分した際に生じるドリフトやUWBモジュールの測距誤差が原因の推定値の分散が少なくなるようにして求めた結果である．また，シミュレーション2はUWBモジュールの分散値を小さくし，UWBモジュールから得られる観測値の影響を大きくした結果である．シミュレーション3はそれとは逆にオプティカルフローセンサの分散値を小さくし，オプティカルフローセンサから得られる観測値の影響を大きくした．次にそれぞれの結果について考察していく．まず，分散値の調整を行ったシミュレーション1であるが，青色の線は，目標点間の移動する過程において波打っていることがわかる．また，拡大図においても，目標点付近において青色の線は値の分散が生じている．しかし，橙色の線は移動中の過程も線が揺らぐことなく直線的であり，目標点付近においても分散が生じることなく点での曲がり角が明確に出ていることがわかる．黄色の線は直線的であり分散も見られないが，目標点付近において他の2線とは離れた位置に定常値を取っている．青色のUWBモジュールと加速度センサのみを用いた場合には，UWBモジュールの測距値に分散が含まれることが原因で推定値にも分散が生じたが，橙色の線ではオプティカルフローセンサの効果によりその分散を打ち消せているため，こういった直線的で分散の少ない結果を得ることができた．また，黄色の単純積分値ではUWBモジュールを用いた座標の補正が効かないため，このように積分値がドリフトし，全体的に傾いた図形になった．次にシミュレーション2であるが，橙色の線はUWBモジュールの影響を大きくしたため，分散が大きくなりこのような直線的ではない結果となった．しかし，座標の補正はUWBモジュールの効果により働いているため，目標値の座標は青色の線と橙色の線で一致していることがわかる．最後にシミュレーション3においてオプティカルフローセンサの影響を強くした橙色の結果は黄色の線同様，滑らかではあるが，UWBモジュールの座標補正が弱くなり，ドリフトした結果となっている．これらのシミュレーション結果より，分散値の値を適切に調整した上で，既存の位置推定システムにオプティカルフローセンサの観測値も組み込むことにより，座標をUWBモジュールの観測値より推定しつつ，オプティカルフローセンサの効果で分散の少ない推定値を得ることが可能であるという結論を得た．


\newpage
\section{位置制御アルゴリズムの評価}
前章までは各種センサを用いたクアッドロータの位置推定方法について述べてきた．この章では実際にクアッドロータを飛行させ，提案した位置制御手法の精度を確認する．

\subsection{位置制御手法}
本節ではFig. \ref{system_core_design}及びFig. \ref{system_core_design2}中に示される目標座標と推定座標の偏差からクアッドロータの位置を制御する手法について述べる．これから述べる手法は先行研究\cite{e}やクアッドロータの位置制御に関する研究\cite{x}\cite{y}などの手法を参考にした．推定した座標と目標座標との偏差より仮想入力の値を次のように設定する．

\begin{align}
\label{5-1-1}
\begin{split}
&U_{x} = k_{px}(x_d - \hat{x} ) + k_{dx}(\dot{x}_d - \dot{\hat{x}} ) + k_{ix} \int_0^t (x_d - \hat{x} ) d\tau   \\
&U_{y} = k_{py}(y_d - \hat{y} ) + k_{dy}(\dot{y}_d - \dot{\hat{y}} ) + k_{iy} \int_0^t (y_d - \hat{y} ) d\tau  
\end{split}
\end{align}

\noindent
$x$軸，$y$軸はそれぞれ機体座標系ではなく，ワールド座標系における軸を表している．式(\ref{5-1-1})からわかるように仮想入力の値は偏差を用いたPIDコントローラより計算できる．これらの入力値を用いると，ピッチ角（$\phi$）及びロール角（$\theta$）の目標値は以下の式により計算できる．

\begin{align}
\label{5-1-2}
\begin{split}
&\phi^{des} = \frac{1}{g} (U_x \sin \psi - U_y  \cos \psi)  \\
&\theta^{des} = \frac{1}{g} (U_x \cos \psi + U_y  \sin \psi)
\end{split}
\end{align}

\noindent
これらの得た値をフライトコントローラであるPixracerが受け取れるPWM信号に変換した後，コントローラに送信することで，クアッドロータの各ロータの回転数が制御され，姿勢角が追従する流れである．またヨー角（$\psi$）に関しては，飛行開始時に置いたクアッドロータの機首が向いている方向を目標角度とし，推定した現在角度との偏差において単純なPID制御器を組むことにより機首の向きが回転しないように制御を行う．


\subsection{ステレオカメラを用いた位置測定システム}
\subsubsection{位置計測システムの原理及び構築}
クアッドロータの位置を制御した場合，位置が精度良く制御できているかを確認するため，それの指標として位置の真値が必要である．飛行体や地上移動機に関わらず，移動型のロボットの真値を計測するにはFig. \ref{VICON}に示すVICON\cite{z}などno
モーションキャプチャシステムを用いることが多い．しかし，こういったシステムは機材だけで数百万円の価格であり，設置費を含むと数千万円に上ることもある．また，Fig. \ref{VICON_room}のように一度室内に環境構築を行うと，システムを他の部屋に移動させることが困難である．したがって，価格がVICONよりも安価であり，必要に応じてシステムを移動させられることなどの利点があることから本論文ではステレオカメラを用いた位置の計測システムを構築した．Fig. \ref{camera_with_chess}に環境構築したステレオカメラシステムを示す．

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}

      \begin{minipage}[t]{0.5\hsize}
        \begin{center}
         \includegraphics[height=45mm]{./Fig2/VICON.jpg}
	  \caption{VICON\cite{z}.}
        \label{VICON}
        \end{center}
      \end{minipage}

      \begin{minipage}[t]{0.5\hsize}
        \begin{center}
          \includegraphics[height=45mm]{./Fig2/VICON_room.jpg}
          \caption{The room where VICON is installed\cite{A}.}
          \label{VICON_room}
        \end{center}
      \end{minipage}

    \end{tabular}
  \end{center}
\end{figure}


\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/camera_with_chess.png}
\caption{Installed stereo camera and chessboard.}
\label{camera_with_chess}
\end{center}
\end{figure}

\noindent
システムの大まかな構成は二台の高速度カメラからなるステレオカメラとデスクトップPCである．使用したカメラはPoint Grey社（現FLIR社）製のGrasshopper3(GS3-U3-32S4C-C)\cite{B}である．Fig. \ref{high-speed_camera}に外観を，仕様をTable \ref{high-speed_camera_tab}に示す．また，画像保存に使用したデスクトップPCの仕様をTable \ref{PC_tab}に示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=50mm]{./Fig2/high-speed_camera.jpg}
\caption{High-speed camera(GS3-U3-32S4C-C).}
\label{high-speed_camera}
\end{center}
\end{figure}



\begin{table}[H]
 \caption{High-speed camera specifications.}
 \label{high-speed_camera_tab}
 \begin{center}
  \begin{tabular}{|c||c|}
   \hline
   Maximum resolution (H$\times$V)[pixel]& 2048$\times$1536 \\ 
   \hline
   Maximum frame rate [fps]& 121 \\
   \hline
   Image sensor& Sony IMX252 \\
   \hline
   Sensor type& CMOS \\
   \hline
   Shutter type&Global shutter\\
   \hline
   Interface & USB3.1 Gen 1 \\
   \hline
   Weight [g] & 90 \\
   \hline
  \end{tabular}
 \end{center}
\end{table}




\begin{table}[H]
 \caption{High-speed camera specifications.}
 \label{PC_tab}
 \begin{center}
  \begin{tabular}{|c||c|}
   \hline
   CPU & intel Core i7 \\ 
   \hline
   Motherboard & ASUS Z270F GAMING \\
   \hline
   Graphic & GTX1050Ti \\
   \hline
   RAM [GB] & 64 (DDR4) \\
   \hline
   OS & Windows 10 $\times$64  \\
   \hline
   Storage　[GB] & 256 (SSD) $+$ 2000 (HDD)  \\
   \hline
   Software & FlyCapture2  \\
   \hline
  \end{tabular}
 \end{center}
\end{table}

\noindent
Table \ref{high-speed_camera_tab}からわかるように，カメラの性能を最大限引き出した際の仕様は，解像度が2048$\times$1536とフルHDを超える解像度であり，フレームレートも100 fpsを上回る121 fpsにて画像または動画を撮影可能である．しかし，Table \ref{PC_tab}に示すPCを用いてもカメラ2台を用いた状態で，1024$\times$768の解像度，100 fpsが限界であった．したがって本システムではこの環境で出せる最高解像度，最高fpsのこの設定で画像を撮影した．なお，撮影した画像のフォーマットは圧縮率75\%のJPEGである．画像計測を用いた位置や角度の検出では撮影された画像中のマーカーを追跡することによりそれを実現する．VICONでは移動物体に取り付けられた反射マーカーに赤外線を照射することで反射した光の重心を求めることで位置や角度を検出する．本システムでは赤外線を照射しないため，それ自体が赤外光を放出する赤外線LEDをクアッドロータの位置検出用のマーカーとして採用した．Fig. \ref{LED_with_quad1}，Fig. \ref{LED_with_quad2}に2種類のクアッドロータに取り付けられた赤外線LEDを示す．


\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}

      \begin{minipage}[t]{0.5\hsize}
        \begin{center}
         \includegraphics[height=55mm]{./Fig2/LED_with_quad1.png}
	  \caption{Old quad rotor with infrared LED.}
        \label{LED_with_quad1}
        \end{center}
      \end{minipage}

      \begin{minipage}[t]{0.5\hsize}
        \begin{center}
          \includegraphics[height=50mm]{./Fig2/LED_with_quad2.png}
          \caption{New quad rotor with infrared LED.}
          \label{LED_with_quad2}
        \end{center}
      \end{minipage}

    \end{tabular}
  \end{center}
\end{figure}


\noindent
先行研究から使われてきたクアッドロータ（Fig. \ref{LED_with_quad1}）には2台のカメラ間で同期が取れるようにリレーが取り付けられている．メインコンピュータであるRaspberry Piから信号を送ることでLEDの点灯を制御可能なため，光ったタイミングを検出することで2台のカメラのマーカー検出タイミングを揃えることができる．先行研究においてはこの方法でカメラ間同期を取っていた．そして，新しく本論文にて新しく開発したクアッドロータは同期用のリレーが付いていない．これの理由について説明する．今回用いた高速度カメラにはPCへのデータ送信用のコネクタ以外に外部へ信号を送ることや受け取ることが可能なコネクタが備わっている．これを用い，片方のプライマリカメラからもう片方のセカンダリカメラへと同期用の信号を送り，その信号をトリガにしてセカンダリカメラは撮影を開始できるため，2台間の同期が取れた状態で画像を撮影可能である．本論文では新たにこの同期方法を採用したため，Fig. \ref{LED_wiith_quad2}のクアッドロータにはリレーが備わっていない．クアッドロータに搭載したLEDマーカーの光はカメラで撮影可能であるが，画像中でLEDの光のみを浮き上がらせて検出が容易になるようカメラにはFig. \ref{infrared_filter}に示す赤外線透過フィルタ（IR-80）を装着した．赤外線LEDを光らせた状態でこのレンズにより撮影した画像をFig. \ref{high-speed_image}に示す．



\begin{figure}[H]
\begin{center}
\includegraphics[height=50mm]{./Fig2/infrared_filter.jpg}
\caption{Infrared longpass filter.}
\label{infrared_filter}
\end{center}
\end{figure}



\begin{figure}[H]
\begin{center}
\includegraphics[height=50mm]{./Fig2/high-speed_image.png}
\caption{Image taken of glowing infrared LED through filter.}
\label{high-speed_image}
\end{center}
\end{figure}

\noindent
フィルタを通すことにより，LEDの光のみを浮き上がらせられているのがわかる．次にステレオカメラを用いた位置計測のアルゴリズムについて簡単に説明する．ここで説明する手法は先行研究\cite{e}や詳解OpenCV\cite{C}に詳しい方法が載っている．Fig. \ref{stereo_camera}に示すように左右に並んだ2台のカメラで同じ対象物を撮影したとする．

\begin{figure}[H]
\begin{center}
\includegraphics[height=90mm]{./Fig2/stereo_camera.png}
\caption{Definition of stereo camera coordinates.}
\label{stereo_camera}
\end{center}
\end{figure}

\noindent
ここでは2台のカメラの画像平面が同一平面上にあり，光軸が平行であり，同じ焦点距離$f$を持つとする．また，カメラの中心間距離を$L$とする．その位置にカメラを設置した状態で同じ対象物を撮影すると，左側のカメラでは$x_l$，右側のカメラでは$x_r$の座標の画像平面にそれぞれ画像が投影される．この座標の差$d$が視差と呼ばれ，


\begin{align}
\label{}
d = x_l - x_r 
\end{align}

\noindent
と表せる．そして，図において三角形の相似の関係を用いると


\begin{align}
\label{}
\frac{L-d}{Z-f} = \frac{L - (x_l - x_r)}{Z - f} = \frac{L}{Z}
\end{align}

\noindent
と表わせ，この式を変形することで

\begin{align}
\label{}
Z = \frac{fL}{x_l - x_r}
\end{align}

\noindent
となり，対象物までの距離$Z$を求めることができる．同様に$x$軸方向$y$軸方向についても

\begin{align}
\label{}
X = \frac{x_l L}{x_l - x_r}, \ Y = \frac{y_l L}{x_l - x_r} = \frac{y_l L}{x_l - x_r}
\end{align}

\noindent
となり，対象物の位置を求められる．以上よりステレオカメラを用いて対象物の位置$(X, Y, Z)$を求める方法が導出できた．しかし，実際には2台のカメラの画像平面が同一平面になるよう置くことや光軸が平行になるように置くことは物理的に不可能である．そこで，行うのがステレオカメラのキャリブレーションである．Fig. \ref{camera_with_chess}に示したチェスボードを2台のカメラで撮影し，アルゴリズムにしたがって計算することで，カメラ間の位置関係を表す並進ベクトル$T$及び回転行列$R$を算出可能である．それらに加え，カメラレンズの歪みやレンズの取付誤差が起因する画像の歪みを補正するためのカメラパラメータも同様のチェスボードを撮影した画像から得ることができる．これらのパラメータを用い，先に示した方法で計算を行うことでクアッドロータの位置を測定した．なお，これらの演算は全てPython2のモジュールとして提供されるモジュール，OpenCVの機能を用いて行った．

\subsubsection{奥行き誤差の検証}
ここで，ステレオカメラを用いた位置計測における奥行き誤差について議論する．Fig. \ref{error_stereo}に設定する状況を考える．ステレオ画像での計測精度は画像中の1画素が実際にどのくらいの長さに対応するかで決まる． つまり，カメラの解像度，対象物までの距離，カメラ間距離によって変わる． また，画像平面中の画像が投影される画像素子は，それ自体が大きさを持っているため，実際の空間中では計測対象点はある範囲内であることしか特定できない． その特定可能な最小の範囲がステレオカメラにおける計測誤差となる．


\begin{figure}[H]
\begin{center}
\includegraphics[height=90mm]{./Fig2/error_stereo.png}
\caption{Error in z direction of stereo camera.}
\label{error_stereo}
\end{center}
\end{figure}


\noindent
図における$\delta x$が横方向誤差であり，$\delta z$が奥行き誤差である．また，図に示す$L'$を計算のために導入する．まず，三角形の相似より

\begin{align}
\label{}
\rm{Pixel} : \frac{L'}{2} = f : l
\end{align}

\noindent
が言える．これを変形し

\begin{align}
\label{ste_1}
L' = \frac{2 \rm{Pixel}}{f}
\end{align}

\noindent
となる．同様に相似より

\begin{align}
\label{ste_2}
\delta z = \frac{L'l}{L - L'}
\end{align}

\noindent
が言える．式(\ref{ste_1})を式(\ref{ste_2})に代入し，整理すると

\begin{align}
\label{}
\delta z = \frac{2 l^2 \rm{Pixel}}{fL - 2l \rm{Pixel}}
\end{align}

\noindent
となり，奥行き誤差が導出できる．同様に$x$方向，$y$方向誤差も相似より計算できるが，$\delta z$に比べて極めて小さく，無視できるため割愛する．奥行き誤差$\delta z$が100 mm以下になるように次の表のパラメータを用いて$l$を計算すると，$l　= 8.959 \ \rm{m}$という結果を得たため，カメラから飛行するクアッドロータまでの距離が8 m以下になるように設定して実験を行うこととする．








\subsection{従来の推定アルゴリズムによる制御性能の評価}
2.4節にて示した従来の位置推定方法及び5.1節にて示した位置制御手法を用いてクアッドロータの位置を制御する実験を行った．次の2つの実験で用いたクアッドロータはFig. \ref{quad-rotor}に示す従来機である．

\subsubsection{定点における位置保持実験}
ある目標点を目標値とし，クアッドロータが自律制御にてホバリングした際の精度を確認することを目的として，以下の実験を行った．まず，クアッドロータをアンカで取り囲まれた空間内の床面に置き，その位置が原点になるようにプログラム内で座標を平行移動させ，キャリブレーションを行う．キャリブレーション終了後，クアッドロータを手動制御にて離陸させる．飛行が安定した時点でモードを手動制御モードから自動制御モードへと切り替え，その際の推定された位置をロギングする．なお，この実験時にはクアッドロータのスロットルの制御はマニュアル操作にて行った．本実験における目標値は$(x, y) = (0, 0)$つまり，実験開始時にクアッドロータを置いた位置である．結果をFig. \ref{position_control_origin_2}に示す．




\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/position_control_origin_2.png}
\caption{Result of static position hold experiment.}
\label{position_control_origin_2}
\end{center}
\end{figure}

\noindent
図中の赤い点が目標値を示す．このグラフは自動制御モードに切り替えてから2分間の飛行をロギングしたものである．目標値からの標準偏差は0.083mであり，目標値からの最大偏差は0.406 mである結果を得た．先行研究においては，姿勢角制御の周波数が低いことが原因で位置制御が発散していた．しかし，フライトコントローラを新たに搭載し，位置制御と姿勢角制御を分けたことにより処理が軽くなったため，位置の発散が抑制され，このような結果を得ることができたと考えられる．



\subsubsection{複数点間を移動する位置制御実験}
次に複数の目標点を移動する位置制御実験を行った．複数の目標点を目標値とし，クアッドロータが自律制御にてホバリング及び目標点間の移動をした際の精度を確認することを目的とした実験である．使用したクアッドロータは前述の定点保持実験と同一の機体であり，位置推定方法も同様の方法である．実験方法を以下に示す．まず，クアッドロータを床面に置き，原点としてキャリブレーションを行う．そして手動制御で離陸させた後，安定した時点で自動制御モードに切り替える．ここまでの方法は前の実験と同様である．その後，目標値を手元の送信機より切り替え，複数点を移動させる．そして，その際の推定された位置をロギングする．目標値の座標を次のTable \ref{Absolute position of way points}に，実験結果をFig. \ref{point_to_point_2}に示す．

\begin{table}[H]
 \caption{Absolute position of way points.}
 \label{Absolute position of way points}
 \begin{center}
  \begin{tabular}{|c|c|c|}
   \hline
    & $x$ position [m] & $y$ position [m] \\
   \hline\hline
   Point0 (Origin) &  0.00 & 0.00 \\
   \hline 
   Point1           &  1.50 & -1.00 \\
   \hline
   Point2           &  -1.50 & 1..00 \\
   \hline
  \end{tabular}
 \end{center}
\end{table}





\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/point_to_point_2.png}
\caption{Result of point to point experiment.}
\label{point_to_point_2}
\end{center}
\end{figure}


\noindent
目標値が原点（Point0）の時，細かな振動はあるが，偏差の中心は目標値と一致していることがわかる．しかし，移動後の点Point1，Point2においては定常偏差が発生し，偏差の中心が目標値からずれていることがわかる．これの原因はUWBアンカの設置誤差が起因する位置推定誤差やUWBモジュールはモジュール間の距離が近くなると測距精度が悪くなることなどが考えられる．







\subsection{提案する推定アルゴリズムによる制御性能の評価}
次に，従来の推定方法及び，2.5節にて示した新たな推定手法の2種類の推定方法により位置制御の実験を行うことで，2つの推定方法による制御性能の違いを比較した．新たな推定手法では，オプティカルフローセンサの値も必要なため，用いた機体はFig. \ref{quad-rotor2_front}に示す新たに構築したクアッドロータである．実験内容は5.4.1節にて示したものと同様であり，1点を目標地点とする位置保持実験である．実験方法も同様であり，2種類の推定プログラムを実験試行毎に切り替えて位置制御を行った．まず，従来の推定手法による実験の結果2つを示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/withoutopt_1.png}
\caption{Position control result using conventional estimation method (trial 1).}
\label{withoutopt_1}
\end{center}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/withoutopt_2.png}
\caption{Position control result using conventional estimation method (trial 2).}
\label{withoutopt_2}
\end{center}
\end{figure}


\noindent
試行1では約18秒間，位置制御状態にて飛行していた．飛行制御の最後の方では大きく目標点から逸脱し，制御不能に陥ったため，制御を終了し，着地させた．試行2も同様に，位置制御を開始してから約28秒後には制御不能のため制御を終了した．次にオプティカルフローセンサも推定に組み込んだ結果を次に示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/withopt_1.png}
\caption{Position control results using an estimation method incorporating an optical flow sensor (trial3).}
\label{withopt_1}
\end{center}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/withopt_2.png}
\caption{Position control results using an estimation method incorporating an optical flow sensor (trial4).}
\label{withopt_2}
\end{center}
\end{figure}

\noindent
試行3は約60秒間，制御状態で飛行していた．しかし，本試行においても飛行制御中に不安定状態に陥り，制御を終了した．試行4は約90秒間制御状態であり，意図的に制御を終了するまで安定してホバリングを続け，最後まで制御不能状態にはならなかった．

次にこれらの結果を考察していく．まず，従来の推定方法を用いた試行1，2では安定した飛行制御が不可能であった．以前の機体の場合，5.4.1節で示した実験のように飛行制御の開始時から終了時点まで目標地点から大きく逸脱することなく制御可能であったが，新たに構築した機体の場合，それを達成することはできなかった．これの原因は各ロータの推力不足によるものと，位置制御におけるPIDゲインの調整不足によるものが考えられる．次節にて示すが，実験に使用したプロペラとロータの組み合わせをスラストメータにて推力を計測したところ，その推力が十分なものではなかった．したがって，各ロータ及びプロペラから発生する推力が不十分であり，姿勢角制御の応答性が悪くなり，位置制御の精度も低下したと考えられる．また，位置制御におけるPIDゲインは本機体においては調整を行わず，以前の機体と同じ値を採用した．しかし，新たな機体は重量や発生推力が以前の機体と異なるため，そのゲインが適切ではなく，このような位置制御精度の低さにつながったと言える．次に，オプティカルフローも位置推定に組み込んだ結果である試行3と4であるが，この試行では試行1，2と同じ機体を使用していたにも関わらず，前半2回に比べて安定した飛行制御が可能であった．これの理由は姿勢角応答の悪さをオプティカルフローセンサの推定周波数の速さが補正していたためであることや，UWBモジュールを及びIMUのみで行う推定精度の悪さをオプティカルフローセンサの値により補正できていたためであると考えられる．機体の姿勢角応答は以前の機体に比べ悪くなったが，オプティカルフローセンサも組み込んだことにより，クアッドロータの運動に対する推定の追従性が向上し，後半2回の制御性能が向上したと考えられる．また，4.2節にて示したようにオプティカルフローセンサが推定に組み込まれない場合は，推定値がUWBモジュールの測距誤差の影響で振動的になっていたが，オプティカルフローセンサが加わることでその振動を抑えられていた．したがって，本実験においても，そいうった推定値の振動成分が少なくなったため，機体が推定値に追従して振動することがなくなり，前半2回に比べて飛行が安定していたと考えられる．

次に5.2節にて説明したステレオカメラを用い位置計測を行ったものと推定値の比較結果を示す．次に示す結果は上実験の試行2のものである．

\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/stereo_estimated_x2.png}
\caption{Comparison of the position of the quad rotor measured by a system using a stereo camera with the estimated value.($x$-axis).}
\label{stereo_estimated_x2}
\end{center}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/stereo_estimated_y2.png}
\caption{Comparison of the position of the quad rotor measured by a system using a stereo camera with the estimated value.($y$-axis).}
\label{stereo_estimated_y2}
\end{center}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/stereo_estimated_z2.png}
\caption{Comparison of the position of the quad rotor measured by a system using a stereo camera with the estimated value.($z$-axis).}
\label{stereo_estimated_z2}
\end{center}
\end{figure}

\noindent
計測値と推定値は時刻同期されておらず，サンプリングレートも異なるため，時刻をずらすことによりタイミングの同期を図った．しかし，推定値のサンプリング間隔が不均一なため，時系列データの初めの方ではタイミングが合っていても，最後の方でずれた結果となってしまっている．また，結果からわかるように奥行方向である$x$方向の計測値に対しノイズが乗る結果を得た．したがって$x$方向の結果のみカットオフ周波数：3 Hzでローパスフィルタを掛けたものも合わせて示した．5.2.2節にて示したとおり，ステレオカメラは特性上カメラから見て奥行方向に誤差が生じやすいため，このように$x$方向にのみノイズが乗る結果となった．しかし，3方向とも2つのデータに同期は取れていないが，近い値を取っているため，クアッドロータに搭載した推定システムを用いて得られる推定座標は妥当なものであることが示された．




\subsection{ロータの推力測定}
次に，飛行実験に実際に用いたプロペラと予備用に用意したプロペラの同回転数時に発生させる推力の差を確認した．理由は飛行に使用したプロペラは十分な推力が発生しておらず，姿勢角制御に悪影響を与えていると考えたためである．飛行実験に使用したプロペラ1及び予備用のプロペラ2を次に示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=50mm]{./Fig2/prop1.jpg}
\caption{Propeller1.}
\label{prop1}
\end{center}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[height=50mm]{./Fig2/prop2.jpg}
\caption{Propeller2.}
\label{prop2}
\end{center}
\end{figure}


\noindent
どちらも直径8 inch，ピッチ4.5 inchの設計である．しかし，図より翼面積に大きな差があることがわかる．次の図に推力測定実験時の様子を示す．


\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/thrustmeter.png}
\caption{Configuration for measuring propeller thrust.}
\label{thrustmeter}
\end{center}
\end{figure}




\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/thrust_prop.png}
\caption{Propeller fixed to thrust meter.}
\label{thrust_prop}
\end{center}
\end{figure}

\noindent
まず，スラストメータに対しプロペラが装備されたロータを設置する．次に各回転数になるようスラストメータからPWM信号をESCに送り，ロータを回転させる．ロータの回転数（rpm）は図中のパルスカウンタを用いて確認した．そして各回転数における発生する推力をスラストメータから読み取った．推力は各回転数において3回ずつ計測し，それらの平均を取った．次の図に2種類のプロペラの各回転数における，計測した推力を示す．また，最小二乗法により近似した二次曲線も合わせて示す．


\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/thrust_2.png}
\caption{Thrust measurement results of two types of propellers.}
\label{thrust_2}
\end{center}
\end{figure}



\noindent
結果からわかるように，いずれの回転数においてもプロペラ1の推力の方がプロペラ2に比べて発生させる推力が低い．推力を$f$とし，回転数を$\omega$ [rpm]とすると，近似曲線の式はプロペラ1で

\begin{align}
f_1 = 5.98\times10^{-9} \omega^2
\end{align}

\noindent
となり，プロペラ2で

\begin{align}
f_2 = 9.94\times10^{-9} \omega^2
\end{align}


\noindent
となり，推力係数はプロペラ2がプロペラ1の1.67倍である結果を得た．直径，ピッチ共に同じ値にも関わらず，このような結果となったのは翼面積の影響が大きいと考えられる．新たに構築したクアッドロータを用いて行った飛行制御実験において，同じ従来の推定手法を用いた場合であっても位置制御性能が低下したのはこの推力不足によるものが大きいと考えられる．各ロータでの推力が十分でなかったため，姿勢角制御の応答性が悪くなり，前の実験のような結果になったと言える．

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% 結言 %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{結言}
本研究では非GPS環境における鋼構造物点検を目的とした自律飛行可能なクアッドロータの開発を行った．クアッドロータの自己位置推定にはUWBモジュール，IMU，距離センサの値を参照し，それらに拡張カルマンフィルタを適用することで位置を推定した．また，オプティカルフローセンサを新たに搭載し，位置推定及び位置制御の精度向上を図った．

まず，先行研究において未達成であった位置制御に取り組んだ．先行研究において，上記のUWB，IMU，距離センサを用いた構成にてクアッドロータの位置を推定することは達成されていた．しかし，メインコンピュータを用いてクアッドロータの姿勢角を制御する際，それの周波数が不十分であり，位置制御飛行中においてクアッドロータの位置が発散していた．そこで，新たに別のフライトコントローラを搭載し，位置推定用のコンピュータと姿勢角制御用のコンピュータを分け，演算負荷を軽くすることで，クアッドロータの位置を制御することが可能になった．先行研究から用いられてきたクアッドロータを使用した位置制御では定点を目標地点とする位置保持制御及び3点間を移動する制御を行った．まず，位置保持制御では，目標位置（原点）からの標準偏差が0.083 m，最大偏差が0.406 mである位置制御結果を得た．また，3点間を移動する制御では，移動後の点において定常偏差が発生したが，目標点を大きく逸脱することなく，安定した位置制御に成功した．

次に，上で行った位置制御において発生した$x-y$平面上でのクアッドロータの細かな振動を取り除くために新たにオプティカルフローセンサを搭載することを考えた．それに伴い，以前のクアッドロータでは搭載するスペースや推力が不足すると考えられため，発生可能な推力が大きく，センサなどが搭載可能な余剰スペースがある新たなクアッドロータを構築した．そのクアッドロータに対しオプティカルフローセンサを搭載し，実験したデータから位置推定の精度を確認するシミュレーションを行ったところ，位置推定の精度が向上し，オプティカルフローセンサの有効性を確認することができた．次に，新たな機体に対し，オプティカルフローセンサも位置推定に組み込んだ状態で位置制御を行った．その結果，オプティカルフローセンサの値を参照していない以前の推定手法を用いた場合よりも位置制御の精度は向上した．しかし，以前のクアッドロータにおいてオプティカルフローセンサの値を参照しない推定手法を用いた場合よりも位置制御の精度が向上する結果は得られなかった．理由としては，クアッドロータの変更に伴い，機体特性が変化したにも関わらず，位置制御用のゲインの調整が不十分であったことや，プロペラから発生する推力が不十分なため姿勢角制御の応答性が悪かったことなどが理由として挙げられる．実際に実験に用いたプロペラと予備に確保した別のプロペラの同回転数時における発生推力を確認したところ，発生する推力に大きな差があった．実験に使用したプロペラの推力係数は比較したプロペラの0.6倍であり，実験に使用したプロペラの選定が不十分であったことがわかった．

今後の課題としては，部品選定を適切に行なった上で推力が確実に発生させられる機体構成に改善し，位置制御ゲインや姿勢角制御ゲインをさらに調整する必要がある．また，位置の真値を計測するのに用いたステレオカメラは奥行方向の計測誤差が大きく，ローパスフィルタを通さなければ適切な値を得られなかった．したがって，カメラの数を増やすことやチェスボードの改良等によるキャリブレーション精度向上などを行うことで測定精度の向上を図る必要がある．さらに，本研究ではUWBモジュールのアンカの数が4つであり，計測可能な範囲や計測精度が限られていた．したがって，将来的にはUWBモジュールの計測周波数が低下しない工夫をした上でアンカの数を増やし，計測範囲の拡大を図る必要があると考えられる．





\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% 謝辞 %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{謝辞}
\addcontentsline{toc}{section}{謝辞}
この研究テーマを与えて下さり，またご指導ご鞭撻を下さった澤田祐一教授，東善之助教に感謝致します．また，加えて報告会において貴重な意見を下さったロボティクス研究室の飛行ロボットグループメンバやアドバイスを下さった研究室の皆様に感謝致します．加えて，学系横断型プロジェクトとして貴重なアドバイスを下さった知的構造システム学研究室の増田新先生や防振システム工学研究室の三浦奈々子先生に心より感謝を申し上げたいと思います．最後に，クアッドロータの飛行実験を行うに当たって貴重な部屋を貸して下さった産学公連携推進センターの皆様にも謝意を表します．






\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{thebibliography}{99}
\addcontentsline{toc}{section}{参考文献}


\bibitem{a}
国土交通省，道路構造物の現状（橋梁），\\
\url{http://www.mlit.go.jp/road/sisaku/yobohozen/yobo1_1.pdf}，2020/01/27閲覧．


\bibitem{b}
山田健太郎，木曽川大橋：トラス斜材の腐食による破断，\\
\url{http://www.kougiken.jp/04_seika/pdfsystem/66_talkin/66_06.pdf}，2020/01/27閲覧．


\bibitem{c}
日経コンストラクション，日本の木曽川大橋も崩落に至る最悪のシナリオがあった，\\
\url{https://tech.nikkeibp.co.jp/kn/article/knp/20071127/513741/}，2020/01/27閲覧．

\bibitem{d}
大阪市立大学　ロボット工学研究室，鋼橋検査ロボット・BIREM (研究紹介)，\\
\url{http://www.robotics.mech.eng.osaka-cu.ac.jp/study/BIREM/BIREM.html}，2020/01/27閲覧．


\bibitem{e}
赤堀俊輔，澤田祐一，東善之，鋼構造物点検用UAVの飛行制御に関する研究，京都工芸繊維大学工芸科学研究科機械設計学専攻修士論文，（2018）．


\bibitem{f}
Microdrones，\\
\url{https://www.microdrones.com/en/}，2020/01/27閲覧．

\bibitem{g}
ArduCopter，\\
\url{http://ardupilot.org/copter/index.html}，2020/01/27閲覧．

\bibitem{h}
PHANTOM SERIES，\\
\url{https://www.dji.com/jp/products/phantom}，2020/01/27閲覧．


\bibitem{i}
株式会社自律制御システム研究所，\\
\url{https://www.acsl.co.jp/products/}，2020/01/27閲覧．


\bibitem{j}
decaWave，\\
\url{https://www.decawave.com/products/dwm1000-module}，2020/01/27閲覧．

\bibitem{k}
足立修一，丸田一郎，カルマンフィルタの基礎，(2013)，99-110，東京電機大学出版局．


\bibitem{l}
ElectronicDesign，What’s The Difference Between Measuring Location By UWB, Wi-Fi, and Bluetooth?\\
\url{https://www.electronicdesign.com/technologies/communications/article/21800581/whats-the-difference-between-measuring-location-by-uwb-wifi-and-　
bluetooth}，2020/01/27閲覧．

\bibitem{m}
Global Interface Technologies，UWBとは，\\
\url{http://www.git-inc.com/uwb.html}，2020/01/27閲覧．

\bibitem{n}
DWM1000 Datasheet，\\
\url{https://www.decawave.com/wp-content/uploads/2018/09/dwm1000-datasheet-1.pdf}，2020/01/27閲覧．


\bibitem{o}
スイッチサイエンス　リチウムイオン電池1800mAh，\\
\url{https://www.switch-science.com/catalog/2507/}，2020/01/27閲覧．


\bibitem{p}
K. Guo, Z. Qiu, C. Miao, A. Zaini, C. Chen, W Meng, L. Xie, Ultra-Wideband-Based Localization for Quadcopter Navigation, 
Unmanned Systems, Vol. 4, No. 1, (2016), 23-34.

\bibitem{q}
S. Lange, Niko Sunderhauf, P. Protzel A Vision Based Onboard Approach for Landing and Position Control of an Autonomous Multirotor UAV in GPS-Denied Environments, International Conference on Advanced Robotics, (2009), 1-6.


\bibitem{r}
N. Gageik, M. Strohmeier, S. Montenegro, An Autonomous UAV with an Optical Flow Sensor for Positioning and Navigation, Int. j. adv. robot. syst., Vol. 10, (2013), 341.


\bibitem{s}
Kim, J \& Brambley, Dual Optic-flow Integrated Navigation for Small-scale Flying Robots, Australasian Conference on Robotics and Automation, (2007), 7.

\bibitem{t}
mRobotics, Pixracer, \\
\url{https://docs.px4.io/v1.9.0/en/flight_controller/pixracer.html}，2020/01/28閲覧．

\bibitem{u}
Federico Thomas and Lluís Ros, Revisiting Trilateration for Robot Localization, IEEE TRANSACTIONS ON ROBOTICS, VOL. 21-1, (2005),  93-99.

\bibitem{v}
D.E. Manolakis, Efficient Solution and Performance Analysis of 3-D Position Estimation by Trilateration, IEEE TRANSACTIONS ON AEROSPACE AND ELECTRONIC SYSTEMS, 32-4, (1996), 1239 - 1248. 

\bibitem{w}
PJRC Teensy LC，\\
\url{https://www.pjrc.com/teensy/teensyLC.html}，，2020/01/28閲覧．


\bibitem{x}
Zongyu Zuo, Quadrotor Trajecotry Tracking Control: A PD Control Algorithm, 2010 3rd International Conference on Computer and Electrical Engineering, 53-2,  (2013). 

\bibitem{y}
Murray L. Ireland, Aldo Vargas and David Anderson, A Comparison of Closed-Loop Performance of Multirotor Configurations Using Non-Linear Dynamic Inversion Control, Aerospace 2015, (2015), 325-352.

\bibitem{z}
VICON CAMERAS, \\
\url{https://www.vicon.com/hardware/cameras/}，2020/01/28閲覧．

\bibitem{A}
REALITY Studio Roppongi\\
\url{https://le.wrightflyer.net/solution/studio.html}，2020/01/28閲覧．

\bibitem{B}
エドモンド・オプティクス・ジャパン株式会社 USB3.0カメラ FLIR GS3-U3-32S4 カラー\\
\url{https://www.edmundoptics.jp/p/gs3-u3-32s4c-c-1-18-inch-grasshopper-usb-30-
color-camera/33122/}，2020/01/28閲覧．

\bibitem{C}
G. Bradski, A. Kaehler, 松田晃一，詳解OpenCVコンピュータビジョンライブラリを使った画像処理・認識，(2012)，377-387，423-432，オーム社．


\end{thebibliography}


\end{document}