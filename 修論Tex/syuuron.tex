%%%%%%%%%%%%%%%%%%%%����%%%%%%%%%%%%%%%%%%%%
\documentclass[a4paper,12pt]{jarticle}	
%!TEX encoding = UTF-8 Unicode

%%%%%%%%%%%%%%%%%%%%�p�b�P�[�W�̓ǂݍ���%%%%%%%%%%%%%%%%%%%%
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{bm}
\usepackage[dvipdfmx]{graphicx}
\usepackage{ascmac}
\usepackage{amsthm}
\usepackage{bmpsize}
\usepackage{subfig}
\usepackage{nidanfloat}
\usepackage{here}
\usepackage{comment}
\usepackage{url}
\usepackage{amsmath} 			
\usepackage{amssymb}			
\usepackage{mathrsfs}
\usepackage[titletoc, title]{appendix}
%\usepackage{indentfirst} 			
%%%%%%%%%%%%%%%%%%%%�}�[�W���̐ݒ�%%%%%%%%%%%%%%%%%%%%
\topmargin=10mm 	
\voffset=-1in 		
\headheight=5mm	  	
\headsep=10mm 		
\textheight=252mm 	
\topskip=0mm 		
\footskip=10mm  	

\evensidemargin=30mm 	
\oddsidemargin=30mm 	
\hoffset=-1in 			
\textwidth=170mm 		

\marginparpush=0mm 		
\marginparsep=0mm 		
\marginparwidth=0mm 	

%%%%%%%%%%%%%%%%%%%%�T�v�C�}�C�\�Ȃǂ̖��O���ς���%%%%%%%%%%%%%%%%%%%%
\renewcommand{\thesection}{\arabic{section}.}
\renewcommand{\thesubsection}{\arabic{section}.\arabic{subsection}}
\renewcommand{\figurename}{{Fig}.}
\renewcommand{\tablename}{{Table}}
\renewcommand{\contentsname}{目次}
\renewcommand{\appendixname}{Appendix}
\renewcommand{\refname}{参考文献}
\renewcommand{\labelenumi}{(\Roman{enumi})}


\newcommand{\eref}[1]{Eq.~(\ref{#1})}
\newcommand{\esref}[2]{Eqs.~(\ref{#1}) and (\ref{#2})}
\newcommand{\essref}[2]{Eqs.~(\ref{#1})$\sim$(\ref{#2})}
\newcommand{\figref}[1]{Fig.~\ref{#1}}
\newcommand{\figsref}[2]{Figs.~\ref{#1} and \ref{#2}}
\newcommand{\figssref}[2]{Figs.~\ref{#1}$\sim$\ref{#2}}
\newcommand{\tabref}[1]{Table \ref{#1}}
\newcommand{\secref}[1]{\S \ \ref{#1}}

\makeatletter
\renewcommand{\@cite}[1]{\textsuperscript{(#1)}}
\renewcommand{\@biblabel}[1]{(#1)}
\makeatother

\newcommand{\citeref}[1]{\textsuperscript{\cite{#1}}}
\newcommand{\citesref}[2]{\textsuperscript{\cite{#1},~\cite{#2}}}
\newcommand{\citessref}[2]{\textsuperscript{\cite{#1}$\sim$\cite{#2}}}

\begin{document}
\input{dummy}
\baselineskip=18pt 	

\thispagestyle{empty} 		
%\pagenumbering{roman}	
%\setcounter{page}{0} 		
\pagestyle{plain} 		

\makeatletter
\def\@maketitle{%
\begin{center}%
\let\footnote\thanks
\vspace*{25mm} % 
{\LARGE \@title \par}%
\vskip 1.5em%
{\large
\lineskip .5em%
\begin{tabular}[t]{c}%
\@author
\end{tabular}\par}%
\vskip 1em%
{\large \@date}%
\end{center}%
\par\vskip 1.5em}
\makeatother 

\makeatletter
\long\def\@makecaption#1#2{%
\vskip\abovecaptionskip
\iftdir\sbox\@tempboxa{#1\hskip1zw#2}%
\else\sbox\@tempboxa{#1 #2}%
\fi
\ifdim \wd\@tempboxa >\hsize
\iftdir #1\hskip1zw#2\relax\par
\else #1 #2\relax\par\fi
\else
\global \@minipagefalse
\hbox to\hsize{\hfil\box\@tempboxa\hfil}%
\fi
\vskip\belowcaptionskip}
\makeatother




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Abstract %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Abstract}
In Japan, a lot of bridges built during high economic growth period from the 1950s to the 1970s get older now. In order to safely use old bridges in the future, periodical inspection is necessary. Many bridges are inspected currently by visual inspection and hammering test by humans to detect cracks and loose bolts. However, bridge inspections by humans are difficult due to the number of bridges, risks of accidents for working persons and traffic control during the inspection. Therefore, various UAVs (Unmanned Aerial Vehicles) have been developed to inspect bridges easily and safely. It is hard to introduce manual operation UAVs to inspection because manual operation is difficult for inspectors who do not have control skills. So, it is necessary to develop autonomous UAV in order to promote the introduction of UAVs. Most of the autonomous UAVs are dependent on GPS (Global Positioning System); however, these UAVs cannot be used for bridge inspection because the bridge inspection UAV flies under the bridge. In this study, a position estimation system using UWB (Ultra-Wide Band), IMU (Inertial Measurement Unit) and a distance sensor and flight control system for the inspection UAV aiming at autonomous flight in non-GPS environment were developed.


\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Abstract %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{概要}
現在日本ではインフラの老朽化が進んでおり，特に橋梁は2023年に半数以上が築50 年を迎える．老朽化した橋梁は定期的な点検が必要になるが，点検に必要なコストや点検作業者の不足が深刻な問題になっている．そのため点検作業の簡略化が望まれており，点検用UAV (Unmanned Aerial Vehicle)の開発・導入が進められている．しかしUAVの操縦経験が浅い点検作業者にとって，点検にマニュアル操縦のUAVの導入することは困難である．したがって自律飛行型の点検用UAVの開発を進める必要がある．今ある自律飛行型UAVの多くはGPS (Global Positioning System)に頼って飛行を行うが，橋梁の点検の場合，ロボットが橋梁の下に潜って点検を行うため，GPSを使うことができない．そこで本研究では点検用UAVの非GPS環境での自律飛行を目的として，UWB (Ultra-Wide Band)や慣性センサ，距離センサを組み合わせた自己位置推定法及びIntegral Backstepping制御を使った自律飛行制御手法を提案する．また小型のクアッドロータを用いて実機での提案手法の評価を行った．

\thispagestyle{empty} 
	
\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Contects %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\thispagestyle{empty} 
\tableofcontents 			
\thispagestyle{empty} 	
\pagenumbering{arabic} 	
\setcounter{page}{0} 		
\pagestyle{plain}
 
\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Introduction %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{緒言}
\subsection{研究背景}
近年の日本において，インフラ，特にその中においても橋梁の老朽化が問題視されている．国土交通省が発表するデータによると，長さ15 mを超える橋梁の数は2013年時点で40万橋存在し，その中でも建設後50年が経過したものの割合は18 \%（7万1000橋）である．こうした老朽化した橋は今後も増加するとされ，10年後には43 \%，20年後には67 \%と，過半数の橋梁が建設後50年を迎えることとなる．適切に管理，検査がなされていない老朽化した橋梁はやはり崩落事故などの危険性をはらんでいる．橋梁の崩落事故はアメリカのミネアポリスのものが有名である．しかし，日本国内においても崩落や崩落事故になりかけた事例がいくつか存在する．2007年の6月三重県にある国道23号の木曽川大橋で，コンクリートの床版に覆われたトラスの斜材が腐食して破断するという事故が起こった．幸いにもこの事故では崩落や死傷者を出すことは免れたが，ずさんな点検のあり方が浮き彫りになった．事故の1年半ほど前には点検が行われたとされているが，腐食の進んだ鋼材の錆の上から塗装を行うなど，常識を逸脱する補修方法が行われているのにも関わらず，それが見過ごされていた．こういった不適切な橋梁の管理，運営には橋梁を所有する地方自治体の財源不足なども背景とされている．国土交通省によると，1橋を近接目視で点検するだけでも50万円の費用がかかるとされている．しかし，市区町村が管理する橋の年間の維持，修繕費は1橋平均でわずか8万円であり，いかに橋梁の点検に掛ける予算が低いのかがわかる．また，橋梁の点検に用いられる一般的な方法は近接目視及び打音検査であり，傷やひび割れの正確な検出には多くの経験値を要する．これらの理由より，低コストかつ簡便に橋梁を点検可能にする新しい技術を開発することが現在の日本において喫緊の課題である．

\begin{figure}[H]
\begin{center}
\includegraphics[height=70mm]{./Fig2/number_of_bridges.png}
\caption{Number of bridges in Japan by construction year}
\label{Number_of_bridges_in_Japan_by_construction_year}
\end{center}
\end{figure}

そこで，着目したのがドローンなどのロボットを用いた橋梁の点検手法である．ここで，ロボットを用いた点検手法は大別して２種類に分けることができる．１つ目は機体に車輪を有し，橋梁の壁面や床面を伝って移動することで点検箇所へアプローチする地上型ロボットである．もう一つはドローンなどの飛行型ロボットでありこれは前者と異なり，空中から点検箇所にアプローチすることが可能である．地上型ロボットとしては高田らが開発したBIREMが挙げられる．このロボットは車輪の先端に磁石を装備しており，吸着対象が磁性体ならば，床や壁を伝いながら点検箇所へ接近し，カメラを用いた目視検査などがすることが可能である．しかし，このロボットは点検箇所まで構造物が地続きである必要があり，橋梁の途中で大きなギャップがあった場合にその先に進めないといったことや，大きな段差があった場合にそれらを乗り越えられないといった問題もある．しかし，飛行型のロボットの場合，大きなギャップや障害物があってもそれらを乗り越えて点検箇所まで近づける．これらの理由より，本研究では飛行型ロボットを開発するに至った．

\begin{figure}[H]
\begin{center}
\includegraphics[height=70mm]{./Fig2/takadabylim.jpg}
\caption{BIREM}
\label{BIREM}
\end{center}
\end{figure}


\subsection{インフラ点検用UAVの開発}
先行研究において，赤堀らはインフラ点検用UAVを開発した[]．このUAVは機体の上部にEPM（Electro-Parmanent Magnet）を搭載し，磁力を用いて構造物の鋼材に吸着することで，安定した点検を可能にした．このEPMと呼ばれる磁石の特徴は，磁力の吸着状態と開放状態を自在に制御することが可能なことである．また，この磁石は電磁石と異なり，吸着と離脱時のみ電力を消費し，吸着中は電力を消費しない．このUAVはEPMに加え，先端にカメラを有するアームも装備するため，EPMを用いて吸着した状態で安定した目視点検をすることが可能である．



\begin{figure}[H]
\begin{center}
\includegraphics[height=70mm]{./Fig2/Overall_picture_of_our_robot.png}
\caption{Overall view of the developed inspection robot in the previous study}
\label{}
\end{center}
\end{figure}

また，自身の先行研究ではこのEPMを吸着機構に採用した振動計測モジュールを開発した[]．このモジュールは加速度センサ及びデータロガーを搭載し，対象物に吸着した後，加速度を計測，ロギングすることが可能である．その振動を解析することで対象物の健全性を評価することが可能である．点検方法としては，点検箇所までUAVを用いて運搬し，EPMの磁力で貼り付け，必要なデータを計測した後，再びUAVで回収する流れである．また，重量が約230 gであるため，赤堀らが開発したUAVなどであれば，複数個積載し，運搬することが可能である．


\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}

      \begin{minipage}{0.5\hsize}
        \begin{center}
         \includegraphics[height=50mm]{./Fig2/front.png}
	  \caption{Front view of vibration measurement unit}
        \end{center}
      \end{minipage}

      \begin{minipage}{0.5\hsize}
        \begin{center}
          \includegraphics[height=50mm]{./Fig2/front.png}
          \caption{Front view of vibration measurement unit}
        \end{center}
      \end{minipage}

    \end{tabular}
  \end{center}
\end{figure}

これらのUAVを用いた点検では，構造物の地形に対して柔軟な対応性を有するが，機体の操作は全て自身の手で行う必要性がある．経験の豊富なパイロットであれば，狙い通りの点検箇所に接近することやセンサを取り付けることが可能であるが，経験の浅いパイロットであると，そういったことは非常に困難である．

\subsection{研究目的}
上記の理由より，飛行型ロボットの有用性は高いが，操作面においてまだまだ課題が多いのが現状である．そこで，現在市販される多くのドローンはGPSなどの位置計測システムを用いて全自動若しくは半自動飛行が可能である[][][]．本研究でも用いたフライトコントローラもGPSアンテナが搭載されており，屋外のGPS環境であれば，目的地を入力するだけでその地点まで全自動飛行することが可能である．しかし，研究対象とする橋梁などの構造物の周辺環境においては，遮蔽物によりGPSの電波が遮断されるため，GPSを用いた自動飛行は不可能である．そこで，非GPS環境においても自動飛行可能なUAVも開発が進んでいる．株式会社自律制御システム研究所はSLAM（Simultaneous Localization and Mapping）の機能を搭載したUAVを開発しており，非GPS環境においても自己位置推定と環境地図の作製を同時に行いながら自律飛行をすることが可能である．
	

\begin{figure}[H]
\begin{center}
\includegraphics[height=70mm]{./Fig2/photo5.png}
\caption{ACSL-PF1}
\label{photo5}
\end{center}
\end{figure}

手法としては搭載された下向きのモノラルカメラや前方に向けて取り付けられたステレオカメラを用いて撮影した画像に処理を施すことで自己位置や方角を推定し自律飛行を行う．しかし，それらをするためには高価で精度の高いカメラを複数個積むことや画像処理用のGPUを積む必要があるため，機体自体の値段が高価になる．また，画像から得た情報を基にあらゆる値を計算するには計算負荷の高い演算をしなくてはならない．点検に掛けられる財源が限られている自治体にとって，人件費がかからなかったとしても，機体が高価であった場合，大きなコスト削減は見込めない．また，多くのセンサや負荷が高い計算をするに伴って性能の高いCPUやGPUを搭載する必要があるため，機体が大型になってしまい，狭い点検空間に入っていくのが難しくなるといった課題がある．

そこで，それらの課題を克服するため，本研究ではローカル座標を推定する手法にUWBモジュールを用いる手法に着目した．UWB（超高帯域無線通信，Ultra Wide Band）とは無線通信方式の一種であり，Wi-FiやBlutoothなど他の無線通信方式に比べ広い帯域幅を持った通信方式である．これを利用し，電波を送信し返ってきた時間より距離を測定することが可能なため，UAVの位置を3次元空間内で推定することが可能である．模式図をFig. \ref{UWB_positioning}に示す．


\begin{figure}[H]
\begin{center}
\includegraphics[height=70mm]{./Fig2/UWB_positioning.png}
\caption{Schematic diagram of the position estimation method}
\label{UWB_positioning}
\end{center}
\end{figure}

詳細は以降の章にて後述するが，座標が既知の各固定局と移動局との距離を計測し，マルチラテレーションの手法を用いることで，移動局の座標を得ることが可能である．この手法はGPSアンテナとGPS衛星との距離を用いて移動局の座標を得るのと同手法である．またUWBモジュールは一個あたり数千円と非常に安価であり，機体のコスト削減に有効である．それに加えてマルチラテレーションの計算は画像解析を用いる計算などに比べて非常に負荷が軽く，高性能なコンピュータを乗せる必要がない．しかし，UWBモジュールの通信周期は4つの固定局を用いた場合に10 Hzと低く，クアッドロータが高速度で移動した際には位置推定周期としては不十分である．そこで，本研究での目的はUWBモジュールの更新周期の遅さを補うためにUWBモジュールを用いたローカルポジショニングシステムにIMU，距離センサ，及びオプティカルフローセンサの値も参照することでクアッドロータの位置を推定し，その位置を制御する手法を提案する．IMU(Inertial Measurement Unit）は加速度，角速度，地磁気を数1000 Hz程度の高い更新周波数で計測可能であり，加速度や角速度を積分することで速度や変位を得ることが可能である．しかし，値を積分した際に誤差が蓄積してしまう．また距離センサは計算することなく，直接地面との距離を計測することが可能である．最後にオプティカルフローセンサは地面の特徴点の移動量より機体の速度を算出することが可能である．先行研究において赤堀ら[]はUWBモジュール，IMU，距離センサを用いたクアッドロータの位置推定システム及び位置制御システムを開発した．しかし，姿勢角制御の周期の遅さが原因でクアッドロータの位置を制御することはなし得ていなかった．そこで，本研究では姿勢角制御の遅さを補うためにフライトコントローラを追加で導入し，改善を図った．次章からはUWBモジュール及び各種センサをカルマンフィルタに適用したクアッドロータの位置推定方法および位置制御方法を示していく．


\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%クアッドロータの位置推定アルゴリズム%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{クアッドロータの位置推定アルゴリズム}
本研究で提案するクアッドロータの位置及び姿勢推定にはカルマンフィルタ，その中でも特に非線形なシステムに適応可能な拡張カルマンフィルタ（EKF : Extended Kalman Filter)を使用している．ここで，カルマンフィルタとは，誤差を含むある観測値（2種類以上も可）を使用し，時々刻々と変化する状態量を推定するのに用いられる，逐次処理が可能なフィルタリング手法である．代表例としてはカーナビゲーションシステムが挙げられる．カーナビゲーションシステムはGPSから得られる誤差の乗った位置情報と内部の加速度センサから得られる誤差の乗った加速度情報を統合することにより，自車の位置座標や速度などを推定している．本研究ではIMU，UWBモジュール，距離センサ，オプティカルフローセンサから得られるセンサ値を統合し，機体の姿勢角，速度，座標を推定するのに用いられる．本章では初めに拡張カルマンフィルタの原理を示した後，UWBモジュールやオプティカルフローセンサの原理やキャリブレーション方法について述べる．そして最後にそれらセンサを統合したシステムを示し，位置の推定方法を説明する．



\subsection{拡張カルマンフィルタの原理}
拡張カルマンフィルタは非線形システムを書く自国において線形化し，それぞれの時刻において時変カルマンフィルタを適用するという考えに基づいている．まず離散時間非線形状態空間表現が次の二式で表される場合を考える．

\begin{align}
\textbf{x}(t+1) = \textbf{f}(\textbf{x}(t)) + \textbf{B}\textbf{v}(t)
\label{2-1}
\end{align}

\begin{align}
\textbf{y}(t) = \textbf{h}(\textbf{x}(t)) + \textbf{w}(t)
\label{2-2}
\end{align}

\noindent
ここで$\textbf{f}(\cdot)$，および$\textbf{h}(\cdot)$はベクトル値をとる$\textbf{x}(t)$の非線形関数である．また$\textbf{v}(t)$は平均値ベクトル0，共分散行列$\textbf{Q}$のr次元システム雑音ベクトル，$\textbf{w}(t)$は平均値ベクトル0，共分散行列$\textbf{R}$のp次元観測雑音ベクトルであり，互いに独立な正規性白色雑音と仮定する．時刻$t$，$t+1$において，それぞれ事前状態推定値$\hat{\textbf{x}}^{-}$と事後推定値$\hat{\textbf{x}}$が利用可能であるという仮定のもとで，式\ref{2-1}と式\ref{2-2}の非線形関数をテイラー級数展開を用いて線形近似すると，

\begin{align}
\textbf{f}(\textbf{x}(t))=\textbf{f}(\hat{\textbf{x}}(t))+\textbf{A}(t)(\textbf{x}(t)-\hat{\textbf{x}}(t)),\left.\textbf{A}(t)=\frac{\partial \textbf{f}(\textbf{x})}{\partial \textbf{x}}\right|_{\textbf{x}=\hat{\textbf{x}}(t)}
\label{2-3}
\end{align}

\begin{align}
\textbf{h}(\textbf{x}(t))=\textbf{h}(\hat{\textbf{x}}^{-}(t))+\textbf{c}^{T}(t)(\textbf{x}(t)-\hat{\textbf{x}}^{-}(t)),\left.\textbf{C}^{T}(t)=\frac{\partial \textbf{h}(\textbf{x})}{\partial \textbf{x}}\right|_{\textbf{x}=\hat{\textbf{x}}^{-}(t)}
\label{2-4}
\end{align}\

\noindent
が得られる．式\eqref{2-3}を式\eqref{2-1}に，式\eqref{2-4}を式\eqref{2-2}に代入すると，それぞれ，

\begin{align}
\textbf{x}(t+1)=\textbf{A}(t)\textbf{x}(t)+\textbf{b}\textbf{v}(t)+\textbf{f}(\hat{\textbf{x}}(t))-\textbf{A}(t)\hat{\textbf{x}}(t)
\label{2-5}
\end{align}

\begin{align}
\textbf{y}(t)=\textbf{C}^{T}(t)\textbf{x}(t)+\textbf{w}(t)+\textbf{h}(\hat{\textbf{x}}^{-}(t))-\textbf{C}^{T}(t)\hat{\textbf{x}}^{-}(t)
\label{2-6}
\end{align}\

\noindent
が得られる．さらに

\begin{align}
\textbf{u}(t)=\textbf{f}(\hat{\textbf{x}}(t))-\textbf{A}(t)\hat{\textbf{x}}(t)
\label{2-7}
\end{align}

\begin{align}
\textbf{z}(t)=\textbf{y}(t)-\textbf{h}(\hat{\textbf{x}}^{-}(t))+\textbf{C}^{T}(t)\hat{\textbf{x}}^{-}(t)
\label{2-8}
\end{align}\

\noindent
とおくと，式\eqref{2-5}と式\eqref{2-6}はそれぞれ次のようになる．

\begin{align}
\textbf{x}(t+1)=\textbf{A}\textbf{x}(t)+\textbf{B}\textbf{v}(t)+\textbf{u}(t)
\label{2-9}
\end{align}

\begin{align}
\textbf{z}(t)=\textbf{C}\textbf{x}(t)+\textbf{w}(t)
\label{2-10}
\end{align}\

\noindent
このように非線形システムをテイラー級数展開を用いて線形近似すると制御入力がある場合のカルマンフィルタになる．以上より予測ステップにおける更新式は

\begin{align}
\hat{\textbf{x}}^{-}(t)=\textbf{f}(\hat{\textbf{x}}(t-1))
\label{2-11}
\end{align}

\begin{align}
\textbf{P}^{-}(t)=\textbf{A}(k-1)\textbf{P}(t-1)\textbf{A}^{T}(k-1)+\textbf{B}\textbf{Q}\textbf{B}^{T}
\label{2-12}
\end{align}\

\noindent
となる．ここで$\textbf{A}(t-1)$は

\begin{align}
\left.\textbf{A}(t-1)=\frac{\partial \textbf{f}(\textbf{x})}{\partial \textbf{x}}\right|_{\textbf{x}=\hat{\textbf{x}}(t)}
\label{2-13}
\end{align}\

\noindent
となる．またフィルタリングステップの更新式は

\begin{align}
\hat{\textbf{x}}(t)=\hat{\textbf{x}}^{-}(t)+\textbf{g}(t)(\textbf{y}(t)-\textbf{h}(\hat{\textbf{x}}^{-}(t)))
\end{align}

\begin{align}
\textbf{P}(t)=(\textbf{I}-\textbf{G}(k)\textbf{C}^{T}(t))\textbf{P}^{-}(k)
\end{align}\

\noindent
となる．ここでカルマンゲイン$G(t)$及び$\textbf{C}^{T}(t)$は次式で計算することができる．

\begin{align}
\textbf{G}(t)=\textbf{P}^{-}(k)\textbf{C}^{T}(\textbf{C}\textbf{P}^{-}(k)\textbf{C}^{T}+\textbf{R})^{-1}
\end{align}\

\begin{align}
\left.\textbf{C}^{T}(t)=\frac{\partial \textbf{h}(\textbf{x})}{\partial \textbf{x}}\right|_{\textbf{x}=\hat{\textbf{x}}^{-}(t)}
\end{align}\

\noindent
拡張カルマンフィルタにおいては各時刻ごとに$\textbf{f}$と$\textbf{h}$のヤコビアンを求めるため偏微分の計算を行わなければならない．そのため，微分可能な滑らかな非線形性の場合には拡張カルマンフィルタを適用できるが，不連続な非線形性をもつ場合には適用できない．






\subsection{UWB通信}
\subsubsection{UWB通信の測距原理（発散の回避方法，取付角の工夫）}
まず，無線通信を利用した距離測定の技術はBlutoothやWi-Fiを用いたものなどが挙げられる．片方のデバイスが電波を発し，それをもう片方が受け取り，デバイス同士が通信を行う．測距の方法は，受信側の受け取った電波の強弱により発信側が近くにあるのか遠くにあるのかを判別し，距離を算出する．しかし，弱い電波を受け取った際，距離が離れているため電波が弱いのか，それともデバイス間に障害物があるため電波が弱くなっているのか，といったことを判別できない．したがって，Wi-FiやBlutoothを用いた測距は誤差が5 mほど乗るとされている．一部の企業はWi-Fi電波の飛行時間（Time of flight，ToF）や到着時間（Time of Arrival，ToA）を使用し，距離をより正確に測るための代替アルゴリズムを開発したが，既存のWi-Fiを用いてこれを行うことは，ハードウェアの問題により難しいとされている．

UWB通信（超広帯域無線通信，Ultra Wide Band）とは無線通信方式の一種であり，非常に広い帯域幅にわたって電波を拡散させることで高速通信を可能とする．Fig. \ref{}にUWB通信と既存の無線通信方式とのスペクトラムの比較を示す．周波数の帯域は3.1 GHｚから10.6 GHzであり，その帯域幅は7.5 GHzと従来の無線の数百 kHzやWi-Fiの20 MHzに比べてかなり広い帯域を利用している．

\begin{figure}[H]
\begin{center}
\includegraphics[height=60mm]{./Fig2/UWB_power.png}
\caption{Comparison of power spectrum between UWB and other wireless communication system}
\label{UWB_power}
\end{center}
\end{figure}

\noindent
送信出力は-41.3 dBm/MHz以下に制限されており，これは家庭用テレビやパソコン等の一般の電子機器等が発生する雑音レベルの約500分の1以下という非常に小さな出力である．また，UWB通信はFig. \ref{narrow_wide}に示すようにナノ秒オーダーのパルスを通信に使用し，狭帯域信号のような立ち上がりが遅い信号に比べて，デバイス間の距離を高精度で測定可能である．

\begin{figure}[H]
\begin{center}
\includegraphics[height=60mm]{./Fig2/narrow_wide.png}
\caption{Comparison of pulses between narrow band and ultra wide band signals}
\label{narrow_wide}
\end{center}
\end{figure}

\noindent
また，Fig. \ref{narrow}，Fig. \ref{wide}に示すように狭帯域信号に比べ，UWB信号はSN比が良いため，ノイズの影響を受けにくいことなどが特長として挙げられる．

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}

      \begin{minipage}[t]{0.5\hsize}
        \begin{center}
         \includegraphics[height=50mm]{./Fig2/narrow.png}
	  \caption{Narrow band signal with noise}
	　\label{narrow}
        \end{center}
      \end{minipage}

      \begin{minipage}[t]{0.5\hsize}
        \begin{center}
          \includegraphics[height=50mm]{./Fig2/wide.png}
          \caption{Ultra wide band signal with noise}
	   \label{wide}
        \end{center}
      \end{minipage}

    \end{tabular}
  \end{center}
\end{figure}

\noindent
無線通信を利用する際に大きな問題とされるのがマルチパスの発生である．マルチパスとは電波を受信した際に，直接波の他に壁などの障害物に反射した反射波を受信してしまう場合があり，この際，正確な信号受け取れないといったことや，直接波の位相を反射波が遅らせてしまうといったことが発生する．テレビやラジオにてゴースト障害が起きるのも，このマルチパスが原因とされている．無線通信を利用した測距の場合には，正確な到達時間を計測できず，測距誤差が発生するということが起きる．次のFig. \ref{narrow_with_reflections}，Fig. \ref{wide_with_reflections}に狭帯域信号とUWB信号のマルチパスの影響の比較を示す．



\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}

      \begin{minipage}[t]{0.5\hsize}
        \begin{center}
         \includegraphics[height=50mm]{./Fig2/narrow_with_reflections.png}
	  \caption{Narrow band signal with reflections}
	　\label{narrow_with_reflections}
        \end{center}
      \end{minipage}

      \begin{minipage}[t]{0.5\hsize}
        \begin{center}
          \includegraphics[height=50mm]{./Fig2/wide_with_reflections.png}
          \caption{Ultra wide band signal with reflections}
	   \label{wide_with_reflections}
        \end{center}
      \end{minipage}

    \end{tabular}
  \end{center}
\end{figure}

\noindent
狭帯域信号では立ち上がりと立ち下がりが鈍く，障害物で位相が反転した反射波の影響により直接波の位相や振幅が変化させられているのが分かる．しかし，UWB信号は立ち上がり時間と立ち下がり時間が短いため，直接波の後に反射波が来ていても直接波に悪影響を与えない．このようなマルチパス耐性が高いといったこともUWBの特長である．


次にUWB通信を用いた測距方法について見ていく．UWB通信による測距は主に電波の飛行時間（ToF）を用いている．送信側と受信側が互いに通信し，電波の到達するのに掛かった時間（Tof）に電波の速度（$c$）を掛けることにより，距離（$d$）を測定することが可能である．次に計算式を示す．

\begin{align}
d = \textrm{ToF} \times c
\label{2-2-1}
\end{align}

\noindent
またFig. \ref{UWB_ranging_2}に通信プロトコルを示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=60mm]{./Fig2/UWB_ranging_2.png}
\caption{Ranging protocol of UWB module}
\label{UWB_ranging_2}
\end{center}
\end{figure}

\noindent
これ以降，クアッドロータに搭載された移動局をタグ，床に固定された固定局をアンカと記載する．クアッドロータの座標を3次元で推定するためには1つのタグと3つ以上のアンカが必要である．それに伴い，複数のデバイスを識別するためにまずアンカ側から16進数からなるIDを送信する．その後タグ側から応答があり，最後にアンカ側のタイムスタンプ（$T_{SP}, T_{RR}, T_{SF}$）を送信する．この送られてきたタイムスタンプ及びタグ側のタイムスタンプ（$T_{RP}, T_{SR}, T_{RF}$）を用い，次式のように電波の飛行時間（ToF）を計算可能である．

\begin{align}
\textrm{ToF} = \frac{1}{4}((T_{SP} - T_{RR}) - (T_{SR} - T_{RP}) + (T_{RF} - T_{SR}) - (T_{SF} - T_{RR})) 
\label{2-2-2}
\end{align}


次のFig. \ref{Anchor}に製作したUWBモジュールのアンカを示す．搭載されたUWBチップはDecaWave社製のDWM1000である．マイコンはTeensy3.6を用いて制御を行っている．電源はFig. \ref{Li_ion}に示すUltraLife社製, 1 cell, 1800 mAhのリチウムイオンバッテリを用いている．図の基板構成で満充電から約3時間容量が保つ．Fig. \ref{Anchor}からわかるように，小型であるためアンカの設置や回収は容易に行うことが可能である．


\begin{figure}[H]
\begin{center}
\includegraphics[height=60mm]{./Fig2/Anchor.png}
\caption{UWB anchor}
\label{Anchor}
\end{center}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[height=50mm]{./Fig2/Li_ion.jpg}
\caption{Battery for UWB Anchor}
\label{Li_ion}
\end{center}
\end{figure}



前述したようにUWB通信はマルチパスに耐性があり，また[]でも示されているように，壁のように強い反射体の近くにおいても測距性能は正確であるが，森林のようなデバイス間に障害物が存在する環境：NLOS(Non Line Of Sight，非見通し環境)においてはマルチパスが発生し，真値より大きく外れた値や負の値を取ることがある．本研究においても，このマルチパスの影響を確認した．Fig. \ref{UWB_out}に測距した際にマルチパスが発生し，値が発散した結果を示す．またそれの拡大図もFig. \ref{UWB_out_zoom}に合わせて示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=60mm]{./Fig2/UWB_out.png}
\caption{Ranging result when outliers occur}
\label{UWB_out}
\end{center}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[height=60mm]{./Fig2/UWB_out_zoom.png}
\caption{Ranging result when outliers occur (enlarged image above)}
\label{UWB_out_zoom}
\end{center}
\end{figure}

\noindent
測距手順はまず，実験室の床に距離を測り，真値の点を1 mから5 mまで1 m間隔で取った．そして，その点に合わせる形で4つのアンカを1 mずつ動かし，それぞれのアンカと固定したタグとの間の測距をUWBモジュールにより計測した．2つの図からわかるように，測距した最長の距離は5 mであるのにも関わらず，値が発散し最長300 mほどの距離や負の距離を計測している．UWBモジュール間に障害物が無かったのにも関わらず，こういったマルチパスが発生した原因は，壁や天井により電波が反射したためであると考えられる．タグと各アンカとの正確な距離が得られていない場合，3次元空間内におけるクアッドロータの位置推定値も不正確になるため，こういった発散した値は取り除く必要がある．そこで，まず初めに行ったのが電波の指向性を考慮したモジュールの改良である．UWBモジュールには指向性があり，電波強度の強い向きと弱い向きが$x,, y, z$軸の回転方向に存在する．本研究にて採用したUWBチップ（DWM1000）の軸を次のFig. \ref{UWB_axis}のように定義する．


\begin{figure}[H]
\begin{center}
\includegraphics[height=40mm]{./Fig2/UWB_axis.png}
\caption{UWB chip axis}
\label{UWB_axis}
\end{center}
\end{figure}

\noindent
DWM1000を製造するDecaWave社がチップから発せられる電波の指向性をデータシートにおいて公開している．$x, y, z$軸周りにおける電波の指向性をFig. \ref{UWB_angle_x}からFig. \ref{UWB_angle_z}に示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=50mm]{./Fig2/UWB_angle_x.png}
\caption{Directivity of radio wave around $x$ axis}
\label{UWB_angle_x}
\end{center}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[height=50mm]{./Fig2/UWB_angle_y.png}
\caption{Directivity of radio wave around $y$ axis}
\label{UWB_angle_y}
\end{center}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[height=50mm]{./Fig2/UWB_angle_z.png}
\caption{Directivity of radio wave around $z$ axis}
\label{UWB_angle_z}
\end{center}
\end{figure}

\noindent
3つの図から考慮すると，UWBチップの平面方向から垂直な方向，つまりFig. \ref{UWB_axis}の$x$軸の方向が通信対象を向けば，電波強度を確保できることがわかる．そこで，Fig. \ref{UWB_case_angle}に示すアンカ用のホルダを3Dプリンタにより製作した．


\begin{figure}[H]
\begin{center}
\includegraphics[height=50mm]{./Fig2/UWB_case_angle.png}
\caption{UWB module holder considering radio wave directivity}
\label{UWB_case_angle}
\end{center}
\end{figure}

\noindent
これを用いる前は，実験室の壁面に対して垂直にアンカを貼り付けていたが，このホルダを用いることでチップ垂直方向をクアッドロータの方向付近を向けることが可能である．これを垂直な壁面に貼り付けることで以前より$30^\circ$ほどオフセット角を稼ぐことができる．そしてこのホルダをアンカの4つ分使用し，実験室の4隅に取り付け，アンカで取り囲まれる範囲内でタグを動かし，測距を行った．アンカの電波の強い方向がタグの方を向くため，マルチパスは発生しなくなると考えられたが，結果はFig. \ref{UWB_out}と同様に発散した値を計測した．したがってアンカの取り付け方法によってマルチパスの発生を抑えることは難しいと考えた．

次に行ったのがプログラムによる発散値の処理を行い，発散値をロギングしないという方法である．処理の内容は，アンカとタグとで通信を行い，計測した距離データを一度メモリ内にバッファする．そして，次の距離データが送られてきた際にバッファした距離と比較し，閾値を上回る変化があった場合にはその直近のデータを破棄し，前のデータを採用するというものである．距離データの発散は，条件にもよるが数秒に1サンプル程度の頻度で発生し，連続したサンプル同士が両方発散することはない．したがって，この処理の方法により真値からかけ離れた値のみを適切に無視することが可能である．閾値としては，クアッドロータが$1 m/s$の速度で水平面内を飛行可能であると考慮し，測距の1ループ内で移動不可能な距離を閾値として設定した．このプログラムによる処理を行い，発散値を回避した測距結果をFig. \ref{UWB_cali}に示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=60mm]{./Fig2/UWB_cali.png}
\caption{Ranging result avoiding outlier}
\label{UWB_cali}
\end{center}
\end{figure}

\noindent
実験方法はFig. \ref{UWB_out}の実験を行った際と同様である．アンカを動かした際の振動による値のずれは生じているが，処理する前の結果と比べて適切に発散値を回避することができている．


\subsubsection{更新周波数の改善のアプローチ（マイコンスペックの比較，周波数グラフの比較）}

\subsection{オプティカルフローセンサ}
\subsubsection{オプティカルフローセンサの原理（センサ座標系のワールド座標系への変換）}
先行研究では，クアッドロータの位置や速度などの状態量をUWBモジュール及びIMUを用いて推定していた．しかし，UWBモジュールのアンカを4つ用いた際に得られる距離データの更新周期は10 Hzと遅く，クアッドロータが高速度で動いた際や運動の不安定さが原因の細かな振動が生じた際に更新周期が不十分であった．そこで，更新周期の遅さを補うために本研究からは新たにオプティカルフローセンサを搭載した位置推定および位置制御システムを構築した．オプティカルフローセンサとは，カメラで撮影した画像の特徴点の移動量から，移動する物体の速度や移動量を算出可能なセンサである．オプティカルフローはPython環境にてOpenCVなどのモジュールを用い，パーソナルコンピュータを使用し計算することも多い．例としては，あらかじめ撮影した車の写真から車速を割り出すことなどに使用される．そして，オプティカルフローセンサは画像の撮影から移動量の算出までを，搭載したチップで行うことが可能である．そして，それらのセンサ値をマイコンにより適切に処理することにより，搭載したロボットなどの速度や移動量を得ることができる．また，別の例としては光学式マウスはこのセンサにより移動量を算出している．[]や[]においてもクアッドロータにこのセンサを搭載し，クアッドロータの位置保持制御や目標点まで移動させる制御などを行っている．本研究で採用したオプティカルフローセンサモジュールの外観をFig. \ref{optical_flow}に示す．


\begin{figure}[H]
\begin{center}
\includegraphics[height=50mm]{./Fig2/optical_flow_with_axis.png}
\caption{Optical Flow Sensor Module}
\label{optical_flow}
\end{center}
\end{figure}

\noindent
このモジュールはオプティカルフローセンサとしてPMW3901のチップを搭載しており，それに加え距離センサとしてVL53L0x ToFセンサを搭載している．二つのセンサが同一の基板上に搭載されているため汎用性が高いモジュールであり，オプティカルフローセンサはSPI通信，距離センサは$\textrm{I}^{2}\textrm{C}$通信をそれぞれ用いるため，配線が少なくてすむ．また，図より大きさもとても小型であることがわかり，積載量の限られたクアッドロータなどにおいても容易に搭載可能である．後述するが，距離センサはオプティカルフローセンサから得た値を補正するのに用いられる．


\subsubsection{センサのキャリブレーション}
オプティカルフローセンサから得られる速度のキャリブレーション方法について述べる．まず，オプティカルフローセンサから得られる値は撮影した写真の変化から得られる特徴点の移動量，つまり単位は距離ではなくピクセルである．例えば，ある物体の上でクアッドロータが100 mm移動したとする．その際，クアッドロータの高さが低ければピクセル数の変化量は大きいが，高さが二倍になった場合，ピクセル数の変化量は二分の一になる．それを表した図がFig. \ref{opt_distance}である．

\begin{figure}[H]
\begin{center}
\includegraphics[height=70mm]{./Fig2/opt_distance.png}
\caption{Difference in Sensor Value Due to Difference in Quad-Rotor Height}
\label{opt_distance}
\end{center}
\end{figure}

\noindent
したがって，オプティカルフローセンサから得られるピクセル数の変化量と距離センサから得られる距離を乗算し，適切な定数を掛けることで真の移動距離を算出することができる．なお，飛行体の高度とオプティカルフローセンサから得られる値の関係は[]に詳しい記述がある．また[]を参考にすると，センサが値を取得し，次の値を取得するまでをセンサの1ループと考えると，その1ループ中に移動した距離は次式で表せる．

\begin{align}
\textrm{Moving distance} = \left( \frac{\textrm{Sensor value} \times \textrm{Altitude}}{\textrm{Sensor's resolution in pixels} \times \textrm{Scalar}}\right) \times 2.0 \times \tan \left(\frac{\textrm{Field of view}}{2.0} \right)
\label{2-3-1}
\end{align}

\noindent
Sensor valueはオプティカルフローセンサから得た値であり，Altitudeは距離センサから得た地面までの距離である．Field of viewはオプティカルフローセンサが撮影可能な画角であり，Sensor's resolution in pixelsは撮影画像の画素数つまり解像度である．この二つの値はセンサ固有のものであり，それらを次のTable. \ref{sensor_value}に示す．


\begin{table}[H]
 \caption{Sensor characteristic value}
  \label{sensor_value}
 \begin{center}
  \begin{tabular}{|c||c|}
   \hline
    FOV [$^{\circ}$]&  42 \\
   \hline
  Resolution [pixel]& 30 $\times$ 30       \\
   \hline 
  \end{tabular}
 \end{center}
\end{table}

\noindent
Scalarは定数であり，このScalarの値を次のキャリブレーションにより求めた．式(\ref{2-3-1})から得られるのは，あくまでも1ループ中に動いた距離，つまり速度である．物体が移動した真の速度を用いてこのScalarの値を求めることは可能であるが，速度を外部のセンサなどを用いて求めるのはシステムが複雑になる．そこで，速度ではなく真の移動距離を用いてこのScalarの値を求めることにした．過去のある時点から現在までに移動した距離を算出するには，センサから得られた速度に対してマイコンが1ループにかかる処理時間を掛け，それを足し合わせることで可能である．つまり，センサ値を積分することである．そこで次のような実験を行った．次のFig. \ref{opt_experiment1}，Fig. \ref{opt_experiment2}のようにある高さに対し，センサが下を向くように固定し，一方向のみレールにより自由度を与える．レールに既知の距離を複数点マークし，その距離分だけセンサを動かした．



\begin{figure}[H]
  \begin{center}
    \begin{tabular}{cc}

      \begin{minipage}[t]{0.5\hsize}
        \begin{center}
         \includegraphics[height=50mm]{./Fig2/opt_experiment1.png}
	  \caption{Narrow band signal with reflections}
	　\label{opt_experiment1}
        \end{center}
      \end{minipage}

      \begin{minipage}[t]{0.5\hsize}
        \begin{center}
          \includegraphics[height=50mm]{./Fig2/opt_experiment2.png}
          \caption{Ultra wide band signal with reflections}
	   \label{opt_experiment2}
        \end{center}
      \end{minipage}

    \end{tabular}
  \end{center}
\end{figure}


\noindent
センサ値を積分して得られた距離データと真の距離を最小二乗法により近似することでScalarを求めた．センサを動かした距離はTable \ref{Sensor_Value_and_Moved_Distance}に示すように0 mmから800 mmまでの200 mm間隔である．固定したセンサの床からの高さは775 mmである．また，センサ値の値は三回試行を行った上でのそれらの平均値である．




\begin{table}[H]
 \caption{Sensor values and moving distance}
 \label{Sensor_Value_and_Moved_Distance}
 \begin{center}
  \begin{tabular}{|c|c|}
   \hline
    Moving distance [mm] & Average of sensor value [-]\\
   \hline\hline
   0 & 0 \\
   \hline 
   200 & 3061 \\
   \hline
   400 & 6165\\
   \hline
   600 & 9198 \\
   \hline
   800 & 12296 \\
   \hline
  \end{tabular}
 \end{center}
\end{table}

\noindent
そして，結果をFig. \ref{opt_cali}に示す．


\begin{figure}[H]
\begin{center}
\includegraphics[height=60mm]{./Fig2/opt_cali.png}
\caption{Relationship between sensor value and moving distance}
\label{opt_cali}
\end{center}
\end{figure}

\noindent
近似直線からわかるように，センサ値と移動距離の関係は線形的に近似可能である．センサの床からの距離，つまり式(\ref{2-3-1})中のAltitudeは距離センサ得られる値を用いたが，Altitudeの値を真値(775 mm)に固定して計算しても結果は同様のものであった．また，この結果はFig. \ref{optical_flow}に示す$y$軸方向の移動の実験におけるものであったが，同様に$x$軸方向における実験も行ったが結果は同様のものであった．したがって，各軸におけるScalarの値は同一の値を採用した．以上の検証よりScalarが求まったため，オプティカルフローセンサよりセンサ座標系における速度が得られるようになった．

次にセンサ座標系のワールド座標系への変換方法について述べる．前述した方法で得られるのはセンサ座標系における速度であり，クアッドロータの位置や速度をワールド座標系内で推定し，位置を制御するにはセンサ座標系をワールド座標系へ変換する必要がある．まず，Fig. \ref{quad_fig}にワールド座標系と機体座標系の関係を示す．


\begin{figure}[H]
\begin{center}
\includegraphics[height=60mm]{./Fig2/quad_fig.png}
\caption{Relationship between the world coordinate system and the quad-rotor coordinate system}
\label{quad_fig}
\end{center}
\end{figure}


\noindent
ワールド座標系は地上の任意の点を原点とする地上に固定されている座標系であり，r-frameと表す．そして，機体座標系は機体重心を原点とし，機体前方を$y_b$，右方向を$x_b$，上方向を$z_b$とした座標系であり，b-frameと表す．また，3次元の姿勢表現としてオイラー角を用いた表現を行う．r-frameとb-frameの回転角の関係は$\phi, \theta, \psi$の3つのオイラー角を用いて表現できる．$\phi, \theta, \psi$はそれぞれ$x, y, z$軸周りにおける回転であり，ピッチ角，ロール角，ヨー角と呼ばれる．もし，機体がワールド座標系内にて$z$軸周りに$\psi$だけ回転した場合，オプティカルフローセンサから得られる速度をワールド座標系へ変換しなければ，ワールド座標系内での速度が得られない．オプティカルフローセンサから得られる$x, y$軸それぞれの速度を$\textbf{v}_o = [v_{ox}, v_{oy}]^T$とし，変換した後のワールド座標系内での速度を$\textbf{v}_r = [v_{rx}, v_{ry}]^T$とすると，それらの関係は$z$軸周りにおける回転行列を用いて次式により表せる．

\begin{align}
\label{2-3-1}
\begin{split}
\left[
    \begin{array}{c}
      v_{rx}  \\
      v_{ry}
    \end{array}
\right]
&= 
\left[
    \begin{array}{cc}
      \cos\psi & -\sin\psi \\
      \sin \psi & \cos\psi
    \end{array}
\right]
\left[
	\begin{array}{cc}
		v_{ox}  \\
		v_{oy}
	\end{array}
\right] \\
&=
\left[
    \begin{array}{c}
      v_{ox}\cos\psi  -v_{oy}\sin\psi \\
      v_{ox}\sin\psi + v_{oy}\cos\psi
    \end{array}
\right]
\end{split}
\end{align}\

\noindent
$z$軸周りの回転角度は地磁気及び角速度センサを使用して推定したものを用いる．推定方法は次章にて説明する．式(\ref{2-3-1})を用いることでクアッドロータのワールド座標系内での速度をオプティカルフローセンサにより得られるようになった．


\subsection{UWBモジュール，IMU，距離センサのみを用いた位置推定システム}
まず，先行研究において開発され，本研究において改良したクアッドロータの外観をFig. \ref{quad-rotor}に示す．また詳細な仕様をTable \ref{Quad-rotor specifications}に示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/quad-rotor.png}
\caption{Quad-rotor equipped with UWB module, IMU and distance sensor}
\label{quad-rotor}
\end{center}
\end{figure}


\begin{table}[H]
 \caption{Quad-rotor specifications.}
 \label{Quad-rotor specifications}
 \begin{center}
  \begin{tabular}{|c||c|}
   \hline
   Total weight [kg] & 0.65 \\ 
   \hline
   Height [mm]& 110 \\
   \hline
   Width [mm]& 250 \\
   \hline
   Depth [mm]& 250 \\
   \hline
   Propeller size [inch] & 5$\times$3\\
   \hline
   Maximum flight time [min]& 10 \\
   \hline
    KV value [rpm/V]& 2633 \\
   \hline
   Buttery capacity[mAh]& 1800 \\
   \hline
  \end{tabular}
 \end{center}
\end{table}

\noindent
先行研究からのクアッドロータの変更点は新たにフライトコントローラを追加した点である．次のFig. \ref{system}に先行研究にて開発された位置推定アルゴリズムを用いた位置制御用のシステムを示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/system.png}
\caption{System configuration of sensors}
\label{system}
\end{center}
\end{figure}

\noindent
本クアッドロータでは姿勢角や位置などの推定値の計算や位置制御のための姿勢角の計算などは全てLinux OS搭載のコンピュータ，Raspberry Piを用いて行う．センサボードはNAVIO2を搭載しており，加速度センサ及び角速度センサの機能を有している．UWBモジュールはSPI通信でArduino Pro Miniと通信しており，4つのアンカから集めた距離データを集約しUART通信でRaspberry Piに送っている．距離センサの値は$\textrm{I}^2\textrm{C}$通信を用いてRaspberry Piに送っている．先行研究においては，推定した自己位置や姿勢を基に姿勢角を制御する際，フライトコントローラとしてRaspberry Piを用い，Integral Backstepping制御を適用することでクアッドロータの位置制御を行っていた．しかし，その制御方法では姿勢角制御のループ周波数が遅く，位置制御が振動的になり目標の位置にクアッドロータを収束させることが不可能であった．そこで，本研究ではその姿勢角制御の遅さを補うため，推定値の演算を行うコンピュータとクアッドロータの姿勢角制御を行うコンピュータを分離させた．推定値の演算や位置の偏差から目標姿勢角を計算することなどは従来通りRaspberry Piを用いて行うが，姿勢角制御はmRobotics社が製作しているPixracerと呼ばれるフライトコントローラを用いて行うように仕様を変更した．Fig. \ref{pixracer}にPixracerの外観を示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/pixracer.png}
\caption{Appearance of Pixracer}
\label{pixracer}
\end{center}
\end{figure}

\noindent
このボードは6個のPWM出力ピンを備えており，重量も約11 gと軽量のため，小型の航空機や地上機などのコントローラとして採用されることが多い．加速度センサ，角速度センサ，地磁気センサ，気圧センサといった各種センサやWi-Fiモジュールも搭載されるため，汎用性が高いコントローラでもある．また，GPSも搭載されており，GPS環境下であればオートフライトも可能である．本研究にてこのコントローラを採用した理由は非常に小型・軽量であるため，従来のクアッドロータに追加で搭載した場合にも，大きな改良を施さなくて良い点やファームウェアやプログラムがオープンソースなため，自身で内部の仕様を変更可能であることなどが理由である．また，何よりも大きな利点は高速なCPUを搭載し，完成度の高い姿勢角制御のアルゴリズムが使用可能なため，自身で構築した姿勢角制御アルゴリズムよりも精度良くクアッドロータの姿勢角を制御可能なことである．Fig. \ref{system}に示すようにフライトコントローラはUSBを介してRaspberry Piと接続されており，Raspberry Piが計算した目標姿勢角をフライトコントローラに送ることで，クアッドロータを目標姿勢に追従させることが可能である．Fig. \ref{system_core_design}に位置制御のブロック線図を示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=100mm]{./Fig2/system_core_design.png}
\caption{Block diagran of positon control system}
\label{system_core_design}
\end{center}
\end{figure}

\noindent
手順としてはまず，UWBモジュールのタグと各アンカとの距離($d_1$から$d_4$)，距離センサから得た地面との距離($d_h$)，センサボードから得た加速度($a_x, a_y, a_z$)，角速度値($\omega_x, \omega_y, \omega_z$)をミキシングし，拡張カルマンフィルタを適用することで位置($x, y, z$)，速度($v_x, v_y, v_z$)，姿勢角($\phi, \theta, \psi$)を推定する．そして，目標座標と現在座標の偏差をPID制御器に通すことで目標姿勢角（$\phi_d, \theta_d, \psi_d$）を求める．そしてそれをフライトコントローラへ送信可能なサーボ信号(Ch1からCh4)へと変換し，フライトコントローラへ送ることでクアッドロータの姿勢角及びスラストが制御され，目標位置へと機体が移動するという流れである．

次に拡張カルマンフィルタを用いてクアッドロータの位置を推定する方法について述べる．まず，姿勢角や位置を推定するのに拡張カルマンフィルタを用いる理由について述べる．初めに姿勢角についてであるが，姿勢角はカルマンフィルタの状態方程式側にて角速度センサの値を積分して角度に変換する．しかし，積分した際，角速度センサに乗ったノイズまで積分するため，推定した角度が時間とともにドリフトしてしまう．また，観測方程式側では加速度センサから得られる値よりヨー角以外の姿勢角を直接計算できる．その際，積分を行わないためドリフトをすることはないが，クアッドロータが並進移動した際に余計な加速度がかかるため，正確な角度を計算できなくなってしまう．それら二種類のセンサの不利な点を補うのに今回のようなカルマンフィルタを用いた姿勢角の推定は有効である．次に位置推定についてであるが，位置推定の計算は状態方程式側において加速度センサの値を二回積分し，移動距離を求め，観測方程式側ではUWBモジュールを用いて求めた距離を用い，マルチラテレーションの手法にて位置を推定している．加速度センサからは数千Hzにて加速度を得られるため，位置推定値も変化に対する応答性が高いが，姿勢角を求めた際と同様に，積分した際にドリフトが生じてしまう．また，UWBを用いた推定では正確な絶対座標が得られるが，UWBアンカを4つ使用した際の更新周波数が10 Hzと遅いため，クアッドロータが高速で運動した際には応答性の悪い推定になってしまう．このように位置推定においても，お互いのセンサ不利な点を補えるためカルマンフィルタは有効である．UWBモジュールを用いてクアッドロータの位置を推定する方法にマルチラテレーションの手法を用いていると述べたが，これについて説明する．マルチラテレーションとは座標が既知の3つ以上の固定局と移動局間の距離を求め，アルゴリズムに基づいて計算することで，移動局の座標を求める手法のことである．身近な例では，複数個のGPS衛星とGPS移動局との距離よりモジュールの位置を割り出すのに使用されている．位置を計算する手法は数多く存在し，[]や[]に詳しい解法が載っている．Fig. \ref{UWB_positioning2}にマルチラテレーションにおける模式図を示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/UWB_positioning2.png}
\caption{Position relationship between Anchors and Tag}
\label{UWB_positioning2}
\end{center}
\end{figure}

\noindent
アンカが固定局のことであり，その絶対座標は既知である．そして，タグは座標未知の移動局であり，クアッドロータに搭載されている．このタグの位置を求めることがマルチラテレーションのことである．タグ及びアンカの座標とモジュール間の距離の関係は次式により表せる．

\begin{align} 
\label{2-4-1}
\left[
    \begin{array}{c}
      d_{1} \\
      d_{2} \\
      d_{3} \\
      d_{4}
    \end{array}
\right]
=
\left[
    \begin{array}{c}
      \sqrt{(\hat{x}-x_{1})^{2}+(\hat{y}-y_{1})^{2}+(\hat{z}-z_{1})^{2}} \\
      \sqrt{(\hat{x}-x_{2})^{2}+(\hat{y}-y_{2})^{2}+(\hat{z}-z_{2})^{2}} \\
      \sqrt{(\hat{x}-x_{3})^{2}+(\hat{y}-y_{3})^{2}+(\hat{z}-z_{3})^{2}} \\
      \sqrt{(\hat{x}-x_{4})^{2}+(\hat{y}-y_{4})^{2}+(\hat{z}-z_{4})^{2}} 
    \end{array}
\right]
\end{align}\



\noindent
方程式(\ref{2-4-1})を$\hat{x}, \hat{y}, \hat{z}$について解くことによりタグの三次元位置座標を求めることが可能である．なお，この式は後に出てくる拡張カルマンフィルタの観測方程式の一部である．次に拡張カルマンフィルタにおける状態方程式を見ていく．機体の速度ベクトル$\textbf{v}_\textbf{r} = [v_x, v_y, v_z]^T$と機体の位置ベクトル$\textbf{p}_\textbf{r} = [x_r, y_y, z_r]^T$ の関係は次式で表せる．

\begin{align}
\label{2-4-2}
\frac{d}{dt}\textbf{p}_\textbf{r}=\textbf{v}_\textbf{r}
\end{align}

\noindent
速度ベクトルの時間微分$\frac{d}{dt} \bf{v_r}$は加速度センサより得られるセンサ値$\textbf{a}_\textbf{b} = [a_x, a_y, a_z]^T$と回転行列$\textbf{R}$を用いて次式で表せる．


\begin{align}
\label{2-4-3}
\frac{d}{dt}\textbf{v}_\textbf{r} = \textbf{R}\textbf{a}_\textbf{b} - \textbf{g}_\textbf{r}
\end{align}

\noindent
ここで，ワールド座標系において重力は$z$軸負方向に重力加速度: $g$分だけ作用するため，$\textbf{g}_\textbf{r}$は$\textbf{g}_\textbf{r} = [0, 0, -g]^T$と定義できる．また，Fig. \ref{quad_fig}におけるr-frameとb-frame間の回転行列$\textbf{R}_\textbf{r}^\textbf{b}$は次式で定義される．

\begin{align}
\label{2-4-4}
\begin{split}
\textbf{R}_\textbf{r}^\textbf{b}(\phi,\theta,\psi)
&=
\left[
    \begin{array}{ccc}
      1 & 0 & 0\\
      0 & \cos\phi & \sin\phi \\
      0 & -\sin\phi & \cos\phi
    \end{array}
\right]
\left[
    \begin{array}{ccc}
      \cos\theta & 0 & -\sin\theta\\
      0 & 1 & 0 \\
      \sin\theta & 0 & \cos\theta
    \end{array}
\right]
\left[
    \begin{array}{ccc}
      \cos\psi & \sin\psi & 0\\
      -\sin\psi & \cos\psi & 0 \\
      0 & 0 & 1
    \end{array}
\right]
\\
&=
\left[
    \begin{array}{ccc}
      \cos\theta\cos\psi & \cos\theta\sin\psi & -\sin\theta\\
      \sin\phi\sin\theta\cos\psi & \sin\phi\sin\theta\sin\psi+\cos\phi\cos\psi & \sin\phi\cos\theta \\
      \cos\phi\sin\theta\cos\psi & \cos\phi\sin\theta\sin\psi-\sin\phi\cos\psi & \cos\phi\cos\theta
    \end{array}
\right]
\end{split}
\end{align}

\noindent
そしてオイラー角$\Theta = [\phi, \theta, \psi]^T$の時間微分と角速度センサより得られる機体角速度$\boldmath{\omega} = [p, q, r]^T$の関係は次式で表せる．


\begin{align}
\label{2-4-5}
\frac{d}{dt}\Theta = \textbf{W} \omega
\end{align}\

\noindent
なお，$\textbf{W}$は[]より

\begin{align}
\label{2-4-6}
\textbf{W}=
\left[
    \begin{array}{ccc}
      1 & \sin\phi\tan\theta & \cos\phi\tan\theta\\
      0 & \cos\phi & -\sin\phi \\
      0 & \sin\phi /\cos\theta & \cos\phi / \cos\theta
    \end{array}
\right]
\end{align}\

\noindent
である．状態ベクトルを$\textbf{x} = [\Theta, \textbf{p}_\textbf{r}, \textbf{v}_\textbf{r}]^T$と定義し，式(\ref{2-4-2})(\ref{2-4-3})(\ref{2-4-5})をまとめると次のようになる．

\begin{align}
\label{2-4-7}
\dot{\textbf{x}}(t)=\textbf{f}(\textbf{x}(t))
\end{align}\

\noindent
ただし$\textbf{f}(\cdot)$は


\begin{align} 
\label{2-4-8}
\textbf{f}(\textbf{x}(t))
=
\left[
    \begin{array}{c}
      \textbf{W}\omega \\
      \textbf{v}_\textbf{r} \\
      \textbf{R}\textbf{a}_\textbf{b} - \textbf{g}_\textbf{r} 
    \end{array}
\right]
\end{align}

\noindent
角速度センサ及び加速度センサから得られる出力値に含まれる観測ノイズ$\delta\omega=[\delta p,\delta q, \delta r]^{T}$及び$\delta \textbf{a}_\textbf{b}=[\delta a_{x},\delta a_{y}, \delta a_{z}]^{T}$を考慮すると式(\ref{2-4-7})は次式のようになる．

\begin{align}
\label{2-4-9}
\dot{\textbf{x}}(t)=\textbf{f}(\textbf{x}(t))+\textbf{B}\textbf{v}
\end{align}

\noindent
ただし，$\textbf{B},\textbf{v}$はそれぞれ


\begin{align} 
\label{2-4-10}
\textbf{B}
=
\left[
    \begin{array}{ccc}
      \textbf{0}_{3\times 3}&\textbf{0}_{3\times 3}&\textbf{I}_{3\times 3} \\
      \textbf{I}_{3\times 3}&\textbf{0}_{3\times 3}&\textbf{I}_{3\times 3}
    \end{array}
\right]^{T},\quad
\textbf{v}=[\delta p,\delta q, \delta r,\delta a_{x},\delta a_{y}, \delta a_{z}]^{T}
\end{align}\

\noindent
である．さらにオイラー法を用いて式(\ref{2-4-9})を離散化すると

\begin{align}
\label{2-4-11}
\textbf{x}(t+1)=\textbf{f}_{t}(\textbf{x}(t))+\textbf{B}_{t}\textbf{v}
\end{align}\

\noindent
ただし

\begin{align}
\label{2-4-12}
\textbf{f}_{t}(\textbf{x}(t))=\textbf{x}(t)+\textbf{f}(\textbf{x}(t))\Delta t, \quad \textbf{B}_{t}=\textbf{B}\Delta t
\end{align}\

\noindent
である．ここで$\Delta t$はサンプリング周期である．

次に観測方程式について見ていく．観測値はUWBモジュールから得られる距離データ，加速度センサデータ，角速度センサデータ，距離センサデータ及びフライトコントローラであるPixracerが推定したヨー角($\psi$)をそれぞれ採用した．
まず，加速度センサ値を用いた角度の算出である．加速度おセンサから得られるセンサ値$\textbf{a}_\textbf{b}$と重力ベクトル$\textbf{g}_\textbf{r}$の関係は回転行列$\textbf{R}$を用いて次のようになる．

\begin{align}
\label{2-4-13}
\begin{split}
\left[
    \begin{array}{c}
      a_{x} \\
      a_{y} \\
      a_{z}
    \end{array}
\right]
&=
\left[
    \begin{array}{ccc}
      \cos\theta\cos\psi & \cos\theta\sin\psi & -\sin\theta\\
      \sin\phi\sin\theta\cos\psi & \sin\phi\sin\theta\sin\psi+\cos\phi\cos\psi & \sin\phi\cos\theta \\
      \cos\phi\sin\theta\cos\psi & \cos\phi\sin\theta\sin\psi-\sin\phi\cos\psi & \cos\phi\cos\theta
    \end{array}
\right]
\left[
    \begin{array}{c}
      0\\
      0 \\
      -g
    \end{array}
\right]\\
&=
\left[
    \begin{array}{c}
      g\sin\theta\\
      -g\cos\theta\sin\phi\\
      -g\cos\theta\cos\phi
    \end{array}
\right]
\end{split}
\end{align}\

式(\ref{2-4-13})の最終項を見ると，$\psi$つまりヨー角成分が現れていないことがわかる．つまり加速度センサのみではヨー角を推定することはできず，そのため今回はヨー角の推定に角速度センサの値とPixracerから得られるヨー角をミキシングしている．ここで観測行列を$\textbf{y}(t) = [a_x, a_y, a_z, d_1, d_2, d_3, d_4, d_h, \psi_{pix}]^T$とおき，式(\ref{2-4-1})，(\ref{2-4-13})と合わせると


\begin{align}
\label{2-4-14}
\textbf{y}(t)=\textbf{h}_{t}(\textbf{x}(t))
\end{align}

\noindent
ただし$\textbf{h}(\cdot)$は

\begin{align} 
\label{2-4-15}
\textbf{h}_{t}(\textbf{x}(t))
=
\left[
    \begin{array}{c}
       g\sin\theta\\
      -g\cos\theta\sin\phi\\
      -g\cos\theta\cos\phi\\
      \sqrt{(x-x_{1})^{2}+(y-y_{1})^{2}+(z-z_{1})^{2}} \\
      \sqrt{(x-x_{2})^{2}+(y-y_{2})^{2}+(z-z_{2})^{2}} \\
      \sqrt{(x-x_{3})^{2}+(y-y_{3})^{2}+(z-z_{3})^{2}} \\
      \sqrt{(x-x_{4})^{2}+(y-y_{4})^{2}+(z-z_{4})^{2}} \\
	z \\
	\psi
    \end{array}
\right]
\end{align}\

\noindent
である．なお$d_h$は距離センサから得られた地面までの距離，$\psi_{pix}$はPixracerが推定したヨー角の値である．式(\ref{2-4-15})に加速度センサ，UWBモジュール，距離センサ，Pixracerからの出力に含まれるノイズ$[\delta a_{x}, \delta a_{y}, \delta a_{z}]^{T},\ [\delta d_1, \delta d_2, \delta d_3, \delta d_4]^{T},\ \delta d_{h},\ \delta \psi_{pix}$を考慮すると観測方程式は


\begin{align}
\label{2-4-16}
\textbf{y}(t)=\textbf{h}_{t}(\textbf{x}(t))+\textbf{w}
\end{align}\

\noindent
となる．ただし$\textbf{w}$は

\begin{align}
\label{2-4-17}
\textbf{w}=[\delta a_{x}, \delta a_{y}, \delta a_{z}, \delta d_1, \delta d_2, \delta d_3, \delta d_4, \delta d_{h}, \delta \psi_{pix}]^{T}
\end{align}

\noindent
以上より状態方程式(\ref{2-4-11})及び観測方程式(\ref{2-4-16})が導出できた．この離散プロセスモデルを2章第1節にて示した拡張カルマンフィルタに対して適用することで位置推定アルゴリズムを得ることができる．





\subsection{従来の構成にオプティカルフローセンサも加えた位置推定システム（複数センサの統合環境）}
ここではオプティカルフローセンサの値も推定アルゴリズムに組み込んだ手法について説明する．次のFig. \ref{system_2}に前のセンサ構成(Fig. \ref{system})にオプティカルフローセンサボードも加えた構成及びFig. \ref{system_core_design2}にオプティカルフローセンサも組み込んだブロック線図をを示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=100mm]{./Fig2/system_2.png}
\caption{Configuration of sensors with optical flow sensor board}
\label{system_2}
\end{center}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[height=100mm]{./Fig2/system_core_design2.png}
\caption{Block diagran of positon control system}
\label{system_core_design2}
\end{center}
\end{figure}

\noindent
図からわかるようにオプティカルフローセンサボードとマイコン（Teensy LC）が新たに加わった．ここで，なぜマイコンを二つ（Arduino Pro Mini，Teensy LC）用いているかの理由を説明する．UWBモジュール（DWM1000）及びオプティカルフローセンサ（PMW3901）はSPI通信を用いてマイコンと通信する．SPI通信はマスタ側とスレイブ側が4線で通信する通信規格であり，スレイブの数が複数あっても1つのマイコンでそれらを処理することが可能である．したがって，Fig. \ref{system_2}に示すArduino Pro Mini1つで3つのセンサ（PMW3901, VL53L0X, DWM1000）の値を処理することを考えた．しかし，実際はPMW3901とDWM1000の2つのセンサ間の相性が悪く，同時に2つのセンサの値を取得することが不可能であった．したがって，オプティカルフローセンサボードの値を処理するマイコン（Teensy LC）とUWBモジュールの値を処理するマイコン（Arduino Pro Mini）を分離し，別々に値を取得してから1つのマイコン（Teensy LC）に値をまとめ，UART通信でRaspberry Piに送る構成を組んだ．また，Teensy LCであるが，このマイコンはArduino Pro Miniと異なり，1つのマイコンで複数のUART通信を行うことが可能であり，図のようにArduino Pro Mini及びNAVIO2の2種類のボードと通信を行う必要があったためこのマイコンを採用するに至った．

次にオプティカルフローセンサの値も拡張カルマンフィルタを組み込んだ式を示していく．このアルゴリズムにおいても状態方程式は式(\ref{2-4-11})と同じものを用いる．つまり，状態方程式側にて，加速度センサの積分値を用いてクアッドロータの変位を推定し，角速度センサの値を用いて姿勢角を推定する．観測方程式であるが加速度センサ値，UWBモジュールから得た値，距離センサ値，Pixracerから得た値を用いることは変わらず，そこにオプティカルフローセンサから得た速度値が加わった．つまり観測行列は$\textbf{y}(t) = [a_x, a_y, a_z, d_1, d_2, d_3, d_4, d_h, \psi_{pix}, v_{rx}, v_{ry}]^T$と表される．ここで$v_{rx}$と$v_{ry}$は式(\ref{2-3-1})で表されるヨー角回転を補正した値である．そして，観測方程式は


\begin{align}
\label{2-4-18}
\textbf{y}(t)=\textbf{h}_{t}(\textbf{x}(t))
\end{align}\

\noindent
となり，$\textbf{h}(\cdot)$は

\begin{align} 
\label{2-4-19}
\textbf{h}_{t}(\textbf{x}(t))
=
\left[
    \begin{array}{c}
       g\sin\theta\\
      -g\cos\theta\sin\phi\\
      -g\cos\theta\cos\phi\\
      \sqrt{(x-x_{1})^{2}+(y-y_{1})^{2}+(z-z_{1})^{2}} \\
      \sqrt{(x-x_{2})^{2}+(y-y_{2})^{2}+(z-z_{2})^{2}} \\
      \sqrt{(x-x_{3})^{2}+(y-y_{3})^{2}+(z-z_{3})^{2}} \\
      \sqrt{(x-x_{4})^{2}+(y-y_{4})^{2}+(z-z_{4})^{2}} \\
	z \\
	\psi \\
	v_x \\
	v_y
    \end{array}
\right]
\end{align}\

\noindent
である．前と同様に各種センサから得られるノイズを考慮すると観測方程式は

\begin{align}
\label{2-4-20}
\textbf{y}(t)=\textbf{h}_{t}(\textbf{x}(t))+\textbf{w}
\end{align}\

\noindent
となり，$\textbf{w}$は

\begin{align}
\label{2-4-21}
\textbf{w}=[\delta a_{x}, \delta a_{y}, \delta a_{z}, \delta d_1, \delta d_2, \delta d_3, \delta d_4, \delta d_{h}, \delta \psi_{pix}, \delta v_{rx}, \delta v_{ry}]^{T}
\end{align}

\noindent
である．以上より新たな構成においても観測方程式が導出できた．これら状態方程式，観測方程式を前節と同様に拡張カルマンフィルタに適用することでオプティカルフローセンサも組み込んだ位置推定アルゴリズムを得ることができる．



\newpage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% 位置制御用クアッドロータの開発 %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{位置制御用クアッドロータの開発}
2.4章で示したクアッドロータは先行研究から利用されてきたものであり，本研究から新たにフライトコントローラ（Pixracer）やオプティカルフローセンサを搭載するに当たって積載物の重量がかさみ，推力不足が懸念された．そして，クアッドロータの推力に余裕が生まれると，機体の応答性が向上し，位置制御の精度が高くなると考えた．そこで，推力の高い新たなクアッドロータのシステムを構築した．その新たに構築したクアッドロータをFig. \ref{quad-rotor2_front}，Fig. \ref{quad-rotor2_back}に示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=85mm]{./Fig2/quad-rotor2_front.png}
\caption{Front side of quad-rotor}
\label{quad-rotor2_front}
\end{center}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[height=70mm]{./Fig2/quad-rotor2_back.png}
\caption{Back side of quad-rotor}
\label{quad-rotor2_back}
\end{center}
\end{figure}

\noindent
図からわかるようにクアッドロータ上面にマイコンやメインコンピュータであるRaspberry Piを配置し，下面にフライトコントローラやオプティカルフローセンサボードを配置した．先行研究から使用してきたクアッドロータの場合にはフライトコントローラを上面に配置していたために重心が上がってしまい，不安定であった．したがって新たに構築したこのクアッドロータは下側にコントローラを配置し，重心が上がらないように配慮した．そして，次の表に詳細な仕様を示す．


\begin{table}[H]
 \caption{Quad-rotor specifications.}
 \label{Quad-rotor specifications}
 \begin{center}
  \begin{tabular}{|c||c|}
   \hline
   Total weight [kg] & 1.05 \\ 
   \hline
   Height [mm]& 200 \\
   \hline
   Width [mm]& 443 \\
   \hline
   Depth [mm]& 443 \\
   \hline
   Propeller size [inch] & 8$\times$4.5\\
   \hline
   Maximum flight time [min]& 10 \\
   \hline
    KV value [rpm/V]&  920\\
   \hline
   Buttery capacity[mAh]& 2650 \\
   \hline
  \end{tabular}
 \end{center}
\end{table}

\noindent
モータやバッテリなど飛行に必要な部品以外に追加で数百gほど搭載可能なスラストが出せるように部品選定を行った．モータの電圧やプロペラの種類にもよるが，最高で約200 gの追加スラストを生み出すことが可能な設計である．また，総飛行時間は約10分であるが，高いパフォーマンス状態で飛行可能な時間は約5分である．







\section{位置推定アルゴリズムの精度評価}
\subsection{従来推定アルゴリズムを用いた位置推定の精度評価}
この章では前章にて説明した位置推定アルゴリズムを用い，クアッドロータの位置を推定し，その推定精度の評価を行う．まず位置推定実験に使用した実験環境を次の図に示す．なお，本実験ではクアッドロータは飛行させず，床に置いた静止状態で目標点における位置を推定した．


\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/experiment_field.png}
\caption{Laboratory used for position estimation and position control experiments}
\label{experiment_field}
\end{center}
\end{figure}

\noindent
まず，クアッドロータの位置を推定する領域を取り囲むように4つのUWBアンカを設置した．アンカは次の図に示すようにカメラ用の三脚の頂点に固定した．

\begin{figure}[H]
\begin{center}
\includegraphics[height=60mm]{./Fig2/anchor_zoom.png}
\caption{Laboratory used for position estimation and position control experiments}
\label{experiment_field}
\end{center}
\end{figure}

\noindent
そして，アンカを設置した位置の絶対座標を次のTable \ref{Absolute position of target UWB anchors}に示す．

\begin{table}[H]
 \caption{Absolute position of target UWB anchors}
 \label{Absolute position of target UWB anchors}
 \begin{center}
  \begin{tabular}{|c|c|c|c|}
   \hline
    & $x$ position [m] & $y$ position [m] & $z$ position [m] \\
   \hline\hline
   Anchor1 &  -5.460 & 2.698 & 1.763\\
   \hline 
   Anchor2 &  5.460 & 2.698 & 1.763\\
   \hline
   Anchor3 &  5.460 & -2.698 & 1.763\\
   \hline
   Anchor4 &  -5.460 & -2.698 & 1.763\\
   \hline
  \end{tabular}
 \end{center}
\end{table}

\noindent
そして，本実験での実験手順を以下に示す．まず，実験室の床に対し，目標点として与える点の真値を可能な限り精度良くマークした．次のTable \ref{Relative coordinates of target points}にその4点の目標値の相対座標を示す．なお，Fig. \ref{experiment_field}において，実験領域に衝撃吸収用のウレタンマットが敷かれているが，この位置推定実験の際には敷かれていないため，マットは真値に対し悪影響を与えない．

\begin{table}[H]
 \caption{Relative coordinates of target points}
 \label{Relative coordinates of target points}
 \begin{center}
  \begin{tabular}{|c|c|c|}
   \hline
    & $x$ position [m] & $y$ position [m] \\
   \hline\hline
   Point0 (Origin) &  0.00 & 0.00 \\
   \hline 
   Point1           &  4.00 & 0.00 \\
   \hline
   Point2           &  4.00 & -3.00 \\
   \hline
   Point3           &  0.00 & -3.00 \\
   \hline
  \end{tabular}
 \end{center}
\end{table}

\noindent
次にクアッドロータの左手前の足が床にマークしたPoint0と重なるようにクアッドロータを床に置く．そして，プログラム内にて座標変換を行い，その一番初めにクアッドロータを接地した点を相対座標系における原点（Point0）としてキャリブレーションを行う．その点において，数十秒間クアッドロータを放置し，次の目標点（Point1）へと手で持って移動させる．Point1においても同様に数十秒間放置した．この動作を他の残り2点でも同様に行い，各点の静止状態における相対座標を，前に示したオプティカルフローセンサを用いない従来の推定手法により推定した．その推定結果を次のFig. \ref{position_verification_2_copy}に示す．




\begin{figure}[H]
\begin{center}
\includegraphics[height=100mm]{./Fig2/position_verification_2_copy.png}
\caption{Position estimation results when the quad rotor is stationary using the conventional estimation method}
\label{position_verification_2_copy}
\end{center}
\end{figure}

\noindent
図中における赤い点がそれぞれの目標点であり，青い線が推定結果を表している．初めにキャリブレーションを行ったPoint0以外の3点において数cmから数十cmほどの定常偏差が生じているが，いずれの点においても誤差1 m以内の精度で位置を推定できていることがわかる．また，点間の移動の過程において，推定された座標の線が直線的でないのは，移動の際に目標となる基準線を与えず，目標点のみ移動の際の指標として与えたためである．目標点同士を線で結び，その上をトレースできれば，結果はより直線に近づくと考えられる．





\subsection{センサの種類及びカルマンフィルタの分散値が位置推定精度に与える影響の考察}
この章では，先行研究において提案された方法を用いて位置推定を行った結果と，本研究において提案する，オプティカルフローセンサも用いた方法を用いて位置推定を行った結果を数値シミュレーションを用いて比較する．また，後者におけるシミュレーションでは，カルマンフィルタにおけるセンサの分散値を変化させ，それが推定結果にどのような影響を与えるかも考察する．まず，シミュレーションに用いるためのセンサ値を実際の実験を通してロギングした．実験方法は床に描いた二等辺三角形の頂点及び線上を，台に固定したクアッドロータがトレースする形で動かし，その際のそれぞれのセンサ値をロギングした．ロギングしたセンサ値はIMU，UWBモジュール，距離センサ，オプティカルフローセンサの値である．また，床面上の線をトレースするのは，クアッドロータにFig. \ref{laser}のように取り付けたレーザポインタから光を下向きに照射し，それが線をなぞるように台を動かすことで実現した．


\begin{figure}[H]
\begin{center}
\includegraphics[height=70mm]{./Fig2/laser.png}
\caption{Laser pointer attached for the purpose of tracing a line drawn on the floor}
\label{laser}
\end{center}
\end{figure}

\noindent
また，設置したUWBアンカの絶対座標をTable \ref{Absolute position of UWB anchors_2}に，床面に描いた二等辺三角形の頂点の相対座標をTable \ref{Relative coordinates of target points_2}に示す．

\begin{table}[H]
 \caption{Absolute position of UWB anchors}
 \label{Absolute position of UWB anchors_2}
 \begin{center}
  \begin{tabular}{|c|c|c|c|}
   \hline
    & $x$ position [m] & $y$ position [m] & $z$ position [m] \\
   \hline\hline
   Anchor1 &  -1.00 & 1.50 & 0.73\\
   \hline 
   Anchor2 &    1.00 & 1.50 & 0.73\\
   \hline
   Anchor3 &    1.00 & -1.50 & 0.73\\
   \hline
   Anchor4 &  -1.00 & -1.50 & 0.73\\
   \hline
  \end{tabular}
 \end{center}
\end{table}



\begin{table}[H]
 \caption{Relative coordinates of target points}
 \label{Relative coordinates of target points_2}
 \begin{center}
  \begin{tabular}{|c|c|c|}
   \hline
    & $x$ position [m] & $y$ position [m] \\
   \hline\hline
   Point0 (Origin) &  0.00 & 0.00 \\
   \hline 
   Point1           &  1..00 & 0.00 \\
   \hline
   Point2           &  0.00 & 1.00 \\
   \hline
   Point3           &  -1.00 & 0.00 \\
   \hline
  \end{tabular}
 \end{center}
\end{table}


\noindent
二等辺三角形の底辺の中点を相対座標系の原点とし，クアッドロータを最初に設置した地点としてキャリブレーションを行う．クアッドロータをPoint0からPoint3まで順に動かし，最後にPoint0に戻した．また，各点においてクアッドロータを10秒間ずつ静止させた．以上の実験を通して集めたデータを数値計算ソフトであるMatlabを用いて作製した位置推定プログラムに対して適用し，位置推定の計算をオフラインの環境で行った．ここで，拡張カルマンフィルタを含むカルマンフィルタにおいて調整可能なパラメータは主に共分散行列の初期値及び観測方程式における各センサの分散値である．数値シミュレーションにおいて初期値は変えず，シミュレーションに使用するセンサの種類及び，それぞれのセンサの分散値を変化させ，それの結果を見ていく．次の表に各シミュレーションにおいて使用したセンサの種類及び，分散値を示す．



\begin{table}[H]
 \caption{Type of used sensors and variance values}
 \label{Type of used sensors and variance values}
 \begin{center}
  \begin{tabular}{|c|c|c|c|}
   \hline
                  & Accelerometer  &  UWB module & Optical flow sensor   \\
   \hline\hline
   Simulation1 &  0.4    & 0.02   & -        \\
   \cline{2-4}
                   &   0.004 & 0.01 & 0.0006  \\
   \hline 
   Simulation2 &    0.4 & 0.02 & -       \\
   \cline{2-4}
                   &    0.004     &    0.000001    &     0.06     \\
   \hline
   Simulation3 &    0.4    & 0.02 & - \\
   \cline{2-4}
                   &    0.004 & 0.1 &  0.0006 \\
   \hline
  \end{tabular}
 \end{center}
\end{table}

\noindent
シミュレーション1から3において，加速度センサ及びUWBモジュールのみを用いる場合はそれらの分散値を変更せず，3種類のセンサを用いる場合のみ分散値を変更した．各シミュレーションにおける結果を次に示す．それぞれのシミュレーションにおいて，青色の線がUWBモジュールと加速度センサの観測値のみフュージョンしたもの，橙色はUWBモジュール，加速度センサ，オプティカルフローセンサの3種類をフュージョンしたもの，黄色はオプティカルフローセンサから得られた速度値を単純に積分して足し合わせたものである．なお，シミュレーション1においてはPoint2付近における拡大図も合わせて示す．






\begin{figure}[H]
\begin{center}
\includegraphics[height=100mm]{./Fig2/result1.png}
\caption{Result of simulation1}
\label{result1}
\end{center}
\end{figure}


\begin{figure}[H]
\begin{center}
\includegraphics[height=100mm]{./Fig2/result1_up.png}
\caption{Enlarged view of Fig. \ref{result1}}
\label{result1_up}
\end{center}
\end{figure}


\begin{figure}[H]
\begin{center}
\includegraphics[height=100mm]{./Fig2/result3.png}
\caption{Result of simulation2}
\label{result3}
\end{center}
\end{figure}




\begin{figure}[H]
\begin{center}
\includegraphics[height=100mm]{./Fig2/result4.png}
\caption{Result of simulation3}
\label{result4}
\end{center}
\end{figure}



\noindent
シミュレーション1は3種間センサの分散値をトライアンドエラーで調整し，オプティカルフローセンサの値を積分した際に生じるドリフトの影響やUWBモジュールの測距誤差が原因の推定値の分散の影響が少なくなるようにして求めた結果である．また，シミュレーション2はUWBモジュールの分散値を小さくし，UWBモジュールから得られる観測値の影響を大きくした結果である．シミュレーション3はそれとは逆にオプティカルフローセンサの分散値を小さくし，オプティカルフローセンサから得られる観測値の影響を大きくした．次にそれぞれの結果について考察していく．まず，分散値の調整を行ったシミュレーション1であるが，青色の線は，目標点間の移動する過程において波打っていることがわかる．また，拡大図においても，目標点付近において青色の線は値の分散が生じている．しかし，橙色の線は移動中の過程も線が揺らぐことなく直線的であり，目標点付近においても分散が生じることなく点での曲がり角が明確に出ていることがわかる．黄色の線は直線的であり分散も見られないが，目標点付近において他の二線とは離れた位置に定常値を取っている．青色のUWBモジュールと加速度センサのみを用いた場合には，UWBモジュールの測距誤差が原因で推定値にも分散が生じたが，橙色の線ではオプティカルフローセンサの効果によりその分散を打ち消せているため，こういった直線的で分散の少ない結果を得ることができた．また，黄色の単純積分値ではUWBモジュールを用いた座標の補正が効かないため，このような積分値がドリフトして傾いた図形の結果を得た．次にシミュレーション2であるが，橙色の線はUWBモジュールの影響を大きくしたため，分散が大きくなりこのような直線的ではない結果となった．しかし，座標の補正はUWBモジュールの効果により働いているため，目標値の座標は青色の線と橙色の線で一致していることがわかる．最後にシミュレーション3においてオプティカルフローセンサの影響を強くした橙色の結果は黄色の線同様，滑らかではあるが，UWBモジュールの座標補正が弱くなり，ドリフトした結果となっている．これらのシミュレーション結果より，分散値の値を適切に調整した上で，既存の位置推定システムにオプティカルフローセンサの観測値も組み込むことにより，座標をUWBモジュールの観測値より推定しつつ，分散の少ない推定値を得ることが可能であるという結論を得た．



\section{位置制御アルゴリズムの評価}
前章までは各種センサを用いたクアッドロータの位置推定方法について述べてきた．この説では実際にクアッドロータを飛行させ，提案する位置制御手法の精度を見ていく．

\subsection{位置制御手法}
まず，この節ではFig. \ref{system_core_design}及びFig. \ref{system_core_design2}にある目標座標と推定座標の偏差からクアッドロータの位置を制御する手法について述べる．これから述べる手法は[][][]などの手法を参考にした．まず，推定した座標と目標座標との偏差より仮想入力の値を次のように設定する．

\begin{align}
\label{5-1-1}
&U_{x} = k_{px}(x_d - \hat{x} ) + k_{dx}(\dot{x}_d - \dot{\hat{x}} ) + k_{ix} \int_0^t (x_d - \hat{x} ) d\tau  \\
&U_{y} = k_{py}(y_d - \hat{y} ) + k_{dy}(\dot{y}_d - \dot{\hat{y}} ) + k_{iy} \int_0^t (y_d - \hat{y} ) d\tau  
\end{align}

\noindent
$x$軸，$y$軸はそれぞれ機体座標系ではなく，ワールド座標系における軸を表している．式(\ref{5-1-1})からわかるように仮想入力の値は偏差を用いたPIDコントローラより計算できる．これらの入力値を用いると，ピッチ角（$\phi$）及びロール角（$\theta$）の目標値は以下の式により計算できる．

\begin{align}
\label{5-1-2}
&\phi^{des} = \frac{1}{g} (U_x \sin \psi - U_y  \cos \psi)  \\
&\theta^{des} = \frac{1}{g} (U_x \cos \psi + U_y  \sin \psi).
\end{align}

\noindent
これらの得た値をフライトコントローラであるPixracerが受け取れるPWM信号に変換した後，コントローラに送信することで，クアッドロータの各ロータの回転数が制御され，姿勢角が追従するという流れである．またヨー角（$\psi$）に関しては，飛行開始時に置いたクアッドロータの機首が向いている方向を目標角度とし，推定した現在角度との偏差において単純なPID制御器を組むことにより機首の向きが回転しないように制御を行う．


\subsection{ステレオカメラを用いた位置測定システム}
\subsubsection{位置計測システムの原理及び構築}
クアッドロータの位置を制御した場合，位置が精度良く制御できているかを確認するため，それの指標として位置の真値が必要である．飛行体や地上移動機に関わらず，移動型のロボットの真値を計測するにはFig. \ref{VICON}に示すVICON[]などといったモーションキャプチャのシステムを用いるのが多い．しかし，こういったシステムは機材だけで数百万円の価格であり，設置費を含むと数千万円に上ることもある．また，Fig. \ref{VICON_room}のように一度室内に環境構築を行うと，システムを他の部屋に移動させることが困難である．したがって，価格がVICONよりも安価であり，必要に応じてシステムを移動させられることなどの利点があることから本論文ではステレオカメラを用いた位置の計測システムを構築した．Fig. \ref{camera_with_chess}に環境構築したステレオカメラシステムを示す．

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}

      \begin{minipage}[t]{0.5\hsize}
        \begin{center}
         \includegraphics[height=45mm]{./Fig2/VICON.jpg}
	  \caption{VICON[]}
        \label{VICON}
        \end{center}
      \end{minipage}

      \begin{minipage}[t]{0.5\hsize}
        \begin{center}
          \includegraphics[height=45mm]{./Fig2/VICON_room.jpg}
          \caption{The room where VICON is installed[]}
          \label{VICON_room}
        \end{center}
      \end{minipage}

    \end{tabular}
  \end{center}
\end{figure}


\begin{figure}[H]
\begin{center}
\includegraphics[height=70mm]{./Fig2/camera_with_chess.png}
\caption{Installed stereo camera and chessboard}
\label{camera_with_chess}
\end{center}
\end{figure}

\noindent
システムの大まかな構成は二台の高速度カメラからなるステレオカメラとデスクトップPCである．使用したカメラはPoint Grey社（現FLIR社）製のGrasshopper3(GS3-U3-32S4C-C)である．Fig. \ref{high-speed_camera}に外観を示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=50mm]{./Fig2/high-speed_camera.jpg}
\caption{High-speed camera(GS3-U3-32S4C-C)}
\label{high-speed_camera}
\end{center}
\end{figure}

\noindent
そして詳細な仕様をTable \ref{high-speed_camera_tab}に示す．

\begin{table}[H]
 \caption{High-speed camera specifications.}
 \label{high-speed_camera_tab}
 \begin{center}
  \begin{tabular}{|c||c|}
   \hline
   Maximum resolution (H$\times$V)[pixel]& 2048$\times$1536 \\ 
   \hline
   Maximum frame rate [fps]& 121 \\
   \hline
   Image sensor& Sony IMX252 \\
   \hline
   Sensor type& CMOS \\
   \hline
   Shutter type&Global shutter\\
   \hline
   Interface & USB3.1 Gen 1 \\
   \hline
   Weight [g] & 90 \\
   \hline
  \end{tabular}
 \end{center}
\end{table}

\noindent
そして画像保存に使用したデスクトップPCの仕様をTable \ref{PC_tab}に示す．

\begin{table}[H]
 \caption{High-speed camera specifications.}
 \label{PC_tab}
 \begin{center}
  \begin{tabular}{|c||c|}
   \hline
   CPU & intel Core i7 \\ 
   \hline
   Motherboard & ASUS Z270F GAMING \\
   \hline
   Graphic & GTX1050Ti \\
   \hline
   RAM [GB] & 64 (DDR4) \\
   \hline
   OS & Windows 10 $\times$64  \\
   \hline
   Storage　[GB] & 256 (SSD) $+$ 2000 (HDD)  \\
   \hline
   Software & FlyCapture2  \\
   \hline
  \end{tabular}
 \end{center}
\end{table}

\noindent
Table \ref{high-speed_camera_tab}からわかるように，カメラの性能を最大限引き出した際の仕様は，解像度が2048$\times$1536とフルHDを超える解像度であり，フレームレートも100 fpsを上回る121 fpsにて画像または動画を撮影可能である．しかし，Table \ref{PC_tab}に示すPCを用いてもカメラ2台を用いた状態で，1024$\times$768の解像度，100 fpsが限界であった．したがって本システムではこの環境で出せる最高解像度，最高fpsのこの設定で画像を撮影した．なお，撮影した画像のフォーマットは圧縮率75\%のJPEGである．画像計測を用いた位置や角度の検出では撮影された画像中のマーカーを追跡することによりそれを実現する．VICONでは移動物体に取り付けられた反射マーカーに赤外線を照射することで反射した光の重心を求めることで位置や角度を検出する．本システムでは赤外線を照射しないため，それ自体が赤外光を放出する赤外線LEDをクアッドロータの位置検出用のマーカーとして採用した．Fig. \ref{LED_with_quad1}，Fig. \ref{LED_with_quad2}に二種類のクアッドロータに取り付けられた赤外線LEDを示す．


\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}

      \begin{minipage}[t]{0.5\hsize}
        \begin{center}
         \includegraphics[height=55mm]{./Fig2/LED_with_quad1.png}
	  \caption{Old quad rotor with infrared LED}
        \label{LED_with_quad1}
        \end{center}
      \end{minipage}

      \begin{minipage}[t]{0.5\hsize}
        \begin{center}
          \includegraphics[height=50mm]{./Fig2/LED_with_quad2.png}
          \caption{New quad rotor with infrared LED}
          \label{LED_with_quad2}
        \end{center}
      \end{minipage}

    \end{tabular}
  \end{center}
\end{figure}


\noindent
先行研究から使われてきたクアッドロータ（Fig. \ref{LED_with_quad1}）には2台のカメラ間で同期が取れるようにリレーが取り付けられている．メインコンピュータであるRaspberry Piから信号を送ることでLEDの点灯を制御可能なため，光ったタイミングを検出することで2台のカメラのマーカー検出タイミングを揃えることができる．先行研究においてはこの方法でカメラ間同期を取っていた．そして，新しく本論文にて新しく開発したクアッドロータは同期用のリレーが付いていない．これの理由について説明する．今回用いた高速度カメラにはPCへのデータ送信用のコネクタ以外に外部へ信号を送ることや受け取ることが可能なコネクタが備わっている．これを用い，片方のプライマリカメラからもう片方のセカンダリカメラへと同期用の信号を送り，その信号をトリガにしてセカンダリカメラは撮影を開始できるため，2台間の同期が取れた状態で画像を撮影可能である．本論文では新たにこの同期方法を採用したため，Fig. \ref{LED_wiith_quad2}のクアッドロータにはリレーが備わっていない．クアッドロータに搭載したLEDマーカーの光はカメラで撮影可能であるが，画像中でLEDの光のみを浮き上がらせて検出が容易になるようカメラにはFig. \ref{}に示す赤外線透過フィルタ（IR-80）を装着してある．



\begin{figure}[H]
\begin{center}
\includegraphics[height=50mm]{./Fig2/infrared_filter.jpg}
\caption{Infrared longpass filter}
\label{infrared_filter}
\end{center}
\end{figure}



\noindent
赤外線LEDを光らせた状態でこのレンズにより撮影した画像を次に示す．


\begin{figure}[H]
\begin{center}
\includegraphics[height=50mm]{./Fig2/high-speed_image.png}
\caption{Image taken of glowing infrared LED through filter}
\label{high-speed_image}
\end{center}
\end{figure}

\noindent
フィルタを通すことにより，LEDの光のみを浮き上がらせられているのがわかる．次にステレオカメラを用いた位置計測のアルゴリズムについて簡単に説明する．ここで説明する手法は[]や[]に詳しい方法が載っている．Fig. \ref{stereo_camera}に示すように左右に並んだ2台のカメラで同じ対象物を撮影したとする．

\begin{figure}[H]
\begin{center}
\includegraphics[height=90mm]{./Fig2/stereo_camera.png}
\caption{Definition of stereo camera coordinates}
\label{stereo_camera}
\end{center}
\end{figure}

\noindent
ここでは2台のカメラの画像平面が同一平面上にあり，光軸が平行であり，同じ焦点距離$f$を持つとする．また，カメラの中心間距離を$L$とする．その位置にカメラを設置した状態で同じ対象物を撮影すると，左側のカメラでは$x_l$，右側のカメラでは$x_r$の座標の画像平面にそれぞれ画像が投影される．この座標の差$d$が視差と呼ばれ，


\begin{align}
\label{}
d = x_l - x_r 
\end{align}

\noindent
と表せる．そして，図において三角形の相似の関係を用いると


\begin{align}
\label{}
\frac{L-d}{Z-f} = \frac{L - (x_l - x_r)}{Z - f} = \frac{L}{Z}
\end{align}

\noindent
と表わせ，この式を変形することで

\begin{align}
\label{}
Z = \frac{fL}{x_l - x_r}
\end{align}

\noindent
となり，対象物までの距離$Z$を求めることができる．同様に$x$軸方向$y$軸方向についても

\begin{align}
\label{}
X = \frac{x_l L}{x_l - x_r}, \ Y = \frac{y_l L}{x_l - x_r} = \frac{y_l L}{x_l - x_r}
\end{align}

\noindent
となり，対象物の位置を求められる．以上よりステレオカメラを用いて対象物の位置$(X, Y, Z)$を求める方法が導出できた．しかし，実際には2台のカメラの画像平面が同一平面になるよう置くことや光軸が平行になるように置くことは物理的に不可能である．そこで，行うのがステレオカメラのキャリブレーションである．Fig. \ref{camera_with_chess}に示したチェスボードを2台のカメラで撮影し，アルゴリズムにしたがって計算することで，カメラ間の位置関係を表す並進ベクトル$T$及び回転行列$R$を算出可能である．それらに加え，カメラレンズの歪みやレンズの取付誤差が起因する画像の歪みを補正するためのカメラパラメータも同様のチェスボードを撮影した画像から得ることができる．これらのパラメータを用い，先に示した方法で計算を行うことでクアッドロータの位置を測定した．なお，これらの演算は全てPython2のモジュールとして提供されるモジュール，OpenCVの機能を用いて行った．

\subsubsection{奥行き誤差の検証}
ここで，ステレオカメラを用いた位置計測における奥行き誤差について議論する．Fig. \ref{error_stereo}に設定する状況を考える．ステレオ画像での計測精度は画像中の1画素が実際にどのくらいの長さに対応するかで決まる． つまり，カメラの解像度，対象物までの距離，カメラ間距離によって変わる． また，画像平面中の画像が投影される画像素子は，それ自体が大きさを持っているため，実際の空間中では計測対象点はある範囲内ということでしか特定できない． その特定可能な最小の範囲がステレオカメラにおける計測誤差となる．


\begin{figure}[H]
\begin{center}
\includegraphics[height=90mm]{./Fig2/error_stereo.png}
\caption{Error in z direction of stereo camera}
\label{error_stereo}
\end{center}
\end{figure}


\noindent
図における$\delta x$が横方向誤差であり，$\delta z$が奥行き誤差である．また，図に示す$L'$を計算のために導入する．まず，三角形の相似より

\begin{align}
\label{}
\rm{Pixel} : \frac{L'}{2} = f : l
\end{align}

\noindent
が言える．これを変形し

\begin{align}
\label{ste_1}
L' = \frac{2 \rm{Pixel}}{f}
\end{align}

\noindent
となる．同様に相似より

\begin{align}
\label{ste_2}
\delta z = \frac{L'l}{L - L'}
\end{align}

\noindent
が言える．式(\ref{ste_1})を式(\ref{ste_2})に代入し，整理すると

\begin{align}
\label{}
\delta z = \frac{2 l^2 \rm{Pixel}}{fL - 2l \rm{Pixel}}
\end{align}

\noindent
となり，奥行き誤差が導出できた．同様に$x$方向，$y$方向誤差も相似より計算できるが，$\delta z$に比べて極めて小さく，無視できるため割愛する．奥行き誤差$\delta z$が100 mm以下になるように次の表のパラメータを用いて$l$を計算すると，$l　= 8.959 \ \rm{m}$という結果を得たため，カメラから飛行するクアッドロータまでの距離が8 m以下になるように設定して実験を行うこととする．



\subsection{ロータの推力測定}
各ロータの推力に差がないかを確認するために実験を行った．実験方法は飛行実験に用いたクアッドロータに搭載してあったロータに対し同一のプロペラを装備し，2500 rpmから6000 rpmまで500 rpmずつ回転数を変化させてプロペラが発生させる推力を計測した．まず，実験時の様子を次の図に示す．



\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/thrustmeter.png}
\caption{Configuration for measuring propeller thrust}
\label{thrustmeter}
\end{center}
\end{figure}




\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/thrust_prop.png}
\caption{Propeller fixed to thrust meter}
\label{thrust_prop}
\end{center}
\end{figure}

\noindent
スラストメータに対し，プロペラが装備されたロータを設置する．次に各回転数になるようスラストメータからPWM信号をESCに送り，ロータを回転させる．ロータの回転数（rpm）は図中のパルスカウンタを用いて確認した．そして各回転数における発生する推力をスラストメータから読み取った．推力は各回転数において3回ずつ計測し，それらの平均を取った．各回転数における計測した推力を次に示す．



\noindent
次に，飛行実験に実際に用いたプロペラと予備用に用意したプロペラの同回転数時に発生させる推力の差を確認した．理由は飛行に使用したプロペラは十分な推力が発生しておらず，姿勢角制御に悪影響を与えていると考えたためである．ここでは飛行に使用したプロペラをプロペラ1，予備のプロペラをプロペラ2とする．2種類のプロペラを次の図に示す．



\begin{figure}[H]
\begin{center}
\includegraphics[height=50mm]{./Fig2/prop1.jpg}
\caption{Propeller1}
\label{prop1}
\end{center}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[height=50mm]{./Fig2/prop2.jpg}
\caption{Propeller2}
\label{prop2}
\end{center}
\end{figure}



\noindent
どちらも直径8 inch，ピッチ4 inchの設計である．しかし，図より翼面積に大きな差があることがわかる．次の図に2種類のプロペラの各回転数における計測した推力を示す．計測方法は前の実験と同様であり，各回転数において2種類のプロペラで3回づつ推力を計測し，平均を取った．また，最小二乗法により近似した二次曲線も合わせて示す．


\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/thrust_2.png}
\caption{Thrust measurement results of two types of propellers}
\label{thrust_2}
\end{center}
\end{figure}



\noindent
結果からわかるように，いずれの回転数においてもプロペラ1の推力の方がプロペラ2に比べて発生させる推力が低い．推力を$f$とし，回転数を$\omega$ [rpm]とすると，近似曲線の式はプロペラ1で

\begin{align}
f_1 = 5.98\times10^{-9} \omega^2
\end{align}

\noindent
となり，プロペラ2で

\begin{align}
f_2 = 9.94\times10^{-9} \omega^2
\end{align}


\noindent
となった．推力係数はプロペラ2がプロペラ1の1.67倍という結果を得た．直径，ピッチ共に同じ値にも関わらず，このような結果となったのは翼面積の影響が大きいと考えられる．新たに構築したクアッドロータを用いて行った飛行制御実験において，従来の推定手法及び新たに提案した推定手法ともに従来のクアッドロータを用いた実験よりも，位置制御性能が低下したのは，こういった推力不足によるものが大きいと考えられる．各ロータでの推力が十分でなかったため，姿勢角制御の応答が悪くなり，こういった結果になったと言える．




\subsection{従来の推定アルゴリズムによる制御性能の評価}
2.4章にて示した従来の位置推定方法及び5.1章にて示した位置制御手法を用いてクアッドロータの位置を制御する実験を行った．次の2つの実験で用いたクアッドロータはFig. \ref{quad-rotor}に示す従来機である．

\subsubsection{定点における位置保持実験}
ある目標点を目標値とし，その点から逸脱することなくクアッドロータの位置を制御可能かどうかを確認するのが目的である．実験方法を以下に示す．まず，クアッドロータをアンカで取り囲まれた空間内の床面に置く．そして，その位置が原点になるようにプログラム内で座標変換を行い，キャリブレーションを行う．キャリブレーション終了後，クアッドロータを手動制御にて離陸させる．飛行が安定した時点でモードを手動制御モードから自動制御モードへと切り替え，その際の推定された位置をロギングする．なお，この実験時にはクアッドロータのスロットルの制御はマニュアル操作にて行った．本実験における目標値は$(x, y) = (0, 0)$つまり，実験開始時にクアッドロータを置いた位置である．結果をFig. \ref{position_control_origin_2}に示す．




\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/position_control_origin_2.png}
\caption{Result of static position hold experiment}
\label{position_control_origin_2}
\end{center}
\end{figure}

\noindent
図中の赤い点が目標値を示す．なお，このグラフは自動制御モードに切り替えてから2分間の飛行をロギングしたものである．目標値からの標準偏差は0.083mであり，目標値からの最大偏差は0.406 mという結果を得た．先行研究においては，姿勢角制御の周波数が低いことが原因で位置制御が発散していた．しかし，フライトコントローラを新たに搭載し，位置制御と姿勢角制御を分けたことにより処理が軽くなったため，位置の発散が起きなくなり，こういった結果を得ることができたと考えられる．



\subsubsection{複数点間を移動する位置制御実験}
次に行ったのが，複数の目標点を移動する位置制御実験である．使用したクアッドロータは前述した，前の定点保持実験と同一の機体であり，位置推定方法も同様の方法である．実験目的は，目標値が複数存在し，飛行中にその値が変更された場合であっても，目標値から逸脱することなく位置を制御可能か確認することである．実験方法を以下に示す．まず，クアッドロータを床面に置き，原点としてキャリブレーションを行う．そして手動制御で離陸させた後，安定した時点で自動制御モードに切り替える．ここまでの方法は前の実験と同様である．その後，目標値を手元の送信機より切り替え，複数点を移動させる．そして，その際の推定された位置をロギングする．目標値の座標を次のTable \ref{Absolute position of way points}に示す．

\begin{table}[H]
 \caption{Absolute position of way points}
 \label{Absolute position of way points}
 \begin{center}
  \begin{tabular}{|c|c|c|}
   \hline
    & $x$ position [m] & $y$ position [m] \\
   \hline\hline
   Point0 (Origin) &  0.00 & 0.00 \\
   \hline 
   Point1           &  1.50 & -1.00 \\
   \hline
   Point2           &  -1.50 & 1..00 \\
   \hline
  \end{tabular}
 \end{center}
\end{table}



\noindent
そして，実験結果をFig. \ref{point_to_point_2}に示す．




\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/point_to_point_2.png}
\caption{Result of point to point experiment}
\label{point_to_point_2}
\end{center}
\end{figure}


\noindent
目標値が原点（Point0）の時，細かな振動はあるが，偏差の中心は目標値と一致していることがわかる．しかし，移動後の点Point1，Point2においては定常偏差が発生し，偏差の中心が目標値からずれていることがわかる．これの原因はUWBアンカの設置誤差が起因する位置推定誤差やUWBモジュールはモジュール間の距離が近くなると測距精度が悪くなることなどが考えられる．







\subsection{提案する推定アルゴリズムによる制御性能の評価}
次に，従来の推定方法及び，2.5章にて示した新たな推定手法の2種類の推定方法により位置制御の実験を行うことで，2つの推定方法による制御性能の違いを比較した．新たな推定手法では，オプティカルフローセンサの値も必要なため，用いた機体はFig. \ref{quad-rotor2_front}に示す新たに構築したクアッドロータである．実験内容は5.4.1章にて示したものと同様であり，1点を目標地点とする位置保持実験である．実験方法も同様であり，2種類の推定プログラムを実験試行毎に切り替えて位置制御を行った．まず，従来の推定手法による実験の結果2つを示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/withoutopt_1.png}
\caption{Position control result using conventional estimation method (trial 1)}
\label{withoutopt_1}
\end{center}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/withoutopt_2.png}
\caption{Position control result using conventional estimation method (trial 2)}
\label{withoutopt_2}
\end{center}
\end{figure}


\noindent
試行1では約18秒間，位置制御状態にて飛行していた．飛行制御の最後の方では大きく目標点から逸脱し，制御不能に陥ったため，制御を終了し，着地させた．試行2も同様に，位置制御を開始してから約28秒後には制御不能のため制御を終了した．次にオプティカルフローセンサも推定に組み込んだ結果を次に示す．

\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/withopt_1.png}
\caption{Position control results using an estimation method incorporating an optical flow sensor (trial3)}
\label{withopt_1}
\end{center}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[height=80mm]{./Fig2/withopt_2.png}
\caption{Position control results using an estimation method incorporating an optical flow sensor (trial4)}
\label{withopt_2}
\end{center}
\end{figure}

\noindent
試行3は約60秒間，制御状態で飛行していた．しかし，本試行においても飛行制御中に不安定状態に陥り，制御を終了した．試行4は約90秒間制御状態であり，意図的に制御を終了するまで安定してホバリングを続け，制御不能状態には至らなかった．

次にこれらの結果を考察していく．まず，従来の推定方法を用いた試行1，2では安定した飛行制御が不可能であった．以前の機体の場合，章5.4.1で示した実験のように飛行制御の開始時から終了時点まで目標地点から大きく逸脱することなく制御可能であったが，新たに構築した機体の場合，それをなし得なかった．これの原因は各ロータの推力不足によるものと，位置制御におけるPIDゲインの調整不足によるものが考えられる．次節にて示すが，実験に使用したプロペラ及びロータをスラストメータに取り付け，推力を計測したところ，その推力が十分なものではなかった．したがって，各ロータから発生する推力が不十分であり，姿勢角制御の応答が悪くなり，位置制御の結果も悪くなったと考えられる．また，位置制御におけるPIDゲインは本機体においては調整を行わず，以前の機体と同じ値を採用した．しかし，新たな機体は重量や発生推力が異なるため，そのゲインが適切ではなかったため，このような位置制御精度の低さにつながったと言える．







\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% 結言 %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{結言}
本研究では非GPS環境における鋼構造物点検を目的とした自律飛行可能なクアッドロータの開発を行った．クアッドロータの自己位置推定にはUWBモジュール，IMU，距離センサの値を参照し，それらを拡張カルマンフィルタ（EKF）に適用することで位置を推定した．また，先行研究では用いられなかったオプティカルフローセンサも新たに搭載し，位置推定及び位置制御の精度が向上するかを確認した．

まず，初めに行ったのが，先行研究において未達成であった位置制御を達成するためのアプローチである．先行研究において，上記のUWB，IMU，距離センサを用いた構成にてクアッドロータの位置を推定することは達成されていた．しかし，メインコンピュータを用いてクアッドロータの姿勢角を制御する際，それの周波数が不十分であり，クアッドロータの位置が発散してしまっていた．そこで，新たに別のフライトコントローラを搭載し，位置推定用のコンピュータと姿勢角制御用のコンピュータを分けた．それにより演算負荷が軽くなったため，クアッドロータの位置を制御することが可能になった．先行研究から用いられてきたクアッドロータを用いた位置制御では定点ホバリング及び3点間を移動する制御を行った．まず，定点ホバリングでは，目標位置（原点）からの標準偏差が0.083 m，最大偏差が0.406 mという位置制御結果を得た．また，3点間を移動する制御では，移動後の点において定常偏差が発生したが，目標点を大きく逸脱することなく，安定した位置制御を行うことができた．

次に，上で行った位置制御において発生した，$x-y$平面上でのクアッドロータの細かな振動を取り除くために新たにオプティカルフローセンサを搭載することを考えた．それに伴い，以前のクアッドロータでは搭載するスペースや推力が不足すると考えられため，発生可能な推力が大きく，センサなどが搭載可能な余剰スペースがある新たなクアッドロータを構築した．そのクアッドロータに対しオプティカルフローを搭載し，実験したデータから位置推定の精度を確認するシミュレーションを行ったところ，位置推定の精度が向上し，オプティカルフローセンサの有効性を確認することができた．しかし，オプティカルフローセンサも位置推定に組み込んだ状態で飛行させ，位置制御を行ったところ，オプティカルフローセンサの値を参照していない場合よりも位置制御の精度は向上したが，以前のクアッドロータよりも格段に位置制御の精度が向上するという結果は得られなかった．理由としては，クアッドロータの変更に伴い，機体特性が変化したにも関わらず，位置制御用のゲインの調整を行わなかったことや，フライトコントローラにおける姿勢角制御用のゲインの調整が不十分であったことなどが理由として考えられる．また，実際に実験に用いられたプロペラと，予備用に確保した別のプロペラの同回転数時における発生推力を確認したところ，発生する推力に大きな違いがあることがわかった．実験に使用したプロペラは比較したプロペラよりもいずれの回転数域においても平均？ \%ほど発生推力が低かった．したがって，推力が不十分であったため機体の姿勢角制御における応答性が悪く，位置制御結果に影響を及ぼしたことも理由の一つとして考えられる．

今後の課題としては，部品選定を適切に行なった上で推力が確実に発生させられる機体構成に改善し，位置制御ゲインや姿勢角制御ゲインをさらに調整する必要がある．また，位置の真値を計測するのに用いたステレオカメラは，奥行方向の計測誤差が大きく，ローパスフィルタを通さなければ，適切な値を得られなかったため，カメラを複数台用いるなどして測定精度の向上を図る必要がある．さらに，本研究ではUWBモジュールのアンカの数が4つと計測可能な範囲や計測精度が限られていたため，計測周波数が落ち込まない工夫をした上でアンカの数をさらに増やす必要があると考えられる．





\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% 謝辞 %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{謝辞}
\addcontentsline{toc}{section}{謝辞}
この研究テーマを与えて下さり，またご指導ご鞭撻を下さった澤田祐一教授，東善之助教授に感謝致します．また，加えて報告会において貴重な意見を下さったロボティクス研究室の飛行ロボットグループメンバやアドバイスを下さった研究室の皆様に感謝致します．加えて，本研究の学会発表の際に共同研究者としてお名前を貸して下さり，またミーティングの際には貴重なアドバイスを下さった知的構造システム学研究室の増田先生や防振システム工学研究室の三浦先生に心より感謝を申し上げたいと思います．最後にクアッドロータの実験を行うに至って貴重な部屋を貸して下さった産学公連携推進センターの皆様にも謝意を表します．






\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{thebibliography}{99}
\addcontentsline{toc}{section}{参考文献}


\bibitem{a}
国土交通省，橋梁の現状，\\
\url{http://www.mlit.go.jp/sogoseisaku/maintenance/_pdf/research01_pdf01.pdf}，2018/02/02閲覧

\bibitem{p}
国土交通省，道路構造物の現状（橋梁），\\
\url{http://www.mlit.go.jp/road/sisaku/yobohozen/yobo1_1.pdf}，2018/02/02閲覧

\bibitem{b}
大阪市立大学，橋の鋼鉄部材を検査できる橋梁検査ロボット バイリム（BIREM）の開発，\\
\url{https://www.osaka-cu.ac.jp/ja/news/2013/e4oxuo}，2018/02/02閲覧

\bibitem{c}
次世代インフラ用ロボット技術・ロボットシステム～現場実証ポータルサイト～，\\
\url{http://www.c-robotech.info/}平成26年度現場検証技術\url{db-1/}平成26年度橋梁維持管理部会\url{db/}橋梁-富士フイルム，2018/02/02閲覧

\bibitem{d}
水谷将馬ら，錯雑した構造体中で飛行が可能な回転球殻を持つクアッドロータ，ロボティクス・メカトロニクス講演会2014，(2014)，1-4.

\bibitem{e}
東北大学，Human-Robot Informatics Laboratory, ぶつかっても落ちないドローン(球殻ヘリ)の研究，\\
\url{http://www.mlit.go.jp/sogoseisaku/maintenance/_pdf/research01_pdf01.pdf}，2018/02/02閲覧

\bibitem{f}
構造物メンテナンス研究センター CAESAR，\\
\url{http://www.pwri.go.jp/caesar/manual/}，2018/02/02閲覧

\bibitem{g}
S. Akahori, Y. Higashi, A. Masuda, K. Takeuchi,
Development of a Vibration Probe Foot Using an EPM for Aerial Inspection Robots, Proc. Of the 10th International Symposium on Advanced Science and Technology in Experimental Mechanics, (2015), 55.

\bibitem{h}
S. Akahori, Y. Higashi, A. Masuda,
Development of an Aerial Inspection Robot with EPM and Camera Arm for Steel Structures, TENCON 2016 - 2016 IEEE Region 10 Conference,
(2016), 1264.

\bibitem{i}
Autonomous Control Systems Laboratory Ltd.，\\
\url{http://www.acsl.co.jp/products/}，2018/02/02閲覧

\bibitem{j}
decaWave，\\
\url{https://www.decawave.com/products/dwm1000-module}，2018/02/02閲覧

\bibitem{k}
G. Bradski, A. Kaehler, 松田晃一，詳解OpenCVコンピュータビジョンライブラリを使った画像処理・認識，(2012)，377-387，423-432，オーム社.

\bibitem{l}
M. Kok, T. B. Schon, Magnetometer Calibration Using Inertial Sensors, IEEE Sensors Journal Volume: 16, (2016), 5679-5689.

\bibitem{m}
Q. Li, J. G. Griffiths, Least Squares Ellipsoid Specific Fitting, Geometric Modeling and Processing 2014, (2014), 2-5.

\bibitem{n}
足立修一，丸田一郎，カルマンフィルタの基礎，(2013)，99-110，東京電機大学出版局.

\bibitem{o}
T. Madani, A. Benallegue, Backstepping Control for a Quadrotor Helicopter, Proceedings of the 2006 IEEE/RSJ International Conference on Intelligent Robots and System, 9419317, (2006), 1-6.

\bibitem{q}
Z. Fang, W. Gao, Adaptive Integral Backstepping Control of a Micro-Quadrotor, Intelligent Control and Information Processing (ICICIP), 12217869, (2011), 1-6.

\bibitem{r}
Z. Zuo, Quadrotor Trajecotry Tracking Control: A PD Control Algorithm, 2010 3rd International Conference on Computer and Electrical Engineering (ICCEE 2010), (2010), 3-4.


\end{thebibliography}


\end{document}